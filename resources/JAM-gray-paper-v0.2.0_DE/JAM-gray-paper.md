<br />
<div align="center">
<img src="img/jam-pen-back.png" width="300"/>
</div>
<br />

<br />
<div align="center">   

# Join-Accumulate-Maschine: Eine semi-kohÃ¤rente, skalierbare, vertrauenslose VM
***Entwurf 0.2.0 Tokyo***   
Verfasser: DR. GAVIN WOOD   
GRÃœNDER, POLKADOT & ETHEREUM   
GAVIN@PARITY.IO   
</div>
<br />

<br />
<div align="center">  

Originalarbeit: https://github.com/gavofyork/graypaper/releases/tag/v0.2.0
</div>
<br />

<br />
<div align="center">   

Deutsche Ãœbersetzung durch [h3rak1it](https://github.com/h3rak1it)
</div>
<br />

Die folgende Ãœbersetzung dient ausschlieÃŸlich zu Bildungszwecken. Ich Ã¼bernehme keine Haftung fÃ¼r die Richtigkeit, VollstÃ¤ndigkeit oder AktualitÃ¤t der Ãœbersetzung.

Es wird empfohlen, diese Ãœbersetzung als zusÃ¤tzliche Ressource zusammen mit dem Originalpapier zu verwenden, insbesondere aufgrund der Darstellung der Formeln, da die Ãœbersetzung nicht in LaTeX erstellt wurde.

## Abstrakt
Wir prÃ¤sentieren eine umfassende und formale Definition von JAM, einem Protokoll, das Elemente sowohl von Polkadot als auch von Ethereum kombiniert. In einem einzigen kohÃ¤renten Modell bietet JAM eine globale, erlaubnisfreie Einzelobjektumgebung â€“ Ã¤hnlich der von Ethereum eingefÃ¼hrten Smart-Contract-Umgebung â€“ kombiniert mit sicherer Nebenbandberechnung (sideband), die Ã¼ber ein skalierbares Knotennetzwerk parallelisiert wird, ein Konzept, das von Polkadot eingefÃ¼hrt wurde.

JAM fÃ¼hrt ein dezentrales Hybridsystem ein, das Smart-Contract-FunktionalitÃ¤t bietet und um einen sicheren und skalierbaren **In-Core/On-Chain-Dualismus** strukturiert ist. WÃ¤hrend die Smart-Contract-FunktionalitÃ¤t einige Ã„hnlichkeiten mit dem Ethereum-Paradigma impliziert, wird das Gesamtmodell des angebotenen Dienstes weitgehend von der zugrunde liegenden Architektur von Polkadot bestimmt.

JAM ist in seiner Natur erlaubnisfrei (permissionless), was es jedem ermÃ¶glicht, Code als Dienst (code as a service) darauf zu deployen, gegen eine GebÃ¼hr (Fee), die den genutzten Ressourcen entspricht, und die AusfÃ¼hrung dieses Codes durch die Beschaffung und Zuweisung von **Core-Time** zu induzieren, ein MaÃŸ fÃ¼r widerstandsfÃ¤hige und allgegenwÃ¤rtige Berechnungen, das dem Kauf von Gas in Ethereum etwas Ã¤hnelt. Wir sehen bereits einen Polkadot-kompatiblen CoreChains-Dienst (Service) vor.

## 1. EinfÃ¼hrung
### 1.1 Nomenklatur
In diesem Papier stellen wir ein dezentrales, krypto-Ã¶konomisches Protokoll vor, zu dem das Polkadot-Netzwerk mÃ¶glicherweise in einer groÃŸen Revision Ã¼bergehen kÃ¶nnte. Im Falle dieses Ereignisses (was nicht als selbstverstÃ¤ndlich angesehen werden darf, da Polkadot ein dezentrales Netzwerk ist) kÃ¶nnte dieses Protokoll auch als Polkadot oder eine Ableitung davon bekannt werden. Derzeit ist dies jedoch nicht der Fall, daher wird unser vorgeschlagenes Protokoll vorerst als JAM bekannt sein.

Eine frÃ¼he, unausgereifte Version dieses Protokolls wurde erstmals im Polkadot Fellowship **rfc31** vorgeschlagen, bekannt als **CoreJAM**. **CoreJAM** hat seinen Namen von dem Sammeln/Verfeinern/Verbinden/Akkumulieren-Modell (collect/
refine/join/accumulate model) der Berechnung, das im Mittelpunkt seines Dienstleistungskonzepts steht. WÃ¤hrend das CoreJAM-rfc eine unvollstÃ¤ndige, eingeschrÃ¤nkte Ã„nderung des Polkadot-Protokolls vorschlug, bezieht sich JAM auf ein vollstÃ¤ndiges und kohÃ¤rentes Blockchain-Protokoll.

### 1.2. Treibende Faktoren
Im Bereich der Blockchain und des weiteren Web3 sind wir in erster Linie davon getrieben, WiderstandsfÃ¤higkeit (resilience) zu liefern. Ein richtiges Web3-Digitalsystem sollte ein deklariertes Serviceprofil einhalten â€“ und idealerweise sogar wahrgenommene Erwartungen erfÃ¼llen â€“ unabhÃ¤ngig von den WÃ¼nschen, dem Reichtum oder der Macht wirtschaftlicher Akteure, einschlieÃŸlich Einzelpersonen, Organisationen und anderen Web3-Systemen. Dies ist unvermeidlich ambitioniert, und wir mÃ¼ssen pragmatisch sein, wie perfekt dies wirklich geliefert werden kann. Nichtsdestotrotz sollte ein Web3-System darauf abzielen, so radikal starke Garantien zu bieten, dass das System praktisch als unaufhaltsam beschrieben werden kann.

WÃ¤hrend Bitcoin vielleicht das erste Beispiel eines solchen Systems im wirtschaftlichen Bereich ist, war es in Bezug auf die Art des angebotenen Dienstes nicht allgemeingÃ¼ltig. Ein regelbasiertes System ist nur so nÃ¼tzlich wie die AllgemeingÃ¼ltigkeit (generality) der Regeln, die darin konzipiert und platziert werden kÃ¶nnen. Die Regeln von Bitcoin ermÃ¶glichten einen ersten Anwendungsfall, nÃ¤mlich ein Token mit fester Ausgabe, dessen Besitz durch Kenntnis eines Geheimnisses gut approximiert und autonom durchgesetzt wird, sowie einige weitere Ausarbeitungen zu diesem Thema.

SpÃ¤ter bot Ethereum eine kategorisch allgemeinere Regelmenge, die praktisch Turing-vollstÃ¤ndig war.**^1** Im Kontext von Web3, wo wir eine massiv mehrbenutzerfÃ¤hige Anwendungsplattform liefern wollen, ist AllgemeingÃ¼ltigkeit entscheidend, und daher nehmen wir dies als gegeben an.

> **Footnotes:**
>
>**^1** Das Gas-Mechanismus beschrÃ¤nkte zwar, welche Programme darauf ausgefÃ¼hrt werden kÃ¶nnen, indem es eine Obergrenze fÃ¼r die Anzahl der ausfÃ¼hrbaren Schritte festlegte, aber es muss sicherlich eine EinschrÃ¤nkung eingefÃ¼hrt werden, um unendliche Berechnungen in einer erlaubnisfreien Umgebung zu vermeiden.

Ãœber WiderstandsfÃ¤higkeit und AllgemeingÃ¼ltigkeit hinaus wird es interessanter, und wir mÃ¼ssen etwas tiefer graben, um unsere treibenden Faktoren zu verstehen. FÃ¼r die gegenwÃ¤rtigen Zwecke identifizieren wir drei zusÃ¤tzliche Ziele:

- (1) **WiderstandsfÃ¤higkeit (Resilience)**: hoch resistent gegen Unterbrechung, Korruption und Zensur.
- (2) **AllgemeingÃ¼ltigkeit (Generality)**: in der Lage, Turing-vollstÃ¤ndige Berechnungen durchzufÃ¼hren.
- (3) **Leistung (Performance)**: in der Lage, Berechnungen schnell und kostengÃ¼nstig durchzufÃ¼hren.
- (4) **KohÃ¤renz (Coherency)**: die kausale Beziehung, die zwischen verschiedenen Elemente des Zustands mÃ¶glich ist, und wie gut einzelne Anwendungen zusammengesetzt werden kÃ¶nnen.
- (5) **ZugÃ¤nglichkeit (Accessibility)**: vernachlÃ¤ssigbare Barrieren fÃ¼r Innovation; einfach, schnell, kostengÃ¼nstig und erlaubnisfrei.

Als deklarierte Web3-Technologie nehmen wir die ersten beiden Punkte implizit an. Interessanterweise sind Punkt 3 und Punkt 4 antagonistisch gemÃ¤ÃŸ einem informations-theoretischen Prinzip, das unserer Meinung nach bereits in irgendeiner Form existiert, fÃ¼r das wir jedoch keinen Namen kennen. Argumentativ werden wir es **GrÃ¶ÃŸen-Synchronie-Antagonismus (size-synchrony antagonism)** nennen.

### 1.3. Skalierung unter GrÃ¶ÃŸen-Synchronie-Antagonismus (Size-Synchrony Antagonism)
Der GrÃ¶ÃŸen-Synchronie-Antagonismus ist ein einfaches Prinzip, das besagt, dass ein Informationssystem, wenn der Zustandsraum wÃ¤chst, notwendigerweise weniger synchron wird. Das Argument lautet:

- (1) Je mehr Zustand ein System fÃ¼r seine Datenverarbeitung nutzt, desto mehr Platz muss dieser Zustand einnehmen.
- (2) Je mehr Platz verwendet wird, desto grÃ¶ÃŸer sind die mittleren und varianzmÃ¤ÃŸigen AbstÃ¤nde zwischen den Zustandskomponenten.
- (3) Wenn Mittelwert und Varianz zunehmen, werden die Interaktionen langsamer und die Teilsysteme mÃ¼ssen die MÃ¶glichkeit verwalten, dass die AbstÃ¤nde zwischen interdependenten Komponenten des Zustands materiell unterschiedlich sein kÃ¶nnten, was AsynchronitÃ¤t erfordert.

Dies setzt eine perfekte KohÃ¤renz des Systemzustands voraus. Wenn wir die Frage der allgemeinen Sicherheit fÃ¼r einen Moment beiseite lassen, kÃ¶nnen wir diese Regel vermeiden, indem wir das Teile-und-herrsche-Prinzip anwenden und den Zustand eines Systems fragmentieren, wodurch seine KohÃ¤renz geopfert wird. Wir kÃ¶nnten zum Beispiel zwei unabhÃ¤ngige Systeme mit kleinerem Zustand schaffen, anstatt ein System mit groÃŸem Zustand. Dieses Muster wendet eine Stufenkurve (step-curve) auf das Prinzip an; die inner-systemische Verarbeitung hat eine geringe GrÃ¶ÃŸe und hohe SynchronitÃ¤t, die zwischen-systemische Verarbeitung hat eine groÃŸe GrÃ¶ÃŸe, aber geringe SynchronitÃ¤t. Es ist das Prinzip hinter Meta-Netzwerken wie Polkadot, Cosmos und der vorherrschenden Vision eines skalierten Ethereum (alle werden in KÃ¼rze ausfÃ¼hrlich diskutiert).

Die vorliegende Arbeit untersucht einen Mittelweg im Antagonismus, der die anhaltende Fragmentierung des Zustandsraums des Systems wie bei bestehenden AnsÃ¤tzen vermeidet. Wir tun dies, indem wir ein neues Berechnungsmodell einfÃ¼hren, das ein hoch skalierbares Element mit einem hoch synchronen Element verbindet. AsynchronitÃ¤t wird nicht vermieden, aber wir erÃ¶ffnen die MÃ¶glichkeit einer hÃ¶heren GranularitÃ¤t, wie sie gegen GrÃ¶ÃŸe ausgetauscht wird. Insbesondere kann die Fragmentierung ephemer statt persistent gemacht werden, indem auf einen kohÃ¤renten Zustand zurÃ¼ckgegriffen und dieser nur so lange fragmentiert wird, wie es dauert, eine beliebige Berechnung darauf auszufÃ¼hren.

Im Gegensatz zu SNARK-basierten L2-Blockchain-Techniken zur Skalierung zieht dieses Modell auf krypto-Ã¶konomische Mechanismen zurÃ¼ck und erbt deren kostengÃ¼nstige und leistungsstarke Profile und vermeidet eine Tendenz zur Zentralisierung.

### 1.4. Dokumentstruktur
Wir beginnen mit einem kurzen Ãœberblick Ã¼ber die aktuellen SkalierungsansÃ¤tze in der Blockchain-Technologie in Abschnitt 2. In Abschnitt 3 definieren und klÃ¤ren wir die Notation, aus der wir fÃ¼r unsere Formalismen schÃ¶pfen werden. 

Wir fahren fort mit einem umfassenden Ãœberblick Ã¼ber das Protokoll in Abschnitt 4, in dem die wichtigsten Bereiche, einschlieÃŸlich der Polka Virtual Machine (**PVM**), der Konsensprotokolle **Safrole** und **GRANDPA**, der gemeinsamen Zeitmessung und der Grundlagen des Formalismus, umrissen werden.

Wir setzen dann die vollstÃ¤ndige Protokolldefinition fort, aufgeteilt in zwei Teile: zunÃ¤chst die korrekte **On-Chain-ZustandsÃ¼bergangsformel (on-chain state-transition)**, die fÃ¼r alle Knoten hilfreich ist, die den Kettenzustand validieren mÃ¶chten, und zweitens in den Abschnitten 13 und 18 die ehrliche (honest) Strategie fÃ¼r die **Off-Chain-Aktionen** aller Akteure, die einen **Validator-SchlÃ¼ssel** besitzen.

Der Hauptteil endet mit einer Diskussion Ã¼ber die Leistungsmerkmale des Protokolls in Abschnitt 20 und schlieÃŸt schlieÃŸlich mit Abschnitt 21.

Der Anhang enthÃ¤lt verschiedene zusÃ¤tzliche Materialien, die fÃ¼r die Protokolldefinition wichtig sind, einschlieÃŸlich der **PVM** in den AnhÃ¤ngen A und B, der **Serialisierung und Merklisierung** in den AnhÃ¤ngen C und D und der **Kryptografie** in den AnhÃ¤ngen F, G und H. Wir schlieÃŸen mit einem Index der Begriffe, der die Werte aller einfachen Konstanten enthÃ¤lt, die in der Arbeit verwendet werden, im Anhang I und schlieÃŸen mit der Bibliographie ab.

## 2 FrÃ¼here Arbeiten und gegenwÃ¤rtige Trends
Seit der ersten VerÃ¶ffentlichung des **Ethereum YP** hat sich der Bereich der Blockchain-Entwicklung immens weiterentwickelt. Neben der Skalierbarkeit wurde an zugrunde liegenden Konsensalgorithmen, Smart-Contract-Sprachen und -Maschinen sowie allgemeinen Zustandsumgebungen gearbeitet. Obwohl interessant, liegen diese letzteren Themen grÃ¶ÃŸtenteils auÃŸerhalb des Umfangs der vorliegenden Arbeit, da sie im Allgemeinen die zugrunde liegende Skalierbarkeit nicht beeinflussen.

### 2.1. Polkadot 
Um seinen Dienst bereitzustellen, Ã¼bernimmt JAM viele der gleichen spieltheoretischen und kryptografischen Mechanismen wie Polkadot, bekannt als **ELVES** und beschrieben von **Alistair Stewart 2018**. Es gibt jedoch wesentliche Unterschiede im tatsÃ¤chlichen Dienstangebot von JAM, das eine Abstraktion bietet, die dem tatsÃ¤chlichen Berechnungsmodell, das von den Validator-Knoten erzeugt wird, nÃ¤her kommt und dessen Wirtschaftlichkeit es incentiviert. 

Ein wesentlicher Punkt des ursprÃ¼nglichen Polkadot-Vorschlags, einer skalierbaren heterogenen Multichain, war die Bereitstellung hoher Leistung durch Partitionierung und Verteilung der Arbeitslast auf mehrere Host-Maschinen. Dabei wurde eine explizite Position eingenommen, dass die Komponierbarkeit verringert wÃ¼rde. Polkadots konstituierende Komponenten, Parachains, sind praktisch gesehen stark isoliert in ihrer Natur. Obwohl ein NachrichtenÃ¼bermittlungssystem (**XCMP**) existiert, ist es asynchron, grobgranular und praktisch begrenzt durch seine AbhÃ¤ngigkeit von einer sich langsam entwickelnden Interaktionssprache XCM.

Daher ist die von Polkadot zwischen seinen konstituierenden Ketten angebotene Komponierbarkeit geringer als bei Ethereum-Ã¤hnlichen Smart-Contract-Systemen, die eine einzige und universelle Objektumgebung bieten und die Art von agiler und innovativer Integration ermÃ¶glichen, die ihren Erfolg untermauert. Polkadot ist, wie es derzeit steht, eine Sammlung unabhÃ¤ngiger Ã–kosysteme mit nur begrenzten KooperationsmÃ¶glichkeiten, sehr Ã¤hnlich den ergonomischen Anforderungen von verbundenen Blockchains, jedoch mit einem kategorisch anderen Sicherheitsprofil. Ein technischer Vorschlag, bekannt als **SPREE**, wÃ¼rde Polkadots einzigartige geteilte Sicherheit nutzen und die Komponierbarkeit verbessern, obwohl Blockchains weiterhin isoliert bleiben wÃ¼rden.

Die Implementierung und der Start einer Blockchain sind schwierig, zeitaufwendig und kostspielig. Durch sein ursprÃ¼ngliches Design beschrÃ¤nkt Polkadot die Klienten, die seinen Dienst nutzen kÃ¶nnen, auf diejenigen, die sowohl in der Lage sind, dies zu tun, als auch eine ausreichende Kaution aufzubringen, um eine Auktion fÃ¼r einen langfristigen Slot zu gewinnen, derzeit einer von etwa 50. Obwohl nicht per se erlaubnispflichtig, ist die ZugÃ¤nglichkeit kategorisch und erheblich geringer als bei Smart-Contract-Systemen, die Ethereum Ã¤hneln.

Es scheint, dass die ErmÃ¶glichung der Teilnahme und Interaktion mÃ¶glichst vieler Innovatoren, sowohl untereinander als auch mit der Benutzerbasis des jeweils anderen, ein wichtiger Erfolgsfaktor fÃ¼r eine Web3-Anwendungsplattform ist. ZugÃ¤nglichkeit ist daher entscheidend.

### 2.2. Ethereum 
Das Ethereum-Protokoll wurde formell in diesem Papier, dem geistigen VorgÃ¤nger des **Yellow Paper**, von Wood 2014 definiert. Dies wurde zu groÃŸen Teilen aus dem ursprÃ¼nglichen Konzeptpapier von Buterin 2013 abgeleitet. In dem Jahrzehnt seit der VerÃ¶ffentlichung des YP hat das de facto Ethereum-Protokoll und die Ã¶ffentliche Netzwerkinstanz eine Reihe von Weiterentwicklungen durchlaufen, die hauptsÃ¤chlich darauf abzielen, FlexibilitÃ¤t Ã¼ber das Transaktionsformat und den Befehlssatz und â€Precompilesâ€œ (spezialisierte, ausgeklÃ¼gelte Zusatzbefehle) seines Skriptkerns, der **Ethereum Virtual Machine (EVM)**, zu ermÃ¶glichen.

Fast eine Million krypto-Ã¶konomische Akteure nehmen an der Validierung fÃ¼r Ethereum teil.**^2** Die Blockerweiterung erfolgt durch eine zufÃ¤llige FÃ¼hrungsrotation, bei der die physische Adresse des FÃ¼hrenden im Voraus vor der Blockproduktion bekannt ist. **^3** Ethereum verwendet **Casper-FFG**, eingefÃ¼hrt von Buterin 2019, um die FinalitÃ¤t zu bestimmen, die mit der groÃŸen Anzahl an Validierern die KettenverlÃ¤ngerung etwa alle 13 Minuten finalisiert.

> **Footnotes:**
>
> **^2** Praktische ErwÃ¤gungen begrenzen das MaÃŸ an echter Dezentralisierung. Die Validator-Software bietet ausdrÃ¼cklich Funktionen, die es ermÃ¶glichen, eine einzelne Instanz mit mehreren SchlÃ¼sselsets zu konfigurieren, wodurch systematisch ein wesentlich geringeres MaÃŸ an tatsÃ¤chlicher Dezentralisierung erreicht wird als die scheinbare Anzahl der Akteure, sowohl in Bezug auf einzelne Betreiber als auch auf Hardware. Anhand der von Hildobby 2024 gesammelten Daten Ã¼ber Ethereum 2 kann man sehen, dass ein Hauptknotenbetreiber, Lido, konstant fast ein Drittel der fast eine Million krypto-Ã¶konomischen Teilnehmer ausmacht.
>
> **^3** Die Entwickler von Ethereum hoffen, dies in etwas Sichereres zu Ã¤ndern, aber es gibt keinen festen Zeitplan.

Die direkte Rechenleistung von Ethereum bleibt im Wesentlichen Ã¤hnlich wie bei der EinfÃ¼hrung im Jahr 2015, mit einer bemerkenswerten Ausnahme, dass nun ein zusÃ¤tzlicher Dienst erlaubt, **1 MB** Verpflichtungsdaten (commitment data) pro Block zu hosten (alle Knoten speichern es fÃ¼r eine begrenzte Zeit). Die Daten kÃ¶nnen nicht direkt von der HauptzustandsÃ¼bergangsfunktion (main state-transition function) genutzt werden, aber spezielle Funktionen bieten den Nachweis, dass die Daten (oder ein Teil davon) verfÃ¼gbar sind. Laut Ethereum danksharding ist die gegenwÃ¤rtige Designrichtung, dies in den kommenden Jahren zu verbessern, indem die Verantwortung fÃ¼r die Speicherung unter den Validatoren in einem Protokoll namens **Dank-Sharding** aufgeteilt wird.

Laut Ethereum  wÃ¼rde die Skalierungsstrategie von Ethereum darin bestehen, diese DatenverfÃ¼gbarkeit mit einem privaten Markt von Roll-ups zu koppeln, sideband computation facilities verschiedener Designs, wobei zk-SNARK-basierte Roll-ups eine erklÃ¤rte PrÃ¤ferenz sind. Das Design, die AusfÃ¼hrung und der Betrieb jedes Anbieters von Roll-ups haben ihre eigenen Implikationen. 

Man kÃ¶nnte vernÃ¼nftigerweise annehmen, dass ein diversifizierter, marktorientierter Ansatz zur Skalierung Ã¼ber Multivendor-Roll-ups gut gestaltete LÃ¶sungen gedeihen lÃ¤sst. Es gibt jedoch potenzielle Probleme mit der Strategie. Ein Forschungsbericht von Sharma 2024 Ã¼ber den Grad der Dezentralisierung in den verschiedenen Roll-ups fand ein breites Muster der Zentralisierung, stellt jedoch fest, dass daran gearbeitet wird, dies zu mildern. Es bleibt abzuwarten, wie dezentralisiert sie noch gemacht werden kÃ¶nnen.

Heterogene Kommunikationseigenschaften (wie Datagramm-Latenz (datagram latency) und semantische Reichweite (semantic range)), Sicherheitseigenschaften (wie die Kosten fÃ¼r RÃ¼ckgÃ¤ngigmachung, Korruption, StÃ¶rung und Zensur) und wirtschaftliche Eigenschaften (die Kosten fÃ¼r die Annahme und Verarbeitung einer eingehenden Nachricht oder Transaktion) kÃ¶nnen sich zwischen den Hauptbereichen eines groÃŸen Flickenteppichs von Roll-ups durch verschiedene konkurrierende Anbieter mÃ¶glicherweise erheblich unterscheiden. WÃ¤hrend das gesamte Ethereum-Netzwerk mÃ¶glicherweise irgendwann einige oder sogar die meisten der zugrunde liegenden Maschinen bereitstellt, die fÃ¼r die sideband computation benÃ¶tigt werden, ist es keineswegs klar, dass es eine â€groÃŸe Konsolidierungâ€œ der verschiedenen Eigenschaften geben wird, falls dies geschieht. Wir haben keine gute Diskussion Ã¼ber die negativen Auswirkungen eines solchen fragmentierten Ansatzes gefunden.**^4**  

> **Footnotes:**
>
>**^4** Einige erste Ãœberlegungen zu diesem Thema fÃ¼hrten zu einem Vorschlag von Sadana, die Polkadot-Technologie zu nutzen, um ein MindestmaÃŸ an KompatibilitÃ¤t zwischen Roll-up-Ã–kosystemen zu schaffen!

#### 2.2.1. SNARK Roll-ups.
WÃ¤hrend das Protokoll keine groÃŸen Annahmen Ã¼ber die Natur von Roll-ups macht, konzentriert sich Ethereums Strategie fÃ¼r Sideband-Berechnungen auf SNARK-basierte Roll-ups und entwickelt das Protokoll dementsprechend. SNARKs sind das Ergebnis eines exotischen Bereichs der Kryptographie, der es ermÃ¶glicht, Beweise zu erstellen, die einem neutralen Beobachter zeigen, dass das angebliche Ergebnis einer vordefinierten Berechnung korrekt ist. Die KomplexitÃ¤t der ÃœberprÃ¼fung dieser Beweise tendiert dazu, sublinear zur GrÃ¶ÃŸe der zu beweisenden Berechnung zu sein und gibt keine internen Details dieser Berechnung oder abhÃ¤ngige Beweisdaten preis, auf die sie sich stÃ¼tzen kÃ¶nnte.

Zk-SNARKs haben EinschrÃ¤nkungen. Es gibt einen Kompromiss zwischen der GrÃ¶ÃŸe des Beweises, der KomplexitÃ¤t der ÃœberprÃ¼fung und der RechenkomplexitÃ¤t seiner Erstellung. Nicht-triviale Berechnungen, insbesondere solche allgemeiner Natur, die mit binÃ¤ren Manipulationen belastet sind und Smart Contracts so attraktiv machen, lassen sich schwer in das SNARK-Modell integrieren.

Um ein praktisches Beispiel zu geben: **risc-zero** (wie von Bogli bewertet) ist ein fÃ¼hrendes Projekt und bietet eine Plattform zur Erstellung von SNARKs fÃ¼r Berechnungen, die von einer **risc-v-virtuellen Maschine** ausgefÃ¼hrt werden, einer Open-Source- und prÃ¤gnanten risc-Maschinenarchitektur, die gut durch Werkzeuge unterstÃ¼tzt wird. Ein aktueller Benchmark-Bericht von Koute zeigte, dass im Vergleich zum eigenen Benchmark von risc-zero die Beweiserstellung allein Ã¼ber **61.000-mal** lÃ¤nger dauert als das einfache Rekompilieren und AusfÃ¼hren, selbst wenn auf **32-mal** so vielen Kernen ausgefÃ¼hrt wird, mit **20.000-mal** so viel RAM und einer zusÃ¤tzlichen hochmodernen GPU. Laut den Hardware-Mietagenten https://cloud-gpus.com/ betrÃ¤gt der Kostenmultiplikator fÃ¼r die Beweiserstellung mit risc-zero **66.000.000-mal** die Kosten **^5** des AusfÃ¼hrens mit unserem risc-v-Recompiler.

> **Footnotes:**
>
>**^5** HÃ¶chstwahrscheinlich tatsÃ¤chlich erheblich mehr, da dies unter Verwendung von "spare" Hardware auf niedriger Stufe in Verbrauchereinheiten geschah und unser Rekompilierer nicht optimiert war.

Viele kryptographische Primitive werden zu teuer, um praktisch verwendet zu werden, und spezialisierte Algorithmen und Strukturen mÃ¼ssen ersetzt werden. Oftmals sind diese sonst suboptimal. In Erwartung der Verwendung von SNARKs (wie plonk vorgeschlagen 2019) verwendet das vorherrschende Design des Dank-Sharding-VerfÃ¼gbarkeitssystems des Ethereum-Projekts eine Form der **Erasure-Codierung**, die auf Polynom-Verpflichtungen Ã¼ber ein groÃŸes Primzahlfeld zentriert ist, um SNARKs einen akzeptabel performanten Zugriff auf Datenabschnitte zu ermÃ¶glichen. Im Vergleich zu Alternativen wie einem binÃ¤ren Feld und der Merklisierung in der vorliegenden Arbeit fÃ¼hrt dies zu einer Belastung der Validatorknoten, die um GrÃ¶ÃŸenordnungen hÃ¶her ist, was die CPU-Nutzung betrifft.

ZusÃ¤tzlich zu ihren grundlegenden Kosten bieten SNARKs keinen groÃŸen Ausweg aus der Dezentralisierung und der Notwendigkeit von Redundanz, was zu weiteren Kostenmultiplikatoren fÃ¼hrt. WÃ¤hrend die Notwendigkeit einiger Vorteile einer staked Dezentralisierung durch ihre verifizierbare Natur abgewendet wird, ist die Notwendigkeit, mehrere Parteien zu incentivieren, dieselbe Arbeit zu leisten, erforderlich, um sicherzustellen, dass eine einzelne Partei kein Monopol bildet (oder mehrere kein Kartell bilden). Das Beweisen eines inkorrekten ZustandsÃ¼bergangs sollte unmÃ¶glich sein, jedoch kann die Service-IntegritÃ¤t auf andere Weise gefÃ¤hrdet werden; eine vorÃ¼bergehende Aussetzung der Beweiserstellung, selbst wenn sie nur Minuten dauert, kÃ¶nnte erhebliche wirtschaftliche Auswirkungen auf Echtzeit-Finanzanwendungen haben.
Es gibt reale Beispiele fÃ¼r die Gefahr der Zentralisierung, die zu Monopolen fÃ¼hrt. Eines wÃ¤re das bereits erwÃ¤hnte SNARK-basierte Austauschframework; wÃ¤hrend es dezentralen BÃ¶rsen dienen soll, ist es in Wirklichkeit zentralisiert, wobei **Starkware** selbst ein Monopol Ã¼ber die DurchfÃ¼hrung von Trades durch die Erstellung und Einreichung von Beweisen innehat, was zu einem einzelnen Ausfallpunkt fÃ¼hrt â€“ sollte der Dienst von **Starkware** beeintrÃ¤chtigt werden, wÃ¼rde die LebensfÃ¤higkeit des Systems leiden.

Es ist noch nicht nachgewiesen, dass SNARK-basierte Strategien zur Eliminierung des Vertrauens in Berechnungen jemals in der Lage sein werden, kostenmÃ¤ÃŸig mit einer multiparteien-kryptoÃ¶konomischen Plattform zu konkurrieren. Alle bisher vorgeschlagenen SNARK-basierten LÃ¶sungen sind stark auf kryptoÃ¶konomische Systeme angewiesen, um sie zu strukturieren und ihre Probleme zu umgehen. DatenverfÃ¼gbarkeit und -sequenzierung sind zwei Bereiche, die gut verstanden werden und eine kryptoÃ¶konomische LÃ¶sung erfordern.

Wir stellen fest, dass sich die SNARK-Technologie verbessert und die Kryptographen und Ingenieure dahinter in den kommenden Jahren Verbesserungen erwarten. In einem kÃ¼rzlich erschienenen Artikel von Thaler gibt es einige glaubwÃ¼rdige Spekulationen, dass mit einigen jÃ¼ngsten Fortschritten in der Kryptographietechnik die Verlangsamung der Beweiserstellung auf nur **50.000-mal** im Vergleich zur regulÃ¤ren nativen AusfÃ¼hrung reduziert werden kÃ¶nnte und vieles davon parallelisiert werden kÃ¶nnte. Dies ist erheblich besser als die derzeitige Situation, aber immer noch mehrere GrÃ¶ÃŸenordnungen grÃ¶ÃŸer, als erforderlich wÃ¤re, um kostenmÃ¤ÃŸig mit etablierten kryptoÃ¶konomischen Techniken wie **ELVES** zu konkurrieren.

### 2.3. Fragmentierte Meta-Netzwerke 
AnsÃ¤tze zur Skalierbarkeit allgemeiner Berechnungen, die von anderen Projekten verfolgt werden, konzentrieren sich im Wesentlichen auf einen von zwei AnsÃ¤tzen: entweder einen Fragmentierungsansatz oder alternativ einen Zentralisierungsansatz. Wir argumentieren, dass keiner der AnsÃ¤tze eine Ã¼berzeugende LÃ¶sung bietet.

Der Fragmentierungsansatz wird von Projekten wie Cosmos und Avalanche  angefÃ¼hrt. Er umfasst ein System, das durch Netzwerke mit einem homogenen Konsensmechanismus fragmentiert ist, aber von separat motivierten Validatorkommissionen besetzt wird. Dies steht im Gegensatz zu Polkadots einzelnem Validatorensatz und Ethereums erklÃ¤rter Strategie heterogener Roll-ups, die teilweise durch denselben Validatorensatz gesichert sind, der unter einem kohÃ¤renten Anreizrahmen arbeitet. Die HomogenitÃ¤t des genannten Fragmentierungsansatzes ermÃ¶glicht vernÃ¼nftig konsistente Nachrichtenmechaniken, die dazu beitragen, eine ziemlich einheitliche Schnittstelle fÃ¼r die Vielzahl verbundener Netzwerke zu prÃ¤sentieren.

Die offensichtliche Konsistenz ist jedoch oberflÃ¤chlich. Die Netzwerke sind vertrauenslos nur unter der Annahme des korrekten Betriebs ihrer Validatoren, die unter einem kryptoÃ¶konomischen Sicherheitsrahmen arbeiten, der letztlich durch wirtschaftliche Anreize und Strafen beschworen und durchgesetzt wird. Um die doppelte Menge an Arbeit mit dem gleichen Sicherheitsniveau und ohne spezielle Koordination zwischen den ValidatorensÃ¤tzen zu leisten, schreiben solche Systeme im Wesentlichen vor, ein neues Netzwerk mit denselben Anreizebenen und Strafanforderungen wie das sicherste Netzwerk zu bilden, mit dem sie interagieren mÃ¶chten.

Es treten mehrere Probleme auf. Erstens gibt es einen Ã¤hnlichen Nachteil wie bei Polkadots isolierten Parachains und Ethereums isolierten Roll-up-Chains: ein Mangel an KohÃ¤renz aufgrund eines persistent geshardeten Zustands, der synchrone Komponierbarkeit verhindert.

Problematischer ist, dass der Skalierungsansatz durch Fragmentierung, der speziell von Cosmos vorgeschlagen wurde, keine homogenen Sicherheits- und Vertrauenslosigkeitsgarantien bietet. Die ValidatorensÃ¤tze zwischen Netzwerken mÃ¼ssen als unabhÃ¤ngig ausgewÃ¤hlt und incentiviert angenommen werden, ohne dass eine Beziehung, kausal oder probabilistisch, zwischen den byzantinischen Handlungen einer Partei in einem Netzwerk und den potenziellen angemessenen Konsequenzen in einem anderen Netzwerk besteht. Im Wesentlichen bedeutet dies, dass, wenn Validatoren sich verschwÃ¶ren, um den Zustand eines Netzwerks zu korrumpieren oder rÃ¼ckgÃ¤ngig zu machen, die Auswirkungen auf andere Netzwerke des Ã–kosystems zu spÃ¼ren sein kÃ¶nnten.

Dass dies ein Problem ist, wird allgemein akzeptiert, und Projekte schlagen vor, es auf eine von zwei Arten anzugehen. Erstens, um die erwarteten Angriffskosten (und damit das Sicherheitsniveau) Ã¼ber Netzwerke hinweg zu fixieren, indem man aus demselben Validatorensatz schÃ¶pft. Der massiv redundante Weg dies zu tun, wie von cosmos unter dem Namen **replizierte Sicherheit** vorgeschlagen, wÃ¤re, jeden Validator zu verpflichten, auf allen Netzwerken zu validieren und fÃ¼r dieselben Anreize und Strafen zu sorgen. Dies ist wirtschaftlich ineffizient in den Sicherheitskosten, da jedes Netzwerk unabhÃ¤ngig dasselbe Anreiz- und Strafniveau wie das sicherste bereitstellen mÃ¼sste, mit dem es interagieren mÃ¶chte. Dies soll sicherstellen, dass der wirtschaftliche Vorschlag fÃ¼r Validatoren unverÃ¤ndert bleibt und der Sicherheitsvorschlag fÃ¼r alle Netzwerke gleichwertig bleibt.
Derzeit ist replizierte Sicherheit kein leicht verfÃ¼gbarer erlaubnisfreier Dienst. Wir kÃ¶nnten spekulieren, dass diese bestrafende Ã–konomie etwas damit zu tun hat.

Der effizientere Ansatz, vorgeschlagen vom OmniLedger-Team, wÃ¤re es, die Validatoren nicht redundant zu machen, sie zwischen verschiedenen Netzwerken zu partitionieren und sie periodisch sicher und zufÃ¤llig neu zu verteilen. Es wird impliziert, dass die Angriffskosten reduziert werden, da es eine Chance gibt, dass ein einzelnes Netzwerk versehentlich eine kompromittierende Anzahl bÃ¶sartiger Validatoren hat, selbst wenn dieser Anteil insgesamt geringer ist. Abgesehen davon stellt es ein effektives Mittel dar, um auf der Basis einer schwachen KohÃ¤renz zu skalieren.

Alternativ, wie in ELVES von Stewart, kÃ¶nnen wir eine nicht-redundante Partitionierung (non-redundant partitioning), verwenden, diese mit einem Vorschlags- und Audit-Spiel (proposal-and-auditing game) kombinieren, das Validatoren spielen, um ungÃ¼ltige Berechnungen herauszufiltern und zu bestrafen, und dann verlangen, dass die FinalitÃ¤t eines Netzwerks von allen kausal verstrickten Netzwerken abhÃ¤ngt. Dies ist die sicherste und wirtschaftlich effizienteste LÃ¶sung der drei, da es einen Mechanismus gibt, um hochgradig sicherzustellen, dass ungÃ¼ltige ÃœbergÃ¤nge erkannt und korrigiert werden, bevor ihre Auswirkungen im gesamten Netzwerk-Ã–kosystem finalisiert werden. Es erfordert jedoch wesentlich komplexere Logik und deren kausale Verstrickung impliziert eine Obergrenze fÃ¼r die Anzahl der Netzwerke, die hinzugefÃ¼gt werden kÃ¶nnen.

### 2.4. HochleistungsfÃ¤hige vollstÃ¤ndig synchrone Netzwerke. 
Ein weiterer Trend in den letzten Jahren der Blockchain-Entwicklung war es, taktische Optimierungen der DatenÃ¼bertragungsrate vorzunehmen, indem die GrÃ¶ÃŸe oder Vielfalt des Validatorensets begrenzt, Softwareoptimierungen vorgenommen, ein hÃ¶herer Grad an KohÃ¤renz zwischen den Validatoren gefordert, strenge Anforderungen an die Hardware der Validatoren gestellt oder die DatenverfÃ¼gbarkeit eingeschrÃ¤nkt wurden.

Die Solana-Blockchain basiert auf der von Yakovenko eingefÃ¼hrten Technologie und prahlt mit theoretischen Zahlen von Ã¼ber 700.000 Transaktionen pro Sekunde, obwohl das Netzwerk laut NG is nur einen Bruchteil davon verarbeitet. Der zugrunde liegende Durchsatz ist immer noch wesentlich hÃ¶her als bei den meisten Blockchain-Netzwerken und verdankt dies verschiedenen technischen Optimierungen zugunsten der Maximierung der synchronen Leistung. Das Ergebnis ist eine hochkohÃ¤rente Smart-Contract-Umgebung mit einer API, die der von YP Ethereum Ã¤hnlich ist (wenn auch mit einer anderen zugrunde liegenden VM), aber mit einer nahezu sofortigen Einbeziehungszeit und FinalitÃ¤t, die bei der Einbeziehung als unmittelbar betrachtet wird.

Zwei Probleme ergeben sich bei einem solchen Ansatz: Erstens schafft die Definition des Protokolls als Ergebnis eines stark optimierten Codebases strukturelle Zentralisierung und kann die WiderstandsfÃ¤higkeit untergraben. Jha schreibt: "Seit Januar 2022 fÃ¼hrten 11 signifikante AusfÃ¤lle zu 15 Tagen, an denen bedeutende oder teilweise AusfÃ¤lle auftraten". Dies ist ein AusreiÃŸer unter den groÃŸen Blockchains, da die Ã¼berwiegende Mehrheit der groÃŸen Chains keine Ausfallzeiten hat. Es gibt verschiedene Ursachen fÃ¼r diese Ausfallzeiten, aber sie sind im Allgemeinen auf Fehler in verschiedenen Subsystemen zurÃ¼ckzufÃ¼hren.

Ethereum bot zumindest bis vor kurzem die kontrastreichste Alternative mit seiner gut Ã¼berprÃ¼ften Spezifikation, klaren Forschung zu seinen kryptoÃ¶konomischen Grundlagen und mehreren Clean-Room-Implementierungen. Es ist vielleicht keine Ãœberraschung, dass das Netzwerk sehr bemerkenswert weitgehend ununterbrochen blieb, als ein Fehler in seiner am meisten eingesetzten Implementierung gefunden und bÃ¶swillig ausgenutzt wurde, wie von Hertig 2016 so beschrieben.

Das zweite Problem betrifft die ultimative Skalierbarkeit des Protokolls, wenn es keine Mittel zur Verteilung der Arbeitslast Ã¼ber die Hardware einer einzelnen Maschine hinaus bietet. In groÃŸem Umfang wÃ¼rden sowohl historische Transaktionsdaten als auch der Zustand unpraktisch wachsen. Solana illustriert, wie problematisch dies sein kann. Im Gegensatz zu klassischen Blockchains bietet das Solana-Protokoll keine LÃ¶sung fÃ¼r die Archivierung und anschlieÃŸende ÃœberprÃ¼fung historischer Daten, was entscheidend ist, wenn der aktuelle Zustand von einer dritten Partei ausgehend von Grundprinzipien als korrekt nachgewiesen werden soll. Es gibt wenig Informationen darÃ¼ber, wie Solana dies in der Literatur handhabt, aber laut Solana platzieren Knoten die Daten einfach auf einer zentralen Datenbank, die von Google gehostet wird. **^6**

> **Footnotes:**
>
>**^6** FrÃ¼here Knotenversionen nutzten das Arweave-Netzwerk, einen dezentralen Datenspeicher, aber dies erwies sich als unzuverlÃ¤ssig fÃ¼r den Datenfluss, den Solana benÃ¶tigte.

Solana-Validatoren werden ermutigt, groÃŸe Mengen an RAM zu installieren, um den groÃŸen Zustand im Speicher zu halten (512 GB ist die aktuelle Empfehlung laut solana). Ohne einen Teile-und-herrsche-Ansatz zeigt Solana, dass das Niveau der Hardware, das Validatoren vernÃ¼nftigerweise bereitstellen kÃ¶nnen, das obere Leistungsniveau eines vollstÃ¤ndig synchronen, kohÃ¤renten AusfÃ¼hrungsmodells bestimmt. Hardwareanforderungen stellen Eintrittsbarrieren fÃ¼r das Validatorenset dar und kÃ¶nnen nicht ohne EinbuÃŸen bei der Dezentralisierung und letztlich der Transparenz wachsen.

## 3. Notationskonventionen
Wie im Yellow Paper, verwenden wir in der vorliegenden Arbeit eine Reihe von Notationskonventionen. Zur Klarstellung definieren wir sie hier. Das Yellow Paper selbst wird im Folgenden als das YP bezeichnet.

### 3.1. Typografie 
Wir verwenden verschiedene Schriftarten, um unterschiedliche Arten von Begriffen zu kennzeichnen. Wenn ein Begriff verwendet wird, um auf einen Wert zu verweisen, der nur in einem lokalen Abschnitt des Dokuments relevant ist, verwenden wir einen Kleinbuchstaben, z.B. **ğ‘¥**,**ğ‘¦** (typischerweise verwendet fÃ¼r ein Element einer Menge oder Sequenz) oder **ğ‘–**,**ğ‘—** (typischerweise verwendet fÃ¼r numerische Indizes). Wenn wir uns in einem lokalen Kontext auf einen booleschen Begriff oder eine Funktion beziehen, verwenden wir tendenziell einen GroÃŸbuchstaben, wie z.B. **ğ´**,**ğ¹**. Wenn besondere Betonung auf die Tatsache gelegt wird, dass ein Begriff komplex oder mehrdimensional ist, verwenden wir eine Fettschrift, insbesondere im Fall von Sequenzen und Mengen.

FÃ¼r Elemente, die ihre Definition in der gesamten vorliegenden Arbeit beibehalten, verwenden wir andere typografische Konventionen. Mengen werden Ã¼blicherweise in einer Blackboard-Schriftart bezeichnet, z.B. **ğ‘** bezieht sich auf alle natÃ¼rlichen Zahlen einschlieÃŸlich Null. Mengen, die parametrisiert werden kÃ¶nnen, kÃ¶nnen tiefgestellt oder in Klammern gesetzte Argumente haben. Importierte Funktionen, die in der vorliegenden Arbeit verwendet werden, aber nicht speziell eingefÃ¼hrt werden, werden in kalligraphischer Schriftart geschrieben, z.B. **ğ»**, die Blake2-Kryptographische Hash-Funktion. FÃ¼r andere kontextunabhÃ¤ngige Funktionen, die in der vorliegenden Arbeit eingefÃ¼hrt werden, verwenden wir griechische GroÃŸbuchstaben, z.B. **Î¥** (Ypsilon) bezeichnet die ZustandsÃ¼bergangsfunktion.

Werte, die nicht fest sind, aber dennoch eine konsistente Bedeutung in der gesamten vorliegenden Arbeit haben, werden mit griechischen Kleinbuchstaben wie **ğœ** (sigma), dem Zustandsbezeichner, bezeichnet. Diese kÃ¶nnen in Fettschrift dargestellt werden, um anzuzeigen, dass sie sich auf einen auÃŸergewÃ¶hnlich komplexen Wert beziehen.

### 3.2. Funktionen und Operatoren
Wir definieren die Vorangehensbeziehung, um anzuzeigen, dass ein Begriff in Bezug auf einen anderen definiert ist. Z.B. 
**ğ‘¦â‰ºğ‘¥** ( **â‰º** die Einheit von Menge und Ordnungsrelation) bedeutet, dass **ğ‘¦** rein in Bezug auf **ğ‘¥** definiert werden kann:

<div align="center">
<img src="img/equation-1.PNG" width="700"/>
</div>

Die Substitute-if-nothing-Funktion **ğ‘ˆ** ist gleich dem ersten Argument, das nicht **âˆ…**,
ist, oder wenn **âˆ…** ein solches Argument nicht existiert:

<div align="center">
<img src="img/equation-2.PNG" width="700"/>
</div>

### 3.3. Mengen (Sets)
Wir bezeichnen die KardinalitÃ¤t einer Menge **ğ‘ **, die Anzahl ihrer Elemente, mit dem Ã¼blichen **âˆ£ğ‘ âˆ£**. Wir bezeichnen die Mengen-Disjunktheit mit der Relation **â«°**. Formal:

**A âˆ© B = âˆ… â‡â‡’ A â«° B**

Wir verwenden hÃ¤ufig **âˆ…**, um anzuzeigen, dass ein Begriff gÃ¼ltig ohne spezifischen Wert bleibt. Seine KardinalitÃ¤t wird als Null definiert. Wir definieren die Operation **?** so, dass **ğ´?â‰¡ğ´âˆª{âˆ…}**, was dieselbe Menge mit der Addition des 
**âˆ…**-Elements anzeigt.

Der Begriff **âˆ‡** (Nabla-Operator) wird verwendet, um das unerwartete Scheitern einer Operation oder dass ein Wert ungÃ¼ltig oder unerwartet ist, anzuzeigen. (Wir versuchen, die konventionellere Verwendung von **âŠ¥** zu vermeiden, um Verwechslungen mit dem booleschen Wert falsch zu vermeiden, der in einigen Kontexten als erfolgreiches Ergebnis interpretiert werden kÃ¶nnte.)

### 3.4. Zahlen    
**ğ‘** bezeichnet die Menge der natÃ¼rlichen Zahlen einschlieÃŸlich Null, wÃ¤hrend 
**ğ‘ğ‘›** die Menge der natÃ¼rlichen Zahlen kleiner als **ğ‘›** bezeichnet. Formal, 
**ğ‘={0,1,â€¦}** und **ğ‘ğ‘›={ğ‘¥âˆ£ğ‘¥âˆˆğ‘,ğ‘¥<ğ‘›}**.
**ğ‘** bezeichnet die Menge der ganzen Zahlen. Wir bezeichnen **ğ‘ğ‘â€¦ğ‘** als die Menge der ganzen Zahlen im Intervall **[ğ‘,ğ‘]**. Formal, **ğ‘ğ‘â€¦ğ‘={ğ‘¥âˆ£ğ‘¥âˆˆğ‘,ğ‘â‰¤ğ‘¥<ğ‘}**. Z.B. **ğ‘2â€¦5={2,3,4}**. Wir bezeichnen die Offset/LÃ¤nge-Form dieser Menge als **ğ‘ğ‘â‹¯+ğ‘**, eine Kurzform von **ğ‘ğ‘â€¦ğ‘+ğ‘**.

Es kann manchmal nÃ¼tzlich sein, LÃ¤ngen von Sequenzen darzustellen und gleichzeitig ihre GrÃ¶ÃŸe zu begrenzen, insbesondere bei der Arbeit mit Oktettsequenzen, die praktisch gespeichert werden mÃ¼ssen. Typischerweise kÃ¶nnen diese LÃ¤ngen als die Menge **ğ‘2^32** definiert werden. Zur Verbesserung der Klarheit bezeichnen wir **ğ‘ğ¿** als die Menge der LÃ¤ngen von Oktettsequenzen und ist Ã¤quivalent zu **ğ‘2^32**.

Wir bezeichnen den **%** Operator als den Modulo-Operator, z.B. **5%3=2**. DarÃ¼ber hinaus kÃ¶nnen wir gelegentlich ein Divisionsergebnis als Quotienten und Rest mit dem Separator **R** ausdrÃ¼cken, z.B. **5Ã·3=1R2**.

### 3.5. WÃ¶rterbÃ¼cher (Dictionaries)

Ein WÃ¶rterbuch ist eine mÃ¶glicherweise partielle Abbildung von einem Bereich in einen Mitbereich, Ã¤hnlich einer regulÃ¤ren Funktion. Im Gegensatz zu Funktionen mÃ¼ssen jedoch bei WÃ¶rterbÃ¼chern die gesamten Paare aufzÃ¤hlbar sein, und wir reprÃ¤sentieren sie in einer Datenstruktur als die Menge aller 
(key â†¦ value)-Paare. (In solchen datenbasierten Abbildungen ist es Ã¼blich, die Werte im Bereich als SchlÃ¼ssel und die Werte im Mitbereich als Wert zu bezeichnen, daher die Benennung.)
Daher definieren wir die Formalisierung **DâŸ¨K â†’ VâŸ©** als ein WÃ¶rterbuch, das vom Bereich **K** zum Bereich **V** abbildet. Wir definieren ein WÃ¶rterbuch als Mitglied der Menge aller WÃ¶rterbÃ¼cher **ğ·**und eine Menge von Paaren 
**ğ‘=(ğ‘˜â†¦ğ‘£)**:

<div align="center">
<img src="img/equation-3.PNG" width="700"/>
</div>

Die Mitglieder eines WÃ¶rterbuchs mÃ¼ssen hÃ¶chstens einen eindeutigen Wert fÃ¼r einen SchlÃ¼ssel **ğ‘˜** zuordnen:

<div align="center">
<img src="img/equation-4.PNG" width="700"/>
</div>

Diese Behauptung ermÃ¶glicht es uns, den Subskript- und Subtraktionsoperator fÃ¼r ein WÃ¶rterbuch **ğ‘‘** eindeutig zu definieren:

<div align="center">
<img src="img/equation-5-6.PNG" width="700"/>
</div>

Beachten Sie, dass bei der Verwendung eines Subskripts eine implizite Behauptung besteht, dass der SchlÃ¼ssel im WÃ¶rterbuch existiert. Sollte der SchlÃ¼ssel nicht existieren, ist das Ergebnis undefiniert und jeder Block, der darauf basiert, muss als ungÃ¼ltig betrachtet werden.

Es ist typischerweise nÃ¼tzlich, die Mengen, aus denen die SchlÃ¼ssel und Werte stammen kÃ¶nnen, zu begrenzen. Formal definieren wir ein typisiertes WÃ¶rterbuch **DâŸ¨K â†’ V âŸ©** als eine Menge von Paaren **ğ‘** der Form **(ğ‘˜â†¦ğ‘£)**:
<div align="center">
<img src="img/equation-7-8.PNG" width="700"/>
</div>

Um die aktive DomÃ¤ne (i.e. Menge der SchlÃ¼ssel) eines WÃ¶rterbuchs **d âˆˆ DâŸ¨K â†’ V âŸ©** zu bezeichnen, verwenden wir 
**K(d) âŠ† K** und fÃ¼r den Bereich (i.e. Menge der Werte), **ğ‘‰(ğ‘‘)âŠ†ğ‘‰**. Formal:

<div align="center">
<img src="img/equation-9-10.PNG" width="700"/>
</div>

Beachten Sie, dass da der Mitbereich von **ğ‘‰** eine Menge ist, sollten unterschiedliche SchlÃ¼ssel mit gleichen Werten im WÃ¶rterbuch erscheinen, enthÃ¤lt die Menge nur einen solchen Wert.

### 3.6. Tupel
Tupel sind Gruppen von Werten, wobei jedes Element einer anderen Menge angehÃ¶ren kann. Sie werden durch Klammern gekennzeichnet, z.B. das Tupel **ğ‘¡** der ganzen Zahlen 3 und 5 wird als **ğ‘¡=(3,5)** bezeichnet und gehÃ¶rt zur Menge der ganzzahligen Paare, die manchmal als **ğ‘Ã—ğ‘** bezeichnet wird, aber in der vorliegenden Arbeit als **(ğ‘,ğ‘)** bezeichnet wird.

Wir mÃ¼ssen hÃ¤ufig auf ein spezifisches Element innerhalb eines Tupelwertes verweisen und finden es daher praktisch, einen Namen fÃ¼r jedes Element zu deklarieren. Z.B. kÃ¶nnen wir ein Tupel mit zwei benannten ganzzahligen Komponenten **ğ‘** und **ğ‘** als **ğ‘‡= (ğ‘ âˆˆ ğ‘, ğ‘ âˆˆ ğ‘)** bezeichnen. Wir wÃ¼rden ein Element **ğ‘¡ âˆˆ ğ‘‡** durch Indizierung seines Namens bezeichnen, also fÃ¼r ein **ğ‘¡=(ğ‘:3,ğ‘:5)**, **ğ‘¡ğ‘=3** und **ğ‘¡ğ‘=5**.

### 3.7. Sequenzen

Eine Sequenz ist eine Reihe von Elementen mit einer bestimmten Ordnung, die nicht von ihren Werten abhÃ¤ngt. Die Menge der Sequenzen von Elementen, die alle aus einer Menge **ğ‘‡** stammen, wird mit **âŸ¦ğ‘‡âŸ§** bezeichnet und definiert eine partielle Abbildung **ğ‘ â†’ ğ‘‡**. Die Menge der Sequenzen, die genau **ğ‘›** Elemente enthalten, wobei jedes Element Mitglied der Menge **ğ‘‡** ist, kann mit **âŸ¦ğ‘‡âŸ§ğ‘›** bezeichnet werden und definiert entsprechend eine vollstÃ¤ndige Abbildung **ğ‘ğ‘› â†’ ğ‘‡**. Ebenso kÃ¶nnen Mengen von Sequenzen mit hÃ¶chstens **ğ‘›** Elementen und mindestens **ğ‘›** Elementen mit **âŸ¦ğ‘‡âŸ§âˆ¶ğ‘›** bzw. **âŸ¦TâŸ§ğ‘›âˆ¶** bezeichnet werden.

Sequenzen sind indizierbar, sodass ein bestimmtes Element an der Indexposition **ğ‘–** innerhalb einer Sequenz **ğ‘ ** mit **ğ‘ [ğ‘–]** oder, wenn eindeutig, mit **ğ‘ ğ‘–** bezeichnet werden kann. Ein Bereich kann durch eine Ellipse dargestellt werden, zum Beispiel: **[0, 1, 2, 3]...2 = [0, 1]** und **[0, 1, 2, 3]1â‹…â‹…â‹…+2 = [1, 2]**. Die LÃ¤nge einer solchen Sequenz kann mit âˆ£sâˆ£ bezeichnet werden. Wir bezeichnen die modulo-Indexierung als **ğ‘ [ğ‘–]â†º** â‰¡ **ğ‘ [ ğ‘– % âˆ£ğ‘ âˆ£ ]**. Das letzte Element **ğ‘¥** einer Sequenz **ğ‘  = [..., ğ‘¥]** wird durch die Funktion **last(ğ‘ ) â‰¡ ğ‘¥** bezeichnet.

#### 3.7.1. Konstruktion

Konstruktion. Wir mÃ¶chten mÃ¶glicherweise eine Sequenz in Bezug auf inkrementelle Indizes anderer Werte definieren: ***[x0,x1, ... ]n*** bezeichnet eine Sequenz von ***n*** Werten, beginnend mit ***x0*** und fortgesetzt bis ***xnâˆ’1***. AuÃŸerdem mÃ¶chten wir mÃ¶glicherweise auch eine Sequenz als Elemente definieren, von denen jedes eine Funktion ihres Indexes ***i*** ist; in diesem Fall bezeichnen wir ***[f(i) âˆ£ i <âˆ’ Nn] â‰¡ [f(0), f(1), ..., f(n âˆ’ 1)]***. Wenn die Reihenfolge der Elemente wichtig ist, verwenden wir **<âˆ’** anstelle der ungeordneten Notation ***âˆˆ***. Letztere kann auch in Kurzform geschrieben werden ***[f(i <âˆ’ Nn)]***. Dies gilt fÃ¼r jede Menge, die eine eindeutige Reihenfolge hat, insbesondere fÃ¼r Sequenzen, daher ***[i2 âˆ£ i <âˆ’ [1, 2, 3]] = [1, 4, 9]***. Mehrere Sequenzen kÃ¶nnen kombiniert werden, daher ***[i â‹… j âˆ£ i <âˆ’ [1, 2, 3], j <âˆ’ [2, 3, 4]] = [2, 6, 12]***.

Wir verwenden die explizite Notation ***f#***, um eine Funktion zu kennzeichnen, die Ã¼ber alle Elemente einer Sequenz abbildet. Angenommen, es gibt eine Funktion ***y = f(x)***:

</div>
<div align="center">
<img src="img/equation-11.PNG" width="700"/>
</div>

Sequenzen kÃ¶nnen aus Mengen oder anderen Sequenzen konstruiert werden, deren Reihenfolge ignoriert werden soll, durch Sequenzordnungsnotation ***[ik^^ i âˆˆ X]***, die definiert ist, um in der Menge oder Sequenz ihres Arguments zu resultieren, auÃŸer dass alle Elemente ***i*** in aufsteigender Reihenfolge des entsprechenden Werts ***ik*** platziert werden.

Der Hauptbestandteil kann ausgelassen werden, in welchem Fall angenommen wird, dass er direkt nach den Elementen geordnet ist; d. h. ***[i âˆˆ X] â‰¡ [i|| i âˆˆ X]. [ik|| i âˆˆ X]*** tut dasselbe, schlieÃŸt jedoch alle doppelten Werte von **i** aus. Zum Beispiel, angenommen ***s = [1, 3, 2, 3]***, dann ***[i|| i âˆˆ s] = [1, 2, 3]*** und ***[âˆ’i^^ i âˆˆ s] = [3, 3, 2, 1].***

Mengen kÃ¶nnen aus Sequenzen mit der regulÃ¤ren Mengenkonstruktionssyntax konstruiert werden, z. B. angenommen ***s = [1, 2, 3, 1]***, dann wÃ¤re ***{a âˆ£ a âˆˆ s}*** gleichbedeutend mit ***{1, 2, 3}***. Sequenzen von Werten, die selbst eine definierte Ordnung haben, haben eine implizite Ordnung Ã¤hnlich einem regulÃ¤ren WÃ¶rterbuch, daher ***[1, 2, 3] < [1, 2, 4]*** und ***[1, 2, 3] < [1, 2, 3, 1]***.

#### 3.7.2. Bearbeitung
Wir definieren den Konkatenationsoperator fÃ¼r Sequenzen ***âŒ¢*** so, dass ***[x0,x1, ... ,y0,y1, ... ] â‰¡ x âŒ¢ y***. FÃ¼r Sequenzen von Sequenzen definieren wir einen unÃ¤ren Alles-konkatenieren-Operator: ***(xâŒ¢) â‰¡ x0 âŒ¢ x1 âŒ¢ ...*** . Weiterhin bezeichnen wir die Konkatenation von Elementen als ***x i â‰¡ x âŒ¢ [i]***. Wir bezeichnen die Sequenz, die aus den ersten ***n*** Elementen der Sequenz s besteht, als ***sâ†’n â‰¡ [s0, s1, ... , snâˆ’1]*** und nur die letzten Elemente als ***sâ†’n***.

Wir definieren ***Tx*** als die Transposition der Sequenz-von-Sequenzen ***x***, vollstÃ¤ndig definiert in Gleichung 305. Wir kÃ¶nnen dies auch auf Sequenzen-von-Tupeln anwenden, um ein Tupel von Sequenzen zu erhalten. Wir bezeichnen die Sequenzsubtraktion mit einer leichten Modifikation des Mengensubtraktionsoperators; speziell wird eine Sequenz ***s*** mit Ausnahme des linken Elements gleich ***v*** als ***s \o {v}*** bezeichnet.

#### 3.7.3. Boolesche Werte.
Bs bezeichnet die Menge der Booleschen Zeichenfolgen der LÃ¤nge s, also ***Bs = âŸ¦{âŠ¥, âŠº}âŸ§s***. Beim Umgang mit Booleschen Werten kÃ¶nnen wir eine implizite Ã„quivalenzzuordnung zu einem Bit annehmen, wobei ***âŠº = 1*** und ***âŠ¥ = 0***, also ***Bâ—» = âŸ¦N2âŸ§â—»***. Wir verwenden die Funktion bits ***(Y) âˆˆ B***, um die Bitsequenz zu bezeichnen, die mit dem am wenigsten signifikanten Bit zuerst geordnet ist und die Oktettsequenz ***Y*** reprÃ¤sentiert, also bits(***[5, 0]) = [1, 0, 1, 0, 0, ... ]***.

#### 3.7.4. Oktette und Blobs.
***Y*** bezeichnet die Menge der Oktettzeichenfolgen (â€Blobsâ€œ) beliebiger LÃ¤nge. Wie zu erwarten, bezeichnet ***Yx*** die Menge solcher Sequenzen der LÃ¤nge ***x***. ***Y$*** bezeichnet die Teilmenge von ***Y***, die ASCII-codierte Zeichenfolgen sind.

Beachten Sie, dass ein Oktett eine implizite und offensichtliche bijektive Beziehung zu natÃ¼rlichen Zahlen kleiner als 256 hat und wir implizit zwischen Oktettform und Ganzzahlform wechseln kÃ¶nnen, aber wir behandeln sie nicht als genau Ã¤quivalente EntitÃ¤ten. Insbesondere fÃ¼r den Zweck der Serialisierung wird ein Oktett immer in der Sequenz serialisiert, die nur sich selbst enthÃ¤lt, wÃ¤hrend eine Ganzzahl als eine Sequenz von potenziell mehreren Oktetten serialisiert werden kann, abhÃ¤ngig von ihrer GrÃ¶ÃŸe.

#### 3.7.5. Mischen (Shuffling.)
Wir definieren die Sequenz-Mischfunktion ***F***, ursprÃ¼nglich eingefÃ¼hrt von Fisher and Yates 1938 , mit einem effizienten In-Place-Algorithmus beschrieben von wikipedia. Diese akzeptiert eine Sequenz und etwas Entropie und gibt eine Sequenz derselben LÃ¤nge mit denselben Elementen, aber in einer durch die Entropie bestimmten Reihenfolge zurÃ¼ck. Die Entropie kann entweder als eine unbestimmte Sequenz von Ganzzahlen oder als ein Hash bereitgestellt werden. Eine vollstÃ¤ndige Definition finden Sie im Anhang E.

### 3.8. Kryptographie
#### 3.8.1. Hashing
***H*** bezeichnet die Menge der 256-Bit-Werte, die typischerweise durch eine kryptografische Funktion erzeugt werden, Ã¤quivalent zu ***Y32***, wobei ***H0*** gleich ***[0]32*** ist. Wir nehmen eine Funktion ***H(m âˆˆ Y) âˆˆ H*** an, die den 256-Bit-Hash von Blake2b darstellt, der von rfc7693 eingefÃ¼hrt wurde, und eine Funktion ***HK(m âˆˆ Y) âˆˆ H*** die den 256-Bit-Hash von Keccak darstellt, wie von bertoni2013keccak vorgeschlagen und von wood2014ethereum genutzt.

Manchmal mÃ¶chten wir nur die ersten ***x*** Oktette eines Hashes nehmen, in diesem Fall bezeichnen wir ***Hx(m) âˆˆ Yx*** als die ersten ***x*** Oktette von ***H(m)***. Die Eingaben einer Hashfunktion werden im Allgemeinen als serialisiert mit unserem Codec ***E(x) âˆˆ Y*** angenommen, jedoch kÃ¶nnen wir zur Klarheit oder Eindeutigkeit auch die Serialisierung explizit angeben. Ebenso mÃ¶chten wir eine Sequenz von Oktetten als eine andere Art von Wert interpretieren, wobei die angenommene Decoder-Funktion ***Eâˆ’1(x âˆˆ Y)*** verwendet wird. In beiden FÃ¤llen kÃ¶nnen wir die Transformationsfunktion mit der Anzahl der Oktette, die wir fÃ¼r die Oktettsequenz erwarten, subskribieren. Somit wÃ¼rde ***r = E4(x âˆˆ N) x âˆˆ N2^32*** und ***r âˆˆ Y4*** zuweisen, wÃ¤hrend ***s = E8^âˆ’1(y) y âˆˆ Y8*** und ***s âˆˆ N2^64*** zuweisen wÃ¼rde.

#### 3.8.2. Signiersysteme (Signing Schemes.)
***EkâŸ¨mâŸ© âŠ‚ Y64*** ist die Menge der gÃ¼ltigen Ed25519-Signaturen, definiert von rfc8032, die durch Kenntnis eines geheimen SchlÃ¼ssels erstellt wurden, dessen Ã¶ffentlicher SchlÃ¼ssel ***k âˆˆ Y32*** ist und dessen Nachricht ***m*** ist. Zur besseren Lesbarkeit bezeichnen wir die Menge der gÃ¼ltigen Ã¶ffentlichen SchlÃ¼ssel als ***k âˆˆ HE***.

Wir verwenden ***Y_BLS âŠ‚ Y_144***, um die Menge der Ã¶ffentlichen SchlÃ¼ssel fÃ¼r das BLS-Signaturschema zu bezeichnen, beschrieben von Jofc, auf der Kurve BLS12-381, definiert von BLS12-381.

Wir bezeichnen die Menge der gÃ¼ltigen Bandersnatch-Ã¶ffentlichen SchlÃ¼ssel als ***HB***, definiert in Anhang G. ***FmâˆˆYkâˆˆHBâŸ¨x âˆˆ YâŸ© âŠ‚ Y96 (see orginal paper)*** ist die Menge der gÃ¼ltigen, einfach kontextualisierten Signaturen, die den geheimen Gegenpart zum Ã¶ffentlichen SchlÃ¼ssel ***k***, einen Kontext ***x*** und eine Nachricht ***m*** nutzen.

***Â¯F mâˆˆY râˆˆYRâŸ¨x âˆˆ YâŸ© âŠ‚ Y_784 (see orginal paper)*** ist hingegen die Menge der gÃ¼ltigen Bandersnatch RingVRF deterministischen, einfach kontextualisierten Wissensnachweise eines Geheimnisses innerhalb einer Menge von Geheimnissen, identifiziert durch eine Wurzel in der Menge der gÃ¼ltigen Wurzeln ***YR âˆˆ Y_196608***. Wir bezeichnen ***O(s âˆˆ âŸ¦HBâŸ§) âˆˆ YR*** als die spezifische Wurzel der Menge der Ã¶ffentlichen SchlÃ¼ssel-GegenstÃ¼cke ***s***. Eine Wurzel impliziert eine spezifische Menge von Bandersnatch-SchlÃ¼sselpaaren; Kenntnis eines der Geheimnisse wÃ¼rde bedeuten, dass man in der Lage wÃ¤re, einen einzigartigen, gÃ¼ltigen und anonymen Wissensnachweis eines einzigartigen Geheimnisses innerhalb der Menge zu erstellen.

Sowohl die Bandersnatch-Signatur als auch der RingVRF-Nachweis implizieren streng, dass ein Mitglied seinen geheimen SchlÃ¼ssel in Kombination mit sowohl dem Kontext ***x*** als auch der Nachricht m verwendet hat; der Unterschied besteht darin, dass das Mitglied im ersteren Fall identifiziert wird und im letzteren anonym bleibt. DarÃ¼ber hinaus definieren beide eine ***VRF***-Ausgabe, einen hoch-entropy Hash, der von ***x*** beeinflusst wird, aber nicht von ***m***, formell bezeichnet als ***Y(Â¯F mrâŸ¨xâŸ©) âŠ‚ H und Y(FmkâŸ¨xâŸ©) âŠ‚ H(see orginal paper)***.

Wir definieren die Funktion ***S*** als Signaturfunktion, so dass ***Sk(m) âˆˆ FmkâŸ¨[]âŸ© âˆª EkâŸ¨mâŸ©(see orginal paper)***. Wir behaupten, dass die FÃ¤higkeit, ein Ergebnis fÃ¼r diese Funktion zu berechnen, auf der Kenntnis eines geheimen SchlÃ¼ssels beruht.

## 4. Ãœbersicht
Wie im Yellow Paper beginnen wir unsere Formalismen, indem wir daran erinnern, dass eine Blockchain als Paarung eines Anfangszustands mit einer ZustandsÃ¼bergangsfunktion auf Blockebene definiert werden kann. Letztere definiert den nachfolgenden Zustand, gegeben ein Paar aus einem vorherigen Zustand und einem darauf angewendeten Datenblock. Formal sagen wir:

</div>
<div align="center">
<img src="img/equation-12.PNG" width="700"/>
</div>

Wobei ***Ïƒ*** der vorherige Zustand ist, ***Ïƒâ€²*** der nachfolgende Zustand, ***B*** ein gÃ¼ltiger Block und ***Î¥*** unsere ZustandsÃ¼bergangsfunktion auf Blockebene ist.
Im GroÃŸen und Ganzen kann JAM (und tatsÃ¤chlich Blockchains im Allgemeinen) einfach definiert werden, indem man ***Î¥*** und einen Anfangszustand (genesis state) ***Ïƒ^0*** spezifiziert.**^7** Wir machen auch einige zusÃ¤tzliche Annahmen Ã¼ber vereinbartes Wissen: eine allgemein bekannte Uhr und die praktischen Mittel zur Datenfreigabe mit anderen Systemen, die unter denselben Konsensregeln arbeiten. Letztere beiden waren stillschweigende Annahmen im YP.

> **Footnotes:**
>
>**^7** Praktisch gesehen machen Blockchains manchmal Annahmen Ã¼ber einen bestimmten Teil der Teilnehmer, deren Verhalten einfach ehrlich ist und weder nachweislich falsch noch anderweitig wirtschaftlich benachteiligt ist. Obwohl diese Annahme vernÃ¼nftig sein mag, muss sie dennoch getrennt von den Regeln des ZustandsÃ¼bergangs angegeben werden.

### 4.1. Block
Zur UnterstÃ¼tzung des VerstÃ¤ndnisses und der Definition unseres Protokolls teilen wir so viele unserer Begriffe wie mÃ¶glich in ihre funktionalen Komponenten auf. Wir beginnen mit dem Block ***B***, der als Header ***H*** und einigen externen, zum System gehÃ¶renden Eingabedaten, die als extrinsisch bezeichnet werden, neu formuliert werden kann, ***E***:

</div>
<div align="center">
<img src="img/equation-13-14.PNG" width="700"/>
</div>

Der Header ist eine Sammlung von Metadaten, die sich hauptsÃ¤chlich auf kryptografische Referenzen zu den Blockchain-Vorfahren sowie die Operanden und das Ergebnis des aktuellen Ãœbergangs beziehen. Als ein a priori bekanntes, unverÃ¤nderliches Element wird angenommen, dass es wÃ¤hrend der funktionalen Komponenten des BlockÃ¼bergangs verfÃ¼gbar ist. Die extrinsischen Daten werden in ihre verschiedenen Teile aufgeteilt:

- **Tickets (tickets)**: Tickets, die fÃ¼r den Mechanismus verwendet werden, der die Auswahl von Validatoren fÃ¼r die Erlaubnis der Blockerstellung verwaltet. Diese Komponente wird mit ***ET*** bezeichnet.
- **Urteile (judgements)**: Stimmen von Validatoren zu Streitigkeiten, die derzeit zwischen ihnen stattfinden. Dies wird mit ***EJ*** bezeichnet.
- **PrÃ¤bilder (preimages)**: Statische Daten, die derzeit angefordert werden, um fÃ¼r Arbeitslasten auf Abruf verfÃ¼gbar zu sein. Dies wird mit ***EP*** bezeichnet.
- **VerfÃ¼gbarkeit (availability)**: Zusicherungen jedes Validators bezÃ¼glich der Eingabedaten der Arbeitslasten, die sie korrekt erhalten und lokal speichern. Dies wird mit ***EA*** bezeichnet.
- **Berichte (reports)**: Berichte Ã¼ber neu abgeschlossene Arbeitslasten, deren Genauigkeit durch spezifische Validatoren garantiert wird. Dies wird mit ***EG*** bezeichnet.

### 4.2. Zustand
Unser Zustand kann logisch in mehrere weitgehend unabhÃ¤ngige Segmente unterteilt werden, was sowohl dazu beitragen kann, visuelle Unordnung in unserer Protokollbeschreibung zu vermeiden, als auch FormalitÃ¤t in Bezug auf Berechnungselemente zu bieten, die gleichzeitig berechnet werden kÃ¶nnen (d.h. parallelisiert). Wir stellen daher eine Ã„quivalenz zwischen ***Ïƒ*** (sigma) (einem vollstÃ¤ndigen Zustand) und einem Tupel von partitionierten Segmenten dieses Zustands fest:

</div>
<div align="center">
<img src="img/equation-15.PNG" width="700"/>
</div>

Zusammenfassend ist ***Î´*** (delta) der Teil des Zustands, der sich mit Diensten befasst, im JAM analog zu den (Smart Contract) Konten im Yellow Paper, dem einzigen Zustand des Yellow Paperâ€™s Ethereum. Die IdentitÃ¤ten der Dienste, die einen privilegierten Status haben, werden in ***Ï‡*** (chi) verfolgt.

Validatoren, die die Gruppe wirtschaftlicher Akteure sind, die einzigartig privilegiert sind, die JAM-Kette zu erstellen und zu pflegen, werden innerhalb von ***Îº*** (kappa) identifiziert, in ***Î»*** (lambda) archiviert und aus ***Î¹*** (iota) in die Warteschlange gestellt. Alle anderen ZustÃ¤nde, die sich auf die Bestimmung dieser SchlÃ¼ssel beziehen, werden innerhalb von ***Î³*** (gama) gehalten. Dies ist eine Abweichung von den stateless Proof-of-Work-Definitionen des Yellow Paper, bei denen diese Gruppe nicht aufgezÃ¤hlt, sondern auf diejenigen beschrÃ¤nkt war, die Ã¼ber ausreichende Rechenleistung verfÃ¼gten, um eine teilweise Hash-Kollision in der SHA2-256-Kryptografiefunktion zu finden. Ein On-Chain-Entropiepool wird in ***Î·*** (eta) beibehalten.

Unser Zustand verfolgt auch zwei Aspekte jedes Kerns: ***Î±*** (alpha), die Autorisierungsanforderung, die die auf diesem Kern durchgefÃ¼hrte Arbeit zum Zeitpunkt der On-Chain-Berichterstattung erfÃ¼llen muss, zusammen mit der Warteschlange, die dies ausfÃ¼llt, ***Ï†*** (phi); und ***Ï*** (rho), jeder der aktuell zugewiesenen Berichte (reports)  der Kerne (cores), deren ArbeitspaketverfÃ¼gbarkeit (work package availability) noch von einer Supermehrheit der Validatoren sichergestellt werden muss.

SchlieÃŸlich werden die Details der neuesten BlÃ¶cke und der Zeit jeweils in ***Î²*** (beta) und ***Ï„*** (tau)verfolgt und vergangene Urteile in ***Ïˆ*** (psi).

#### 4.2.1  ZustandsÃ¼bergangs-AbhÃ¤ngigkeitsgraph
Wie im Yellow Paper spezifizieren wir ***Î¥*** (ypsilon) als die Implikation, alle Elemente des nachfolgenden Zustands in Bezug auf den vorherigen Zustand und den Block zu formulieren. Um die Implementierung dieser Berechnung zu parallelisieren, minimieren wir die Tiefe des AbhÃ¤ngigkeitsgraphen, wo immer mÃ¶glich. Der gesamte AbhÃ¤ngigkeitsgraph wird hier spezifiziert:

</div>
<div align="center">
<img src="img/equation-16-22.PNG" width="700"/>
</div>
</div>
<div align="center">
<img src="img/equation-23-29.PNG" width="700"/>
</div>

Die einzigen synchronen Verflechtungen sind durch die Zwischenelemente sichtbar, die mit einem Dolch hochgestellt sind und in den Gleichungen 17, 24 und 26 definiert sind. Letztere markieren einen ZusammenfÃ¼hrungs- und VerknÃ¼pfungspunkt im AbhÃ¤ngigkeitsgraphen und implizieren konkret, dass das Preimage-Lookup-Extrinsic in den Zustand eingefÃ¼gt werden muss, bevor das VerfÃ¼gbarkeits-Extrinsic vollstÃ¤ndig verarbeitet werden kann und die Arbeitsakkumulation stattfinden kann.

### 4.3. Welche Vergangenheit?

Eine Blockchain ist eine Sequenz von BlÃ¶cken, die jeweils kryptografisch auf einen vorherigen Block verweisen, indem sie einen Hash ihres Headers enthalten, der bis zu einem ersten Block zurÃ¼ckreicht, der auf den Genesis-Header verweist. Wir gehen bereits von einem Konsens Ã¼ber diesen Genesis-Header H0 und den Zustand aus, den er darstellt, der bereits als Ïƒ0 definiert ist.

Indem wir eine deterministische Funktion zur Ableitung eines einzigen nachfolgenden Zustands fÃ¼r jede (gÃ¼ltige) Kombination aus vorherigem Zustand und Block definieren, sind wir in der Lage, einen eindeutigen kanonischen Zustand fÃ¼r jeden gegebenen Block zu definieren. Wir nennen den Block mit den meisten Vorfahren im Allgemeinen den Head und seinen Zustand den Headzustand. Es ist im Allgemeinen mÃ¶glich, dass zwei BlÃ¶cke gÃ¼ltig sind und dennoch auf den selben vorherigen Block verweisen, was als Fork bezeichnet wird. Dies impliziert die MÃ¶glichkeit von zwei verschiedenen Headern, jeder mit seinem eigenen Zustand. Obwohl wir keine MÃ¶glichkeit kennen, diese MÃ¶glichkeit strikt auszuschlieÃŸen, mÃ¼ssen wir dennoch versuchen, sie zu minimieren, damit das System nÃ¼tzlich ist. Wir streben daher an sicherzustellen, dass:

- (1) Es im Allgemeinen unwahrscheinlich ist, dass zwei Heads entstehen.
- (2) Wenn zwei Heads entstehen, diese schnell zu einem einzigen Head zusammengefÃ¼hrt werden.
- (3) Es mÃ¶glich ist, einen Block zu identifizieren, der nicht viel Ã¤lter ist als der Head, von dem wir Ã¤uÃŸerst sicher sein kÃ¶nnen, dass er dauerhaft Teil der Blockchain-Geschichte sein wird. Wenn ein Block als solcher identifiziert wird, nennen wir ihn finalisiert und diese Eigenschaft erstreckt sich natÃ¼rlich auf alle seine VorgÃ¤ngerblÃ¶cke.

Diese Ziele werden durch eine Kombination aus zwei Konsensmechanismen erreicht: Safrole, der die (nicht notwendigerweise Fork freie) Erweiterung der Blockchain regelt, und Grandpa, der die Finalisierung einer Erweiterung in die kanonische Geschichte regelt. Ersterer liefert Punkt 1, letzterer Punkt 3 und beide sind wichtig fÃ¼r die ErfÃ¼llung von Punkt 2. Wir beschreiben diese Teile des Protokolls ausfÃ¼hrlich in den Abschnitten 6 bzw. 18.

WÃ¤hrend Safrole Forks weitgehend einschrÃ¤nkt (durch Kryptografie, Wirtschaft und gemeinsame Zeit, siehe unten), kann es Zeiten geben, in denen wir absichtlich forken mÃ¶chten, da wir wissen, dass eine bestimmte KettenverlÃ¤ngerung zurÃ¼ckgesetzt werden muss. Im regulÃ¤ren Betrieb sollte dies niemals passieren, jedoch kÃ¶nnen wir die MÃ¶glichkeit von bÃ¶sartigen oder fehlerhaften Knoten nicht ausschlieÃŸen. Wir definieren daher eine solche Erweiterung als jede, die einen Block enthÃ¤lt, in dem Daten gemeldet werden, die von einem anderen Blockzustand als ungÃ¼ltig markiert wurden (siehe Abschnitt 10, wie dies erfolgt). Wir verlangen weiterhin, dass Grandpa keine Erweiterung finalisiert, die einen solchen Block enthÃ¤lt. Siehe Abschnitt 18 fÃ¼r weitere Informationen.

### 4.4. Zeit
Wir gehen von einem vorbestehenden Konsens Ã¼ber die Zeit aus, insbesondere fÃ¼r die Blockerstellung und -import. Obwohl dies keine Annahme von Polkadot war, existieren pragmatische und belastbare LÃ¶sungen, einschlieÃŸlich des NTP-Protokolls und Netzwerks. Wir nutzen diese Annahme auf nur eine Weise: Wir verlangen, dass BlÃ¶cke vorÃ¼bergehend ungÃ¼ltig sind, wenn ihr Zeitfenster in der Zukunft liegt. Dies wird im Detail in Abschnitt 6 spezifiziert.

Formal definieren wir die Zeit in Sekunden, die seit Beginn der JAM Common Era vergangen sind, 1200 UTC am 1. Januar 2024.**^8** Mittags CET wurde ausgewÃ¤hlt, um sicherzustellen, dass alle bedeutenden Zeitzonen am selben Datum bei jedem exakten 24-Stunden-Intervall ab Beginn der Common Era sind. Formal wird dieser Wert als T bezeichnet.

> **Footnotes:**
>
>**^8** 1.704.110.400 Sekunden nach der Unix-Epoche.

### 4.5. Bester Block
Bester Block. Angesichts der Anerkennung einer Anzahl gÃ¼ltiger BlÃ¶cke ist es notwendig zu bestimmen, welcher als der â€besteâ€œ Block behandelt werden sollte, was bedeutet, der jÃ¼ngste Block, von dem wir glauben, dass er letztendlich in allen zukÃ¼nftigen JAM-Ketten enthalten sein wird. Die einfachste und am wenigsten riskante Methode, dies zu tun, wÃ¤re, den GRANDPA-FinalitÃ¤tsmechanismus zu inspizieren, der in der Lage ist, einen Block bereitzustellen, fÃ¼r den es ein sehr hohes MaÃŸ an Vertrauen gibt, dass er ein Vorfahre jedes zukÃ¼nftigen Kettenkopfs bleibt.

Um jedoch das Risiko zu verringern, dass der resultierende Block letztendlich nicht in der kanonischen Kette enthalten ist, wird GRANDPA typischerweise einen Block zurÃ¼ckgeben, der ein kleines StÃ¼ck Ã¤lter ist als der zuletzt erstellte Block. (Existierende Implementierungen deuten darauf hin, dass es sich unter regulÃ¤rem Betrieb um etwa 1-2 BlÃ¶cke in der Vergangenheit handelt.) Es gibt oft UmstÃ¤nde, in denen wir eine geringere Latenz bei dem Risiko wÃ¼nschen, dass der zurÃ¼ckgegebene Block letztendlich nicht Teil der zukÃ¼nftigen kanonischen Kette wird. Zum Beispiel kÃ¶nnten wir in der Lage sein, einen Block zu erstellen, und wir mÃ¼ssen entscheiden, was sein Elternteil sein soll. Alternativ kÃ¶nnte es uns wichtig sein, Ã¼ber den aktuellsten Zustand zu spekulieren, um Informationen fÃ¼r eine nachgelagerte Anwendung bereitzustellen, die auf den Zustand von JAM angewiesen ist.

In diesen FÃ¤llen definieren wir den besten Block als den Head der besten Kette, die in Abschnitt 18 definiert ist.

### 4.6. Wirtschaft
Die vorliegende Arbeit beschreibt ein kryptoÃ¶konomisches System, d.h. eines, das Elemente der Kryptografie, Wirtschaft und Spieltheorie kombiniert, um einen selbstsouverÃ¤nen digitalen Dienst zu bieten. Um wirtschaftliche Anreize zu kodifizieren und zu manipulieren, definieren wir ein Token, das systemeigen ist und das wir in dieser Arbeit einfach als Tokens bezeichnen.

Ein Wert von Tokens wird im Allgemeinen als Guthaben (balance) bezeichnet, und ein solcher Wert wird als Mitglied der Menge der Guthaben (balance), ***NB***, bezeichnet, die genau der Menge der 64-Bit-unsigned-integers entspricht:

<div align="center">
<img src="img/equation-30.PNG" width="700"/>
</div>

Obwohl fÃ¼r die vorliegende Arbeit unerheblich, gehen wir davon aus, dass es eine standardisierte Bezeichnung fÃ¼r **10^9** Tokens gibt. Dies unterscheidet sich sowohl von Ethereum (das eine Bezeichnung von **10^18** verwendet), Polkadot (das eine Bezeichnung von **10^10** verwendet) als auch von Polkadots experimentellem Cousin Kusama (der **10^12** verwendet).

Die Tatsache, dass Guthaben als 64-Bit-Integer dargestellt werden, impliziert, dass es in JAM niemals mehr als etwa **18Ã—10^9** Tokens (jeweils in Teile von **10^âˆ’9** teilbar) geben kann. Wir wÃ¼rden erwarten, dass die Gesamtzahl der jemals ausgegebenen Tokens deutlich geringer sein wird.

Wir gehen auÃŸerdem davon aus, dass eine Anzahl konstanter Preise in Form von Tokens bekannt ist. Die spezifischen Werte werden jedoch in nachfolgender Arbeit bestimmt:

- ***BI***: Das zusÃ¤tzliche Mindestguthaben fÃ¼r ein einzelnes Element innerhalb einer Abbildung.
- ***BL***: Das zusÃ¤tzliche Mindestguthaben fÃ¼r ein einzelnes Oktett von Daten innerhalb einer Abbildung.
- ***BS***: Das Mindestguthaben fÃ¼r einen Dienst.

### 4.7. Die virtuelle Maschine und Gas.
In der vorliegenden Arbeit nehmen wir die Definition einer Polka Virtual Machine (***PVM***) an. Diese virtuelle Maschine basiert auf der RISC-V-Befehlssatzarchitektur, speziell der RV32EN-Variante, und ist die Grundlage fÃ¼r die EinfÃ¼hrung erlaubnisfreier Logik in unsere ZustandsÃ¼bergangsfunktion.

Die **PVM** ist vergleichbar mit der **EVM**, die im Yellow Paper definiert ist, aber etwas einfacher: Die komplexen Befehle fÃ¼r kryptografische Operationen fehlen ebenso wie diejenigen, die mit Umweltinteraktionen zu tun haben. Insgesamt ist sie weit weniger eigensinnig, da sie ein vorbestehendes, allgemeines Design, RISC-V, verÃ¤ndert und fÃ¼r unsere BedÃ¼rfnisse optimiert. Dies bietet uns hervorragende vorhandene Werkzeuge, da **PVM** im Wesentlichen mit RISC-V kompatibel bleibt, einschlieÃŸlich UnterstÃ¼tzung durch das Compiler-Toolkit LLVM und Sprachen wie Rust und C++. DarÃ¼ber hinaus macht die Einfachheit des Befehlssatzes, den RISC-V und **PVM** teilen, zusammen mit der RegistergrÃ¶ÃŸe (32-Bit), der aktiven Anzahl (13) und der Endianness (beschreibt die Reihenfolge, in der Bytes innerhalb eines mehrbytigen Datenelements gespeichert und verarbeitet werden) (little) (Least Significant Bytes, LSB) sie besonders gut geeignet fÃ¼r die Erstellung effizienter Rekompilierer auf gÃ¤ngige Hardwarearchitekturen.

Die **PVM** ist vollstÃ¤ndig in Anhang A definiert, aber zur Kontextualisierung werden wir kurz die grundlegende Aufruffunktion ***Î¨*** zusammenfassen, die den resultierenden Zustand einer **PVM**-Instanz berechnet, die mit einigen Registern (***âŸ¦NRâŸ§13***) und RAM (***M***) initialisiert wurde und bis zu einer bestimmten Menge an Gas (***NG***), einer Anzahl von ungefÃ¤hr zeitproportionalen Berechnungsschritten, ausgefÃ¼hrt wird:

<div align="center">
<img src="img/equation-31.PNG" width="700"/>
</div>

Wir bezeichnen die zeitproportionalen Berechnungsschritte als Gas (Ã¤hnlich wie im Yellow Paper) und begrenzen sie auf eine 64-Bit-Menge. Wir kÃ¶nnen entweder ***NG*** oder ***ZG*** verwenden, um es zu begrenzen, das erste als vorheriges Argument, da es als positiv bekannt ist, das letzte als Ergebnis, bei dem ein negativer Wert den Versuch anzeigt, das Gaslimit zu Ã¼berschreiten. Im Kontext der **PVM** wird ***Î¾ âˆˆ NG*** typischerweise verwendet, um Gas zu bezeichnen.

<div align="center">
<img src="img/equation-32.PNG" width="700"/>
</div>

Es bleibt ein wichtiges Implementierungsdetail sicherzustellen, dass die Zeit, die zur Berechnung der Funktion ***Î¨(..., Î¾, ...)*** benÃ¶tigt wird, ungefÃ¤hr proportional zum Wert von ***Î¾*** (xi) ist, unabhÃ¤ngig von anderen Operanden.

Die **PVM** ist eine sehr einfache RISC-Registermaschine und hat als solche 13 Register, von denen jedes ein 32-Bit-Integer ist, bezeichnet als NR.**^9** Im Kontext der **PVM** wird ***Ï‰ âˆˆ âŸ¦NRâŸ§13*** typischerweise verwendet, um die Register zu bezeichnen.

<div align="center">
<img src="img/equation-33.PNG" width="700"/>
</div>

> **Footnotes:**
>
>**^9** Dies sind drei weniger als die 16 von RISC-V, jedoch werden von Compilern ausgegebene Programmcode 13 verwendet, da zwei fÃ¼r die Betriebssystemnutzung reserviert sind und der dritte als Null festgelegt ist.

Die **PVM** nimmt einen einfachen seitenweise adressierbaren RAM von 32-Bit an, bei dem jedes Oktett entweder unverÃ¤nderlich, verÃ¤nderlich oder unzugÃ¤nglich sein kann. Die RAM-Definition **M** umfasst zwei Komponenten: einen Wert **V** und den Zugriff **A**. Wenn die Komponente beim Indizieren nicht spezifiziert ist, kann die Wertkomponente angenommen werden. Im Kontext der virtuellen Maschine wird ***Î¼ âˆˆ M*** typischerweise verwendet, um RAM zu bezeichnen.

<div align="center">
<img src="img/equation-34.PNG" width="700"/>
</div>

Wir definieren zwei Indexmengen fÃ¼r den RAM ***Î¼: VÎ¼*** ist die Menge der Indizes, die gelesen werden kÃ¶nnen; und ***V^âˆ— Î¼** ist die Menge der Indizes, die beschrieben werden kÃ¶nnen.

Der Aufruf der **PVM** hat einen Beendigungsgrund als erstes Element im resultierenden Tupel. Es ist entweder:

- RegulÃ¤re Programmbeendigung durch einen expliziten Halt-Befehl, **âˆ**.
- UnregelmÃ¤ÃŸige Programmbeendigung durch auÃŸergewÃ¶hnliche UmstÃ¤nde, **â˜‡**.
- ErschÃ¶pfung des Gases, **âˆ**.
- Ein Seitenfehler (Versuch, auf eine Adresse im RAM zuzugreifen, die nicht zugÃ¤nglich ist), **F**(umgekertes F). Dies umfasst die fehlerhafte Adresse.
- Ein Versuch, einen Host-Call fortzusetzen, Ìµ**h** . Dies ermÃ¶glicht die Fortschreibung und Integration einer kontextabhÃ¤ngigen Zustandsmaschine Ã¼ber die regulÃ¤re **PVM** hinaus.

Die vollstÃ¤ndige Definition folgt in Anhang A.

### 4.8. Epochen und Slots.
Im Gegensatz zum YP Ethereum mit seinem Proof-of-Work-Konsenssystem definiert JAM einen Proof-of-Authority-Konsensmechanismus, wobei die autorisierten Validatoren durch eine Menge Ã¶ffentlicher SchlÃ¼ssel identifiziert werden, die durch einen Staking-Mechanismus innerhalb eines von JAM gehosteten Systems entschieden werden. Das Staking-System liegt auÃŸerhalb des Umfangs dieser Arbeit; stattdessen gibt es eine API, die genutzt werden kann, um diese SchlÃ¼ssel zu aktualisieren, und wir gehen davon aus, dass die notwendige Logik fÃ¼r das Staking-System eingefÃ¼hrt wird und diese API nach Bedarf verwendet.

Der Safrole-Mechanismus unterteilt die Zeit nach der Genesis in Epochen mit fester LÃ¤nge, wobei jede Epoche in ***E = 600*** Timeslots mit einer einheitlichen LÃ¤nge von ***P = 6*** Sekunden unterteilt ist, was einer Epochenperiode von ***Eâ‹…P = 3600*** Sekunden oder einer Stunde entspricht. Diese sechssekÃ¼ndige Slotperiode stellt die Mindestzeit zwischen JAM-BlÃ¶cken dar, und durch Safrole zielen wir darauf ab, Forks sowohl aufgrund von Konkurrenz innerhalb eines Slots (wo zwei gÃ¼ltige BlÃ¶cke innerhalb desselben sechssekÃ¼ndigen Zeitraums produziert werden kÃ¶nnen) als auch aufgrund von Konkurrenz Ã¼ber mehrere Slots hinweg (wo zwei gÃ¼ltige BlÃ¶cke in verschiedenen Timeslots, aber mit demselben Elternblock produziert werden) streng zu minimieren.

Formal verwenden wir zur Identifizierung eines Timeslot-Indexes einen 32-Bit-Integer, der die Anzahl der sechssekÃ¼ndigen Timeslots seit der JAM Common Era angibt. FÃ¼r die Verwendung in diesem Kontext fÃ¼hren wir die Menge ***NT*** ein:

<div align="center">
<img src="img/equation-35.PNG" width="700"/>
</div>

Dies impliziert, dass die Lebensdauer des vorgeschlagenen Protokolls bis Mitte August des Jahres 2840 reicht, was mit dem aktuellen Verlauf der Menschheit reichlich bemessen sein sollte.

### 4.9. Das Kernmodell und die Services
WÃ¤hrend im Ethereum Yellow Paper bei der Definition der Zustandsmaschine, die unter allen Netzwerkteilnehmern im Konsens gehalten wird, davon ausgegangen wird, dass alle Maschinen den vollstÃ¤ndigen Netzwerkzustand aufrechterhalten und zu dessen VergrÃ¶ÃŸerung beitragen â€“ oder zumindest hoffen, dies zu tun â€“ und alle Berechnungen auswerten, verfolgen wir in JAM einen anderen Ansatz. Dieser â€jeder macht allesâ€œ-Ansatz kÃ¶nnte als On-Chain-Konsensmodell bezeichnet werden. Es ist leider nicht skalierbar, da das Netzwerk nur so viel Logik im Konsens verarbeiten kann, wie es hoffen kann, dass ein einzelner Knoten innerhalb eines gegebenen Zeitraums selbst ausfÃ¼hren kann.

#### 4.9.1. In-core-Konsens.
In der vorliegenden Arbeit erreichen wir die Skalierbarkeit der ausgefÃ¼hrten Arbeit durch die EinfÃ¼hrung eines zweiten Modells fÃ¼r solche Berechnungen, das wir das In-Core-Konsensmodell nennen. In diesem Modell ist unter normalen UmstÃ¤nden nur ein Teil des Netzwerks tatsÃ¤chlich dafÃ¼r verantwortlich, eine bestimmte Berechnung auszufÃ¼hren und die VerfÃ¼gbarkeit der Eingabedaten, auf die es angewiesen ist, fÃ¼r andere sicherzustellen. Durch diesen Ansatz und die Annahme eines gewissen MaÃŸes an paralleler Berechnung innerhalb der Validatorknoten des Netzwerks kÃ¶nnen wir die Menge der im Konsens durchgefÃ¼hrten Berechnungen proportional zur GrÃ¶ÃŸe des Netzwerks und nicht zur Rechenleistung eines einzelnen GerÃ¤ts skalieren. In der vorliegenden Arbeit erwarten wir, dass das Netzwerk in der Lage ist, mehr als das 300-fache der Menge an In-Core-Berechnungen durchzufÃ¼hren, die von einer einzelnen Maschine, die die virtuelle Maschine mit voller Geschwindigkeit ausfÃ¼hrt, durchgefÃ¼hrt werden kÃ¶nnte.

Da der In-Core-Konsens nicht von allen Knoten im Netzwerk evaluiert oder verifiziert wird, mÃ¼ssen wir andere Wege finden, um ausreichend Vertrauen in die Richtigkeit der Berechnungsergebnisse zu gewinnen und sicherzustellen, dass die zur Bestimmung dieser Ergebnisse verwendeten Daten fÃ¼r einen praktischen Zeitraum verfÃ¼gbar sind. Dies erreichen wir durch ein kryptoÃ¶konomisches Spiel in drei Stufen, genannt **Garantieren (guaranteeing,)**, **Sicherstellen (assuring,)**, **Auditing (auditing)** und gegebenenfalls **Urteilen (judging)**. Diese Stufen heften jeweils erhebliche wirtschaftliche Kosten an die UngÃ¼ltigkeit einer vorgeschlagenen Berechnung; dann ein ausreichendes MaÃŸ an Vertrauen, dass die Eingaben der Berechnung fÃ¼r einen bestimmten Zeitraum verfÃ¼gbar sein werden; und schlieÃŸlich ein ausreichendes MaÃŸ an Vertrauen, dass die GÃ¼ltigkeit der Berechnung (und damit die Durchsetzung der ersten Garantie) von einer Partei Ã¼berprÃ¼ft wird, von der wir erwarten kÃ¶nnen, dass sie ehrlich ist.

Alle im In-Core durchgefÃ¼hrten AusfÃ¼hrungen mÃ¼ssen von jedem Knoten reproduzierbar sein, der mit dem Teil der Kette synchronisiert ist, der finalisiert wurde. Die im In-Core durchgefÃ¼hrten AusfÃ¼hrungen sind daher so stateless wie mÃ¶glich gestaltet. Die Anforderungen dafÃ¼r umfassen nur den Verfeinerungscode (refinement code) des Dienstes, den Code des Autorisierers und alle wÃ¤hrend der AusfÃ¼hrung durchgefÃ¼hrten Preimage-Lookups.

Wenn ein Work Report On-Chain prÃ¤sentiert wird, wird ein spezifischer Block identifiziert, der als Lookup-Anker bekannt ist. Korrektes Verhalten erfordert, dass dieser Block in der finalisierten Kette und hinreichend aktuell sein muss, beide Eigenschaften, die bewiesen werden kÃ¶nnen und daher innerhalb eines Konsensprotokolls akzeptabel sind.

Wir beschreiben diese Pipeline im Detail in den relevanten Abschnitten spÃ¤ter.

#### 4.9.2 On Services und Accounts
Im YP Ethereum gibt es zwei Arten von Konten: Vertragskonten (deren Aktionen deterministisch basierend auf dem dem Konto zugeordneten Code und Zustand definiert sind) und einfache Konten, die als Gateways fÃ¼r Daten dienen, um in den Weltzustand zu gelangen und durch das Wissen um einen geheimen SchlÃ¼ssel kontrolliert werden. In JAM sind alle Konten Dienstkonten. Wie Ethereums Vertragskonten haben sie ein zugehÃ¶riges Guthaben, einige Codes und ZustÃ¤nde. Da sie nicht durch einen geheimen SchlÃ¼ssel kontrolliert werden, benÃ¶tigen sie keine Nonce.

Es stellt sich dann die Frage: Wie kÃ¶nnen externe Daten in den Weltzustand von JAM eingespeist werden? Und wie erfolgt die gesamte Zahlung, wenn nicht durch Abzug der Kontosalden derjenigen, die Transaktionen unterzeichnen? Die Antwort auf die erste Frage liegt in der Tatsache, dass unsere Dienstdefinition tatsÃ¤chlich mehrere Code-Einstiegspunkte umfasst, einer betrifft die Verfeinerung und der andere die Akkumulation. Ersterer fungiert als eine Art leistungsstarker stateless Prozessor, der beliebige Eingabedaten akzeptieren und in eine viel kleinere Menge an Ausgabedaten destillieren kann. Der letztere Code ist zustandsorientierter und bietet Zugriff auf bestimmte On-Chain-FunktionalitÃ¤ten, einschlieÃŸlich der MÃ¶glichkeit, Guthaben zu Ã¼bertragen und die AusfÃ¼hrung von Code in anderen Diensten zu veranlassen. Da er zustandsorientiert ist, kÃ¶nnte man sagen, dass er eher dem Code eines Ethereum-Vertragskontos entspricht.

Um zu verstehen, wie JAM seinen Dienstcode aufteilt, muss man das grundlegende Konzept von JAM bezÃ¼glich AllgemeingÃ¼ltigkeit und Skalierbarkeit verstehen. Alle extrinsischen Daten zu JAM werden in den Verfeinerungscode eines Dienstes eingespeist. Dieser Code wird nicht On-Chain ausgefÃ¼hrt, sondern soll In-Core ausgefÃ¼hrt werden. WÃ¤hrend der Akkumulatorcode denselben SkalierungsbeschrÃ¤nkungen wie die Vertragskonten von Ethereum unterliegt, wird der Verfeinerungscode Off-Chain ausgefÃ¼hrt und unterliegt keinen solchen BeschrÃ¤nkungen, was es JAM-Diensten ermÃ¶glicht, sowohl in der GrÃ¶ÃŸe ihrer Eingaben als auch in der KomplexitÃ¤t ihrer Berechnungen dramatisch zu skalieren.

WÃ¤hrend Verfeinerung und Akkumulation in Konsensumgebungen unterschiedlicher Natur stattfinden, werden beide von den Mitgliedern derselben Validatorengruppe ausgefÃ¼hrt. Das JAM-Protokoll stellt durch seine Belohnungen und Strafen sicher, dass der In-Core ausgefÃ¼hrte Code ein vergleichbares MaÃŸ an kryptoÃ¶konomischer Sicherheit wie der On-Chain ausgefÃ¼hrte Code hat, wobei der Hauptunterschied zwischen ihnen die Skalierbarkeit gegenÃ¼ber der SynchronitÃ¤t ist.

Was die Zahlungsabwicklung betrifft, so fÃ¼hrt JAM einen neuen Abstraktionsmechanismus ein, der auf Polkadots Agile Coretime basiert. Im Ethereum-Transaktionsmodell ist der Mechanismus der Kontoautorisierung etwas mit dem Mechanismus des Kaufs von Blockspace kombiniert, beide verlassen sich auf eine kryptografische Signatur, um ein einzelnes â€Transaktorâ€œ-Konto zu identifizieren. In JAM sind diese getrennt, und es gibt kein solches Konzept eines â€Transaktorsâ€œ.

Anstelle von Ethereums Gas-Modell zum Kauf und zur Messung von Blockspace hat JAM das Konzept der Coretime, die vorgekauft und einem Autorisierungsagenten zugewiesen wird. Coretime ist insofern analog zu Gas, als es die zugrunde liegende Ressource ist, die bei der Nutzung von JAM verbraucht wird. Ihre Beschaffung liegt auÃŸerhalb des Umfangs dieser Arbeit und wird voraussichtlich von einer System-Parachain verwaltet, die innerhalb eines Parachain-Dienstes betrieben wird und mit einer Anzahl von Kernen fÃ¼r das AusfÃ¼hren solcher Systemdienste ausgestattet ist. Der Autorisierungsagent ermÃ¶glicht externen Akteuren, Eingaben in einen Dienst zu liefern, ohne sich notwendigerweise identifizieren zu mÃ¼ssen, wie es bei Ethereums Transaktionssignaturen der Fall ist. Sie werden ausfÃ¼hrlich in Abschnitt 8 besprochen.

## 5. Header
Zuerst mÃ¼ssen wir den Header in Bezug auf seine Komponenten definieren. Der Header umfasst einen Eltern-Hash und den Wurzelhash des vorherigen Zustands (***Hp*** und ***Hr***), einen extrinsischen Hash ***Hx***, einen Timeslot-Index ***Ht***, die Epoche, Gewinn-Tickets und Urteilsmarker ***He***, ***Hw*** und ***Hj***, einen Bandersnatch-BlockautorschlÃ¼ssel ***Hk*** und zwei Bandersnatch-Signaturen; die entropieerzeugende VRF-Signatur ***Hv*** und ein Block-Siegel ***Hs***. Header kÃ¶nnen mit und ohne die letztgenannte Siegelkomponente in eine Oktettsequenz serialisiert werden, unter Verwendung von ***E*** bzw. ***EU***. Formal:

<div align="center">
<img src="img/equation-36.PNG" width="700"/>
</div>

BlÃ¶cke, die nach dieser Regel als ungÃ¼ltig betrachtet werden, kÃ¶nnen mit fortschreitender Zeit ***T*** gÃ¼ltig werden.
Die Blockchain ist eine Sequenz von BlÃ¶cken, die jeweils kryptografisch auf einen vorherigen Block verweisen, indem sie einen Hash enthalten, der aus dem Header des Elternblocks abgeleitet ist, bis hin zu einem ersten Block, der auf den Genesis-Header verweist. Wir gehen bereits von einem Konsens Ã¼ber diesen Genesis-Header ***H0*** und den von ihm reprÃ¤sentierten Zustand ***Ïƒ0*** aus.
Mit Ausnahme des Genesis-Headers haben alle Block-Header ***H*** einen zugehÃ¶rigen Eltern-Header, dessen Hash ***Hp*** ist. Wir bezeichnen den Eltern-Header ***H = P(H)***:

<div align="center">
<img src="img/equation-37.PNG" width="700"/>
</div>

***P*** wird somit als die Abbildung von einem Block-Header auf seinen Eltern-Block-Header definiert. Mit ***P*** kÃ¶nnen wir die Menge der Vorfahren-Header ***A*** definieren:

<div align="center">
<img src="img/equation-38.PNG" width="700"/>
</div>

Wir verlangen nur, dass Implementierungen die Header der Vorfahren speichern, die in den letzten ***L = 24*** Stunden vor jedem Block ***B*** erstellt wurden, den sie validieren mÃ¶chten.
Der extrinsische Hash ist der Hash der extrinsischen Daten des Blocks. Gegeben sei ein Block ***B = (H, E)***, dann formal:

<div align="center">
<img src="img/equation-39.PNG" width="700"/>
</div>

Ein Block kann nur als gÃ¼ltig angesehen werden, wenn der Timeslot-Index ***Ht*** in der Vergangenheit liegt. Er ist immer streng grÃ¶ÃŸer als der seines Elternteils. Formal:

<div align="center">
<img src="img/equation-40.PNG" width="700"/>
</div>

Die Wurzel des Elternzustands ***Hr*** ist die Wurzel eines Merkle-Tries, der durch die Abbildung der Merkle-Wurzel des vorherigen Zustands gebildet wird, die definitionsgemÃ¤ÃŸ auch der nachfolgende Zustand des Elternblocks ist. Dies ist eine Abweichung sowohl von Polkadot als auch vom Ethereums Yellow Paper, in denen der Header eines Blocks die Merkle-Wurzel des nachfolgenden Zustands enthÃ¤lt. Wir tun dies, um die Pipeline der Blockberechnung und insbesondere die Merklization zu erleichtern.

<div align="center">
<img src="img/equation-41.PNG" width="700"/>
</div>

Wir nehmen an, dass die Zustands-Merklization-Funktion ***MS*** in der Lage ist, unseren Zustand ***Ïƒ*** in eine 32-Oktett-Verpflichtung(comitment) zu transformieren. Siehe Anhang D fÃ¼r eine vollstÃ¤ndige Definition dieser beiden Funktionen.
Alle BlÃ¶cke haben einen zugehÃ¶rigen Ã¶ffentlichen SchlÃ¼ssel zur Identifizierung des Autors des Blocks. Wir identifizieren dies als einen Index in die aktuelle Validatormenge ***Îº***. Wir bezeichnen den ***Bandersnatch***-SchlÃ¼ssel des Autors als ***Ha***, weisen jedoch darauf hin, dass dies lediglich eine Ã„quivalenz ist und nicht als Teil des Headers serialisiert wird.

<div align="center">
<img src="img/equation-42.PNG" width="700"/>
</div>

### 5.1. Die Epoche und Gewinn-Tickets-Marker
Wenn nicht **âˆ…**, dann gibt der Epoch-Marker den SchlÃ¼ssel und die Entropie an, die fÃ¼r die folgende Epoche relevant sind, falls der Ticket-Wettbewerb nicht angemessen abgeschlossen wird (ein sehr unerwarteter Fall). Ebenso liefert der Gewinn-Tickets-Marker, falls nicht **âˆ…**, die Serie von 600 Slot-Versiegelungstickets fÃ¼r die nÃ¤chste Epoche (siehe nÃ¤chsten Abschnitt):

<div align="center">
<img src="img/equation-43.PNG" width="700"/>
</div>

Die Begriffe werden vollstÃ¤ndig in Abschnitt 6.6 definiert.

## 6. Blockproduktion und Kettenwachstum

Wie bereits erwÃ¤hnt, ist JAM um einen hybriden Konsensmechanismus herum aufgebaut, der dem Babe/Grandpa-Hybrid von Polkadot Ã¤hnelt. Der Blockproduktionsmechanismus von JAM, genannt Safrole, ist nach dem neuartigen Sassafras-Produktionsmechanismus benannt, von dem er eine vereinfachte Variante ist. Safrole ist ein zustandsbehaftetes System, das weitaus komplexer ist als der im YP beschriebene Nakamoto-Konsens.

Das Hauptziel eines Blockproduktions-Konsensmechanismus besteht darin, die Rate zu begrenzen, mit der neue BlÃ¶cke erstellt werden kÃ¶nnen, und idealerweise die MÃ¶glichkeit von "Forks" auszuschlieÃŸen: mehrere BlÃ¶cke mit gleicher Anzahl von Vorfahren.

Um dies zu erreichen, begrenzt Safrole den mÃ¶glichen Autor eines Blocks innerhalb eines bestimmten sechssekÃ¼ndigen Timeslots auf einen einzigen SchlÃ¼sselinhaber aus einer vordefinierten Gruppe von Validatoren. DarÃ¼ber hinaus bleibt unter normalen Betriebsbedingungen die IdentitÃ¤t des SchlÃ¼sselinhabers eines zukÃ¼nftigen Timeslots weitgehend anonym. Als Nebeneffekt seiner Funktionsweise kÃ¶nnen wir einen hochwertigen Entropiepool erzeugen, der von anderen Teilen des Protokolls genutzt werden kann und fÃ¼r darauf laufende Dienste zugÃ¤nglich ist.

Aufgrund seiner eng gefassten Rolle ist der Kern des Zustands von Safrole, Î³, unabhÃ¤ngig vom Rest des Protokolls. Es interagiert mit anderen Teilen des Protokolls durch Î¹ und Îº, die jeweiligen Gruppen von zukÃ¼nftigen und aktiven Validatorkeys; Ï„, dem Timeslot des neuesten Blocks; und Î·, dem Entropieakkumulator.

Das Safrole-Protokoll generiert einmal pro Epoche eine Sequenz von E Siegel-keys, einen fÃ¼r jeden potenziellen Block innerhalb einer ganzen Epoche. Jeder Blockheader enthÃ¤lt seinen Timeslot-Index Ht (die Anzahl der sechssekÃ¼ndigen Perioden seit Beginn der JAM Common Era) und eine gÃ¼ltige Siegelsignatur Hs, signiert vom Siegel-SchlÃ¼ssel, der dem Timeslot in der oben genannten Sequenz entspricht. Jeder Siegel-SchlÃ¼ssel ist in der Tat ein Pseudonym fÃ¼r einen Validator, dem das Privileg zugestanden wurde, einen Block im entsprechenden Timeslot zu erstellen.

Um diese Sequenz von Siegel-SchlÃ¼sseln zu erzeugen und insbesondere, um dies zu tun, ohne die Zuordnungsrelation zwischen ihnen und der Validatoren-Gruppe Ã¶ffentlich zu machen, verwenden wir eine neuartige kryptografische Struktur, bekannt als RingVRF, unter Verwendung der Bandersnatch-Kurve. Bandersnatch RingVRF ermÃ¶glicht den Nachweis, dass der Autor einen SchlÃ¼ssel innerhalb einer Gruppe kontrolliert (in unserem Fall Validatoren), und liefert zweitens eine Ausgabe, einen unbeeinflussbaren deterministischen Hash, der uns eine sichere verifizierbare zufÃ¤llige Funktion (VRF) bietet und als Mittel zur Bestimmung dient, welche Validatoren in welchen Slots autorisieren kÃ¶nnen.

### 6.1. Zeitmessung
Hier definiert ***Ï„*** den Slot-Index des neuesten Blocks, den wir auf den Slot-Index wie im Header des Blocks definiert Ã¼berfÃ¼hren:

<div align="center">
<img src="img/equation-44.PNG" width="700"/>
</div>

Wir verfolgen den Slot-Index im Zustand als ***Ï„***, um sowohl eine neue Epoche leicht identifizieren als auch den Slot bestimmen zu kÃ¶nnen, in dem der vorherige Block erstellt wurde. Wir bezeichnen ***e*** als den Epochenindex des vorherigen Blocks und ***m*** als den Slot-Phasenindex innerhalb dieser Epoche, wÃ¤hrend ***eâ€²*** und ***mâ€²*** die entsprechenden Werte fÃ¼r den aktuellen Block sind:

<div align="center">
<img src="img/equation-45.PNG" width="700"/>
</div>

### 6.2. Safrole Grundzustand
Wir unterteilen ***Î³*** in eine Anzahl von Komponenten:

<div align="center">
<img src="img/equation-46.PNG" width="700"/>
</div>

***Î³z*** ist die Wurzel der Epoche, eine Bandersnatch-Ring-Wurzel, die mit einem Bandersnatch-SchlÃ¼ssel jedes Validators der nÃ¤chsten Epoche zusammengesetzt ist, definiert in ***Î³k*** (selbst im nÃ¤chsten Abschnitt definiert).

<div align="center">
<img src="img/equation-47.PNG" width="700"/>
</div>

SchlieÃŸlich ist ***Î³a*** der Ticket-Akkumulator, eine Serie von hÃ¶chstbewerteten Ticket-Identifikatoren, die fÃ¼r die nÃ¤chste Epoche verwendet werden. ***Î³s*** ist die Slot-Sealer-Serie der aktuellen Epoche, die entweder eine vollstÃ¤ndige ErgÃ¤nzung von ***E*** Tickets oder, im Falle eines Fallback-Modus, eine Serie von ***E*** ***Bandersnatch***-SchlÃ¼sseln ist:

<div align="center">
<img src="img/equation-48.PNG" width="700"/>
</div>

Hier wird ***C*** verwendet, um die Menge der Tickets zu bezeichnen, eine Kombination aus einem verifizierbar zufÃ¤lligen Ticket-Identifikator ***y*** und dem Eintragsindex ***r***:

<div align="center">
<img src="img/equation-49.PNG" width="700"/>
</div>

Wie in Abschnitt 6.4 beschrieben, verlangt Safrole, dass jeder Blockheader ***H*** ein gÃ¼ltiges Siegel ***Hs*** enthÃ¤lt, das eine ***Bandersnatch***-Signatur fÃ¼r einen Ã¶ffentlichen SchlÃ¼ssel am entsprechenden Index ***m*** der aktuellen Epoche ist, die im Zustand als ***Î³s*** vorhanden ist.

### 6.3. SchlÃ¼sselrotation

ZusÃ¤tzlich zur aktiven Gruppe von Validatorkeys ***Îº*** und der Staging-Gruppe ***Î¹*** behalten wir intern im Safrole-Zustand eine ausstehende Gruppe ***Î³k***. Die aktive Gruppe ist die Menge der SchlÃ¼ssel, die die Knoten identifizieren, die derzeit das Privileg haben, BlÃ¶cke zu erstellen und die Validierungsprozesse durchzufÃ¼hren, wÃ¤hrend die ausstehende Gruppe ***Î³k***, die zu Beginn jeder Epoche auf ***Î¹*** zurÃ¼ckgesetzt wird, die Menge der SchlÃ¼ssel ist, die in der nÃ¤chsten Epoche aktiv sein werden und die die ***Bandersnatch***-Ringwurzel bestimmen, die Tickets in den Siegel-SchlÃ¼ssel-Wettbewerb fÃ¼r die nÃ¤chste Epoche autorisiert.

<div align="center">
<img src="img/equation-50.PNG" width="700"/>
</div>

Wir mÃ¼ssen ***K*** einfÃ¼hren, die Menge der Validator-SchlÃ¼ssel-Tupel. Dies ist eine Kombination aus kryptografischen Ã¶ffentlichen SchlÃ¼sseln fÃ¼r Bandersnatch- und Ed25519-Kryptografie und einem dritten Metadaten-SchlÃ¼ssel, der eine opake Oktettsequenz ist, aber zur Spezifizierung praktischer Identifikatoren fÃ¼r den Validator verwendet wird, nicht zuletzt einer Hardware-Adresse.

Die Menge der Validatorkeys selbst entspricht der Menge der 336-Oktett-Sequenzen. Aus GrÃ¼nden der Klarheit unterteilen wir die Sequenz jedoch in vier leicht benennbare Komponenten. FÃ¼r jeden Validatorkey ***v*** wird der Bandersnatch-SchlÃ¼ssel als ***vb*** bezeichnet und entspricht den ersten 32 Oktetten; der Ed25519-SchlÃ¼ssel, ***ve***, ist die zweiten 32 Oktette; der BLS-SchlÃ¼ssel, vBLS, ist den folgenden 144 Oktetten entsprechend, und schlieÃŸlich sind die Metadaten ***vm*** die letzten 128 Oktette. Formal:

<div align="center">
<img src="img/equation-51-55.PNG" width="700"/>
</div>

Mit einer neuen Epoche unter regulÃ¤ren Bedingungen werden Validatorkeys rotiert und die Bandersnatch-SchlÃ¼ssel-Wurzel der Epoche in ***Î³â€²z*** aktualisiert:

<div align="center">
<img src="img/equation-56.PNG" width="700"/>
</div>

Beachten Sie, dass die nachfolgende aktive Validatorkey-Gruppe ***Îºâ€²*** so definiert ist, dass SchlÃ¼ssel, die zur historischen Bestrafungsgruppe ***Ïˆâ€²p*** gehÃ¶ren, durch einen NullschlÃ¼ssel ersetzt werden, der nur Nullen enthÃ¤lt. Der Ursprung dieser Bestrafungsgruppe wird in Abschnitt 10 erlÃ¤utert.

### 6.4. Versiegelung und Entropieakkumulation
Der Header muss ein gÃ¼ltiges Siegel und eine gÃ¼ltige VRF-Ausgabe enthalten. Dies sind zwei Signaturen, die beide den aktuellen Siegel-SchlÃ¼ssel des Slots verwenden; die Nachrichtendaten des ersteren ist die Serialisierung des Headers ohne die Siegelkomponente ***Hs***, wÃ¤hrend letztere als bias-resistente Entropiequelle verwendet wird und daher ihre Nachricht bereits festgelegt sein muss: Wir verwenden die Entropie, die sich aus der VRF der Siegelsignatur ergibt. Formal:

<div align="center">
<img src="img/equation-57-62.PNG" width="700"/>
</div>

Das Versiegeln mit dem Ticket bietet eine hÃ¶here Sicherheit, und wir nutzen dieses Wissen bei der Bestimmung eines Kandidatenblocks zur Erweiterung der Kette, wie in Abschnitt 18 detailliert beschrieben. Wir stellen also fest, dass der Block unter regulÃ¤rer Sicherheit mit dem booleschen Marker ***T*** versiegelt wurde. Wir definieren dies nur zur Vereinfachung der spÃ¤teren Spezifikation.

ZusÃ¤tzlich zum Entropieakkumulator ***Î·0*** behalten wir drei weitere historische Werte des Akkumulators zum Zeitpunkt der drei zuletzt beendeten Epochen, ***Î·1***, ***Î·2*** und ***Î·3***. Der zweitÃ¤lteste davon, ***Î·2***, wird verwendet, um sicherzustellen, dass zukÃ¼nftige Entropie unbeeinflusst bleibt (siehe Gleichung 63) und um die Seal-Key-Generierungsfunktion mit ZufÃ¤lligkeit zu versehen (siehe Gleichung 66). Der Ã¤lteste wird verwendet, um diese ZufÃ¤lligkeit bei der ÃœberprÃ¼fung des Siegels oben neu zu erzeugen.

<div align="center">
<img src="img/equation-63.PNG" width="700"/>
</div>

***Î·0*** definiert den Zustand des Zufallsakkumulators, dem die nachweislich zufÃ¤llige Ausgabe der VRF, die Signatur Ã¼ber einen unbeeinflussbaren Input, bei jedem Block hinzugefÃ¼gt wird. ***Î·1*** und ***Î·2** behalten wÃ¤hrenddessen den Zustand dieses Akkumulators am Ende der beiden zuletzt beendeten Epochen bei.

<div align="center">
<img src="img/equation-64.PNG" width="700"/>
</div>

Bei einem EpochenÃ¼bergang (identifiziert durch die Bedingung ***eâ€² > e***) rotieren wir daher den Akkumulatorwert in die Geschichte ***Î·1***, ***Î·2*** und ***Î·3***:

<div align="center">
<img src="img/equation-65.PNG" width="700"/>
</div>

### 6.5. Die Slot-SchlÃ¼ssel-Sequenz
Die nachfolgende Slot-SchlÃ¼ssel-Sequenz ***Î³â€²s*** ist eine von drei AusdrÃ¼cken, abhÃ¤ngig von den UmstÃ¤nden des Blocks. Wenn der Block nicht der erste in einer Epoche ist, bleibt er unverÃ¤ndert gegenÃ¼ber dem vorherigen ***Î³s***. Wenn der Block die nÃ¤chste Epoche signalisiert (durch Epochenindex) und der Slot des vorherigen Blocks sich in der Schlussphase der vorherigen Epoche befand, nimmt er den Wert des vorherigen Ticket-Akkumulators ***Î³â€²a*** an. Andernfalls nimmt er den Wert der Fallback-SchlÃ¼ssel-Sequenz an. Formal:

<div align="center">
<img src="img/equation-66.PNG" width="700"/>
</div>

Hier verwenden wir ***Z*** als Inside-Out-Sequenzierungsfunktion, die wie folgt definiert ist:

<div align="center">
<img src="img/equation-67.PNG" width="700"/>
</div>

SchlieÃŸlich ist ***F*** die RÃ¼ckfall-SchlÃ¼ssel-Sequenz-Funktion, die eine Epoche von Validator Bandersnatch-SchlÃ¼sseln (***âŸ¦HBâŸ§E***) zufÃ¤llig aus der Validator-Key-Gruppe ***k*** unter Verwendung der On-Chain gesammelten Entropie ***r*** auswÃ¤hlt:

<div align="center">
<img src="img/equation-68.PNG" width="700"/>
</div>

### 6.6. Die Marker
Die Epoche und Gewinn-Tickets-Marker sind Informationen, die im Header platziert werden, um den notwendigen Datenverkehr zur Bestimmung der Validatorkeys einer beliebigen Epoche zu minimieren. Sie sind besonders nÃ¼tzlich fÃ¼r Knoten, die nicht den gesamten Zustand fÃ¼r einen bestimmten Block synchronisieren, da sie die sichere Nachverfolgung von Ã„nderungen an den Validatorkey-Gruppen nur mit der Header-Kette erleichtern.

Wie bereits erwÃ¤hnt, ist der Epoch-Marker He im Header entweder leer oder, wenn der Block der erste in einer neuen Epoche ist, ein Tupel aus der Epochen-ZufÃ¤lligkeit und einer Sequenz von Bandersnatch-SchlÃ¼sseln, die die Bandersnatch-Validatorkeys (***kb***) fÃ¼r die nÃ¤chste Epoche definieren. Formal:

<div align="center">
<img src="img/equation-69.PNG" width="700"/>
</div>

Der Gewinn-Tickets-Marker ***Hw*** ist entweder leer oder, wenn der Block der erste nach dem Ende der Einreichungsfrist fÃ¼r Tickets ist und der Ticket-Akkumulator gesÃ¤ttigt ist, dann die endgÃ¼ltige Sequenz von Ticket-Identifikatoren. Formal:

<div align="center">
<img src="img/equation-70.PNG" width="700"/>
</div>

Beachten Sie, dass dies nicht honoriert wird, wenn die nÃ¤chste Epoche mit einem Urteil in ihren extrinsischen Daten beginnt.

### 6.7. Die Extrinsischen Daten und Tickets
Die extrinsischen **ET** sind eine Sequenz von Nachweisen gÃ¼ltiger Tickets; ein Ticket impliziert einen Eintrag in unserem epochalen â€Wettbewerbâ€œ, um zu bestimmen, welche Validatoren das Privileg haben, einen Block fÃ¼r jeden Timeslot in der folgenden Epoche zu erstellen. Tickets geben einen temporÃ¤ren SchlÃ¼ssel und einen Eintragsindex an, die beide wÃ¤hlbar sind, zusammen mit einem Nachweis der GÃ¼ltigkeit des Tickets. Der Nachweis impliziert eine Ticket-IdentitÃ¤t, eine hoch-entropische unbeeinflussbare 32-Oktett-Sequenz, die sowohl als Punktzahl im oben genannten Wettbewerb als auch als Eingabe in die On-Chain VRF verwendet wird.

Gegen Ende der Epoche (d.h. ***Y*** Slots ab dem Beginn) wird dieser Wettbewerb geschlossen, was bedeutet, dass aufeinanderfolgende BlÃ¶cke innerhalb derselben Epoche keine Tickets extrinsisch enthalten dÃ¼rfen. Zu diesem Zeitpunkt wird die Siegel-SchlÃ¼ssel-Sequenz der folgenden Epoche festgelegt.

Wir definieren das Extrinsic als eine Sequenz von Nachweisen gÃ¼ltiger Tickets, von denen jedes ein Tupel aus einem Eintragsindex (eine natÃ¼rliche Zahl kleiner als ***N***) und einem Nachweis der GÃ¼ltigkeit des Tickets ist. Formal:

<div align="center">
<img src="img/equation-71-73.PNG" width="700"/>
</div>

Wir definieren ***n*** als die Menge neuer Tickets, wobei die Ticket-IdentitÃ¤t, ein Hash, als die Ausgangskomponente des Bandersnatch RingVRF-Nachweises definiert ist:

<div align="center">
<img src="img/equation-74.PNG" width="700"/>
</div>

Die Ã¼ber die Extrinsic eingereichten Tickets mÃ¼ssen bereits in der Reihenfolge ihrer implizierten IdentitÃ¤t angeordnet worden sein. Doppelte IdentitÃ¤ten sind niemals erlaubt, damit ein Validator nicht dasselbe Ticket mehrfach einreichen kann:

<div align="center">
<img src="img/equation-75-76.PNG" width="700"/>
</div>

Der neue Ticket-Akkumulator ***Î³â€²a*** wird konstruiert, indem neue Tickets in den vorherigen Akkumulatorwert (oder die leere Sequenz, wenn es sich um eine neue Epoche handelt) eingefÃ¼gt werden:

<div align="center">
<img src="img/equation-77.PNG" width="700"/>
</div>

Die maximale GrÃ¶ÃŸe des Ticket-Akkumulators ist ***E***. Bei jedem Block wird der Akkumulator zu den niedrigsten Elementen der sortierten Vereinigung von Tickets aus dem vorherigen Akkumulator ***Î³a*** und den eingereichten Tickets. Es ist ungÃ¼ltig, nutzlose Tickets in den Extrinsic einzuschlieÃŸen, daher mÃ¼ssen alle eingereichten Tickets in ihrem nachfolgenden Ticket-Akkumulator existieren. Formal:

<div align="center">
<img src="img/equation-78.PNG" width="700"/>
</div>

Beachten Sie, dass im Falle eines leeren Extrinsic ***ET = []***, wie durch ***mâ€² â‰¥ Y*** impliziert, ***Î³â€²a = Î³a***.

## 7. KÃ¼rzliche Historie
Wir speichern Informationen Ã¼ber die letzten **H** BlÃ¶cke im Zustand. Dies wird verwendet, um die MÃ¶glichkeit auszuschlieÃŸen, dass doppelte oder veraltete Arbeitsberichte eingereicht werden.

<div align="center">
<img src="img/equation-79.PNG" width="700"/>
</div>

FÃ¼r jeden kÃ¼rzlich blockieren wir seinen Header-Hash, seine State-Root, sein Akkumulationsergebnis **MMR** und den Hash jedes Arbeitsberichts, der darin erstellt wurde, wobei die Gesamtanzahl der Kerne (cores), ***C = 341**, nicht Ã¼berschritten wird.
WÃ¤hrend der Akkumulationsphase wird ein Wert mit der partiellen Transition dieses Zustands bereitgestellt, der das Update fÃ¼r die neu bekannten Wurzeln des Ã¼bergeordneten Blocks enthÃ¤lt:

<div align="center">
<img src="img/equation-80-81.PNG" width="700"/>
</div>

So erweitern wir die jÃ¼ngste Historie mit dem Header-Hash des neuen Blocks, der Akkumulationsergebnis-Merkelbaumwurzel und der Menge der darin erstellten Arbeitsberichte. Beachten Sie, dass die Akkumulationsergebnisbaumwurzel ***r*** aus ***C*** (definiert in Abschnitt 12) unter Verwendung der grundlegenden binÃ¤ren Merklisierung Funktion ***MS*** (definiert im Anhang F) abgeleitet und unter Verwendung der ***MMR***-AnhÃ¤ngenfunktion ***A*** (definiert in Anhang F.2) angehÃ¤ngt wird, um eine Merkle-Bergkette zu bilden.
Die Zustandsbaumwurzel wird als null Hash, ***H0***, betrachtet, was zwar am Endzustand des Blocks ***Î²â€²*** ungenau ist, aber dennoch sicher ist, da ***Î²â€²*** nicht verwendet wird, auÃŸer um den nÃ¤chsten Block ***Î²â€²â€²*** zu definieren, der einen korrigierten Wert fÃ¼r diesen enthÃ¤lt.

## 8. Autorisierung
Wir haben das Modell der Arbeitspakete und Dienstleistungen bereits in Abschnitt 4.9 besprochen, aber noch nicht genau erklÃ¤rt, wie eine bestimmte Kernzeitressource (core time ressource) einem Arbeitspaket und dessen zugehÃ¶rigem Dienst zugewiesen werden kann. Im YP-Ethereum-Modell wird die zugrunde liegende Ressource, Gas, beim On-Chain-EinfÃ¼hrungspunkt beschafft, und der KÃ¤ufer ist immer der gleiche Akteur, der die Daten erstellt, die die zu erledigende Arbeit beschreiben (d.h. die Transaktion). Im Gegensatz dazu wird im Polkadot-Modell die zugrunde liegende Ressource, ein Parachain-Slot, typischerweise fÃ¼r 24 Monate gegen eine betrÃ¤chtliche Einzahlung beschafft, und der Beschaffer, in der Regel ein Parachain-Team, hat oft keine direkte Beziehung zum Autor der zu erledigenden Arbeit (d.h. ein Parachain-Block).

Auf einem Prinzip der FlexibilitÃ¤t mÃ¶chten wir, dass JAM eine Reihe von Interaktionsmustern sowohl im Ethereum- als auch im Polkadot-Stil unterstÃ¼tzt. Um dies zu erreichen, fÃ¼hren wir das Autorisierungssystem ein, ein Mittel zur Entkopplung der Nutzungsabsicht fÃ¼r eine bestimmte Kernzeit von der Spezifikation und Einreichung einer bestimmten Arbeitslast, die darauf ausgefÃ¼hrt werden soll. Dadurch kÃ¶nnen wir den Kauf und die Zuweisung von Kernzeit von der spezifischen Bestimmung der darauf zu erledigenden Arbeit trennen und so sowohl Ethereum- als auch Polkadot-Interaktionsmuster unterstÃ¼tzen.

### 8.1. Authorizers und Authorisierungen
Das Autorisierungssystem umfasst zwei SchlÃ¼sselkonzepte: Authorizers und Authorisierungen. Eine Autorisierung ist einfach ein StÃ¼ck undurchsichtiger Daten, das mit einem Arbeitspaket enthalten ist. Ein Authorizer hingegen ist ein StÃ¼ck vorkonfigurierter Logik, das eine Autorisierung als zusÃ¤tzlichen Parameter akzeptiert und bei AusfÃ¼hrung innerhalb einer VM mit vorgegebenen Rechenlimits eine boolesche Ausgabe liefert, die die Richtigkeit der Autorisierung anzeigt.

Autorisierungen werden als Hash ihrer Logik (angegeben als VM-Code) und ihrer Vorkonfiguration identifiziert. Der Prozess, durch den Arbeitspakete als autorisiert (oder nicht) bestimmt werden, ist nicht die Kompetenz der On-Chain-Logik und erfolgt vollstÃ¤ndig intern und wird daher in Abschnitt 13.3 besprochen. Die On-Chain-Logik muss jedoch jede Gruppe von Authorizers identifizieren, die jedem Kern zugewiesen sind, um zu Ã¼berprÃ¼fen, ob ein Arbeitspaket berechtigt ist, diese Ressource zu nutzen. Dieses Subsystem werden wir nun definieren.

### 8.1. Pool und Warteschlange
Wir definieren die Gruppe der fÃ¼r einen bestimmten Kern ***c*** zulÃ¤ssigen Authorizers als den Authorizer-Pool ***Î±[c]***. Um diesen Wert zu erhalten, wird fÃ¼r jeden Kern ein weiterer Teil des Zustands verfolgt: die aktuelle Authorizer-Warteschlange ***Ï†[c]*** des Kerns, aus der wir Werte ziehen, um den Pool zu fÃ¼llen. Formal:

<div align="center">
<img src="img/equation-82.PNG" width="700"/>
</div>

Hinweis: Der Zustandsteil ***Ï†*** darf nur durch einen exogenen Aufruf geÃ¤ndert werden, der von der Akkumulationslogik eines entsprechend privilegierten Dienstes gemacht wird.
Die Zustandstransition eines Blocks beinhaltet das EinfÃ¼gen einer neuen Autorisierung in den Pool aus der Warteschlange:

<div align="center">
<img src="img/equation-83-84.PNG" width="700"/>
</div>

Da ***Î±â€²*** von ***Ï†â€²*** abhÃ¤ngt, muss dieser Schritt praktisch nach der Akkumulation berechnet werden, der Phase, in der ***Ï†â€²*** definiert wird.

## 9. Service Accounts
Wie bereits erwÃ¤hnt, ist ein Service in JAM in gewisser Weise analog zu einem Smart Contract in Ethereum, da er unter anderem eine Codekomponente, eine Speichereinheit und ein Guthaben umfasst. Im Gegensatz zu Ethereum ist der Code jedoch auf zwei isolierte Einstiegspunkte aufgeteilt, die jeweils ihre eigenen Umgebungsbedingungen haben; der eine, "refinement", ist im Wesentlichen zustandslos und erfolgt intern, der andere, "accumulation", ist zustandsbehaftet und erfolgt on-chain. Letzterer wird nun im Fokus stehen.
Servicekonten werden im Zustand unter ***Î´*** gehalten, einer partiellen Abbildung von einer Servicekennung ***NS*** in ein Tupel benannter Elemente, die die fÃ¼r das JAM-Protokoll relevanten Attribute des Services spezifizieren.
Formal:

<div align="center">
<img src="img/equation-85-86.PNG" width="700"/>
</div>

Das Servicekonto wird als Tupel des Speicherdictionaries ***s***, der Preimage-Lookup-Dictionaries ***p*** und ***l***, des Code-Hashes ***c*** und des Guthabens ***b*** sowie der beiden Code-Gaslimits ***g*** und ***m*** definiert. Formal:

<div align="center">
<img src="img/equation-87.PNG" width="700"/>
</div>

Somit wÃ¼rde das Guthaben des Services mit dem Index ***s*** als ***Î´[s]b*** und das Speicherelement des SchlÃ¼ssels ***k âˆˆ H*** fÃ¼r diesen Service als ***Î´[s]s [k]*** bezeichnet werden.

### 9.1. Code und Gas.
Der Code c eines Servicekontos wird durch einen Hash reprÃ¤sentiert, der, wenn der Service funktionsfÃ¤hig sein soll, in seinem Preimage-Lookup vorhanden sein muss (siehe Abschnitt 9.2). Wir definieren somit den tatsÃ¤chlichen Code ***c***:

<div align="center">
<img src="img/equation-88.PNG" width="700"/>
</div>

Es gibt drei Einstiegspunkte im Code:

- 0 **refine**: Verfeinerung, intern ausgefÃ¼hrt und zustandslos.**^10**
- 1 **accumulate**: Akkumulation, on-chain ausgefÃ¼hrt und zustandsbehaftet.
- 2 **on transfer**: Transfer-Handler, on-chain ausgefÃ¼hrt und zustandsbehaftet.

> **Footnotes:**
>
>**^10** Technisch gesehen gibt es eine kleine Annahme eines Zustands, nÃ¤mlich dass eine einigermaÃŸen aktuelle Instanz der PrÃ¤bilder jedes Dienstes vorhanden ist. Die Einzelheiten dazu werden in Abschnitt 13.3 besprochen.

WÃ¤hrend der erste, intern ausgefÃ¼hrte Punkt in Abschnitt 13.3 detaillierter beschrieben wird, werden die beiden anderen in diesem Abschnitt definiert.
Wie in Anhang A angegeben, wird die AusfÃ¼hrungszeit in der JAM-Virtual-Machine deterministisch in Gaseinheiten gemessen, die als 64-Bit-Integer formal als ***ZG*** bezeichnet werden. Es gibt zwei Limits, die im Konto angegeben sind: ***g***, das Mindestgas, das erforderlich ist, um den Akkumulations-Einstiegspunkt des Servicecodes auszufÃ¼hren, und ***m***, das Minimum, das fÃ¼r den Transfer-Einstiegspunkt erforderlich ist.

### 9.2. Preimage-Lookups 
ZusÃ¤tzlich zur Speicherung von Daten in beliebigen SchlÃ¼ssel/Wert-Paaren, die nur on-chain verfÃ¼gbar sind, kann ein Konto auch Daten anfordern, die auch intern verfÃ¼gbar gemacht werden sollen, und somit der Refine-Logik des Servicecodes zugÃ¤nglich sind. Der Zustand, der diese Funktion betrifft, wird unter den ***p***- und ***l***-Komponenten des Services gehalten.
Es gibt mehrere Unterschiede zwischen Preimage-Lookups und Speicher. Erstens agieren Preimage-Lookups als eine Abbildung von einem Hash zu seinem Preimage, wÃ¤hrend allgemeiner Speicher beliebige SchlÃ¼ssel zu Werten abbildet. Zweitens werden Preimage-Daten extrinsisch bereitgestellt, wÃ¤hrend Speicherdaten als Teil der Akkumulation des Services entstehen. Drittens kÃ¶nnen Preimage-Daten, einmal bereitgestellt, nicht frei entfernt werden; stattdessen durchlaufen sie einen Prozess, bei dem sie als nicht verfÃ¼gbar markiert werden und erst nach einer gewissen Zeit aus dem Zustand entfernt werden dÃ¼rfen. Dies stellt sicher, dass historische Informationen Ã¼ber ihre Existenz erhalten bleiben. Letzteres ist besonders wichtig, da Preimage-Daten zur internen Abfrage durch die Refine-Logik des Servicecodes entworfen wurden, und daher ist es wichtig, dass die historische VerfÃ¼gbarkeit des Preimages bekannt ist.
Wir beginnen mit der Neugestaltung des Teils des Zustands, der unser Daten-Lookup-System betrifft. Der Zweck dieses Systems besteht darin, eine MÃ¶glichkeit zu bieten, statische Daten on-chain zu speichern, sodass sie spÃ¤ter innerhalb der AusfÃ¼hrung eines beliebigen Servicecodes verfÃ¼gbar gemacht werden kÃ¶nnen, als Funktion, die nur den Hash der Daten und deren LÃ¤nge in Oktetten akzeptiert.
WÃ¤hrend der on-chain AusfÃ¼hrung der Akkumulationsfunktion ist dies trivial zu erreichen, da es einen Zustand gibt, den alle Validatoren, die den Block verifizieren, notwendigerweise vollstÃ¤ndig kennen, nÃ¤mlich ***Ïƒ***. FÃ¼r die interne AusfÃ¼hrung von Refine gibt es jedoch keinen solchen Zustand, der allen Validatoren inhÃ¤rent verfÃ¼gbar ist; wir benennen daher einen historischen Zustand, den Lookup-Anker, der kÃ¼rzlich als finalisiert betrachtet werden muss, bevor das Arbeitsergebnis akkumuliert wird, und somit diese Garantie bietet.
Indem wir historische Informationen Ã¼ber seine VerfÃ¼gbarkeit beibehalten, sind wir zuversichtlich, dass jeder Validator mit einer kÃ¼rzlich finalisierten Ansicht der Kette bestimmen kann, ob ein bestimmtes Preimage zu irgendeinem Zeitpunkt innerhalb des Zeitraums, in dem eine ÃœberprÃ¼fung stattfinden kann, verfÃ¼gbar war. Dies stellt sicher, dass die Urteile deterministisch sind, auch ohne Konsens Ã¼ber den Kettenzustand.
Zusammengefasst, wir mÃ¼ssen in der Lage sein, eine historische Lookup-Funktion ***Î›*** zu definieren, die bestimmt, ob das Preimage eines bestimmten Hashs ***h*** zu einem bestimmten Zeitpunkt ***t*** fÃ¼r einen bestimmten Service-Account ***a*** verfÃ¼gbar war und, falls ja, sein Preimage bereitstellt:

<div align="center">
<img src="img/equation-89.PNG" width="700"/>
</div>

Diese Funktion wird kurz unten in Gleichung 91 definiert.
Das Preimage-Lookup fÃ¼r einen Service mit dem Index s wird als ***Î´[s]p*** bezeichnet und ist ein Dictionary, das einen Hash zu seinem entsprechenden Preimage abbildet. ZusÃ¤tzlich gibt es Metadaten, die mit dem Lookup verbunden sind, bezeichnet als ***Î´[s]l***, ein Dictionary, das einen Hash und eine vorausgesetzte LÃ¤nge in historische Informationen abbildet.

#### 9.2.1. Invarianten
Der Zustand des Lookup-Systems erfÃ¼llt natÃ¼rlicherweise eine Reihe von Invarianten. Erstens muss jeder Preimage-Wert seinem Hash entsprechen, wie in Gleichung 90 dargestellt. Zweitens impliziert das Vorhandensein eines Preimage-Wertes im Zustand, dass sein Hash und LÃ¤ngenpaar einen zugehÃ¶rigen Status haben, ebenfalls in Gleichung 90 dargestellt. Formal:

<div align="center">
<img src="img/equation-90.PNG" width="700"/>
</div>

#### 9.2.2. Semantik
Die historische Statuskomponente h âˆˆ [NT]âˆ¶3 ist eine Sequenz von bis zu drei Zeitschlitzen, und die KardinalitÃ¤t dieser Sequenz impliziert einen von vier Modi:

- ***h = []***: Das Preimage wird angefordert, wurde aber noch nicht bereitgestellt.
- ***h âˆˆ âŸ¦NTâŸ§1***: Das Preimage ist verfÃ¼gbar und war es seit Zeitpunkt ***h0***.
- ***h âˆˆ âŸ¦NTâŸ§2***: Das zuvor verfÃ¼gbare Preimage ist seit Zeitpunkt ***h1*** nicht mehr verfÃ¼gbar. Es war von Zeitpunkt ***h0*** bis ***h1*** verfÃ¼gbar.
- ***h âˆˆ âŸ¦NTâŸ§3***: Das Preimage ist verfÃ¼gbar und war es seit Zeitpunkt ***h2***. Es war zuvor von Zeitpunkt h0 bis ***h1*** verfÃ¼gbar.
Die historische Lookup-Funktion ***Î›*** kann nun wie folgt definiert werden:

<div align="center">
<img src="img/equation-91.PNG" width="700"/>
</div>

### 9.3. KontofuÃŸabdruck und Schwellenwertguthaben (Account Footprint and Threshold Balance.)
Wir definieren die abhÃ¤ngigen Werte ***i*** und ***l*** als den SpeicherfuÃŸabdruck des Services, speziell die Anzahl der Elemente im Speicher und die Gesamtzahl der verwendeten Oktette im Speicher. Diese werden ausschlieÃŸlich anhand der Speicherkarte eines Services definiert, und es muss angenommen werden, dass sich diese Ã¤ndern, wann immer der Speicher eines Services geÃ¤ndert wird.

Des Weiteren, wie wir in der Kontoserialisierungsfunktion in Abschnitt C sehen werden, wird erwartet, dass diese explizit innerhalb der Merklisierten Zustandsdaten gefunden werden. Aus diesem Grund machen wir ihre Menge explizit.

Wir kÃ¶nnen dann einen zweiten abhÃ¤ngigen Term ***t*** definieren, das minimale oder Schwellenwertguthaben, das fÃ¼r ein gegebenes Servicekonto in Bezug auf seinen SpeicherfuÃŸabdruck erforderlich ist.

<div align="center">
<img src="img/equation-92.PNG" width="700"/>
</div>

### 9.4. Serviceprivilegien
Bis zu drei Services kÃ¶nnen als privilegiert anerkannt werden. Der Zustandsteil, in dem dies gehalten wird, wird als ***Ï‡*** bezeichnet und hat drei Komponenten, jeweils einen Service-Index. ***m*** ist der Index des Managerservices, des Services, der in der Lage ist, eine Ã„nderung von ***Ï‡*** von Block zu Block zu bewirken. ***a*** und ***v*** sind jeweils die Indizes von Services, die in der Lage sind, ***Ï†*** und ***Î¹*** von Block zu Block zu Ã¤ndern. Formal:

<div align="center">
<img src="img/equation-93.PNG" width="700"/>
</div>

## 10. Urteile (judgements)
JAM bietet eine MÃ¶glichkeit, eine Abstimmung unter allen Validatoren Ã¼ber die GÃ¼ltigkeit eines Arbeitsberichts, einer im Rahmen von JAM geleisteten Arbeitseinheit, aufzuzeichnen (fÃ¼r nÃ¤here Informationen zur Natur eines Arbeitsberichts siehe Abschnitt 11). Eine solche Abstimmung wird in der Praxis nicht oft (wenn Ã¼berhaupt) erwartet, jedoch ist sie eine wichtige SicherheitsmaÃŸnahme, die es ermÃ¶glicht, problematische SchlÃ¼ssel kurzfristig aus dem Validatorenset zu entfernen, wenn ein Konsens Ã¼ber deren Fehlfunktion besteht. Sie hilft auch dabei, die FÃ¤higkeit zu koordinieren, nicht finalisierte KettenverlÃ¤ngerungen rÃ¼ckgÃ¤ngig zu machen und durch eine VerlÃ¤ngerung zu ersetzen, die keinen ungÃ¼ltigen Arbeitsbericht enthÃ¤lt.
Im Allgemeinen werden Urteilsdaten als Ergebnis eines Streits zwischen Validatoren entstehen, ein off-chain Prozess, der in Abschnitt 10 beschrieben wird. Ein Urteil gegen einen Bericht impliziert, dass die Kette auf unmittelbar vor der Akkumulation dieses Berichts zurÃ¼ckgesetzt wird. Das Urteil on-chain zu stellen, hat den Effekt, seine Akkumulation zu annullieren. Die spezifische Strategie zur Kettenauswahl wird vollstÃ¤ndig in Abschnitt 18 beschrieben.
Falls eine ausreichende Anzahl von Validator-Knoten ein Urteil in ***EJ*** abgeben, wird ein indizierter Bericht dieses Urteils on-chain gestellt (in ***Ïˆ***, dem Zustandsteil, der Streiturteile behandelt).
Ein persistenter on-chain Bericht ist in mehrfacher Hinsicht hilfreich. Erstens bietet er eine sehr einfache MÃ¶glichkeit, die UmstÃ¤nde zu erkennen, unter denen MaÃŸnahmen gegen einen Validator ergriffen werden mÃ¼ssen, durch eine hÃ¶here Ebene der Validatorauswahl-Logik. Sollte JAM fÃ¼r ein Ã¶ffentliches Netzwerk wie Polkadot verwendet werden, wÃ¼rde dies das Streichen des Einsatzes des fehlbaren Validators auf der Staking-Parachain bedeuten.
Wie erwÃ¤hnt, ist es wichtig, Berichte mit hoher Sicherheit auf UngÃ¼ltigkeit zu erfassen, um sicherzustellen, dass diese Berichte nicht erneut eingereicht werden dÃ¼rfen. Umgekehrt stellt die Erfassung von Berichten, die als gÃ¼ltig befunden wurden, sicher, dass in der Zukunft der Kette keine weiteren Streitigkeiten erhoben werden kÃ¶nnen.

### 10.1. Zustand (State)
Der Urteilszustand umfasst drei Elemente: ein Allow-Set (***Ïˆa***), ein Ban-Set (***Ïˆb***) und ein Punish-Set (***Ïˆp***). Das Allow-Set enthÃ¤lt die Hashes aller Arbeitsberichte, die bestritten und als genau beurteilt wurden. Das Ban-Set enthÃ¤lt die Hashes aller Arbeitsberichte, die bestritten wurden und deren Genauigkeit nicht mit Sicherheit bestÃ¤tigt werden konnte. Das Punish-Set ist eine Menge von SchlÃ¼sseln von Bandersnatch-SchlÃ¼sseln, die garantiert einen Bericht unterstÃ¼tzt haben, der mit Sicherheit als ungÃ¼ltig befunden wurde.

<div align="center">
<img src="img/equation-94-95.PNG" width="700"/>
</div>

### 10.2. Extrinsisch (Extrinsic)
Das Urteilsextrinsische, ***EJ***, kann ein oder mehrere Urteile als eine Zusammenstellung von Signaturen enthalten, die von genau zwei Dritteln plus eins entweder des aktiven Validatorensets (d.h. der Ed25519-SchlÃ¼ssel von ***Îº***) oder des Validatorensets der vorherigen Epoche (d.h. die SchlÃ¼ssel von ***Ïˆk***) stammen:

<div align="center">
<img src="img/equation-96.PNG" width="700"/>
</div>

Alle Signaturen mÃ¼ssen in Bezug auf eines der beiden erlaubten ValidatorenschlÃ¼ssel-Sets gÃ¼ltig sein. Beachten Sie, dass die SchlÃ¼ssel-Sets der beiden Epochen nicht gemischt werden dÃ¼rfen! Formal:

<div align="center">
<img src="img/equation-97.PNG" width="700"/>
</div>

Urteile mÃ¼ssen nach Berichtshash sortiert werden und es dÃ¼rfen keine doppelten Berichtshashes innerhalb des Extrinsischen oder unter allen vergangenen berichteten Hashes vorhanden sein. Formal:

<div align="center">
<img src="img/equation-98-99.PNG" width="700"/>
</div>

Die Stimmen aller Urteile mÃ¼ssen nach Validatorindex sortiert werden und es dÃ¼rfen keine doppelten Indizes vorhanden sein. Formal:

<div align="center">
<img src="img/equation-100.PNG" width="700"/>
</div>

Wir definieren ***J*** als die Sequenz der in den Extrinsischen eingefÃ¼hrten Urteile (und entsprechend sortiert), mit der Sequenz der Signaturen, die durch die Summe der Stimmen Ã¼ber die Signaturen ersetzt wird. Wir verlangen, dass diese Summe genau null, zwei Drittel plus eins oder ein Drittel plus eins des Validatorensets ist, was jeweils darauf hinweist, dass wir sicher sind, dass der Bericht gÃ¼ltig ist, sicher, dass er ungÃ¼ltig ist, oder dass uns die Sicherheit in beiden FÃ¤llen fehlt. Diese Anforderung mag willkÃ¼rlich erscheinen, aber dies sind die Entscheidungsschwellen fÃ¼r unsere drei mÃ¶glichen Aktionen und sind akzeptabel, da die Sicherheitsannahmen die Anforderung umfassen, dass mindestens zwei Drittel plus ein Validator aktiv sind (stewart2018efficient diskutiert die Sicherheitsimplikationen ausfÃ¼hrlich).
Formal:

<div align="center">
<img src="img/equation-101-103.PNG" width="700"/>
</div>

Beachten Sie, dass ***t*** die Schwelle der Urteile ist, dass der Bericht gÃ¼ltig ist, berechnet durch Summieren von Booleschen Werten in ihrer impliziten Ã„quivalenz zu BinÃ¤rziffern der Menge ***N2***.
Wir lÃ¶schen alle Arbeitsberichte, die als ungÃ¼ltig beurteilt wurden, aus ihrem Kern:

<div align="center">
<img src="img/equation-104.PNG" width="700"/>
</div>

Das Allow-Set nimmt die Hashes aller Berichte auf, die wir als gÃ¼ltig beurteilen. Das Ban-Set nimmt alle anderen beurteilten Berichtshashes auf. SchlieÃŸlich akkumuliert das Punish-Set die GarantieschlÃ¼ssel aller Berichte, die als ungÃ¼ltig beurteilt wurden:

<div align="center">
<img src="img/equation-105-107.PNG" width="700"/>
</div>

Beachten Sie, dass das erweiterte Punish-Set verwendet wird, um ***Îºâ€²*** zu bestimmen, um alle ValidatorschlÃ¼ssel, die in der Punish-Liste erscheinen, zu nullifizieren.

### 10.3. Header
Der Urteilsmarker muss genau die Sequenz der Berichtshashes enthalten, die nicht als eindeutig gÃ¼ltig beurteilt wurden (d.h. entweder umstritten oder ungÃ¼ltig). Formal:

<div align="center">
<img src="img/equation-108.PNG" width="700"/>
</div>

## 11. Berichterstattung und Sicherung  (Reporting and Assurance)
Berichterstattung und Sicherung sind die beiden On-Chain-Prozesse, die wir verwenden, um die Ergebnisse der internen Berechnung in den Servicezustand-Singleton, ***Î´***, zu Ã¼bertragen. Ein Arbeitspaket, das mehrere Arbeitselemente umfasst, wird von Validatoren, die als BÃ¼rgen agieren, in den entsprechenden Arbeitsbericht umgewandelt, der ebenfalls mehrere Arbeitsausgaben umfasst und dann On-Chain innerhalb der Garantieextrinsik prÃ¤sentiert wird. Zu diesem Zeitpunkt wird das Arbeitspaket in zahlreiche Segmente aufgeteilt und jedes Segment an den zugehÃ¶rigen Validator verteilt, der dann seine VerfÃ¼gbarkeit durch eine On-Chain-Sicherung bestÃ¤tigt. Nach entweder ausreichenden Sicherungen oder einem Timeout (je nachdem, was zuerst eintritt), wird der Arbeitsbericht als verfÃ¼gbar betrachtet und die Arbeitsergebnisse verÃ¤ndern den Zustand des zugehÃ¶rigen Dienstes durch Akkumulation, die in Abschnitt 12 behandelt wird.

Aus der Perspektive des Arbeitsberichts erfolgt daher die Garantie zuerst und die Sicherung danach. Aus der Perspektive der Zustandstransition eines Blocks ist es jedoch am besten, die Sicherungen zuerst zu verarbeiten, da jeder Kern zu einem Zeitpunkt nur einen einzigen Arbeitsbericht haben kann, dessen Paket verfÃ¼gbar wird. Daher werden wir zunÃ¤chst die Transition behandeln, die sich aus der Verarbeitung der VerfÃ¼gbarkeitssicherungen ergibt, gefolgt von den Arbeitsberichtsgarantien. Diese SynchronitÃ¤t kann formal durch die Anforderung eines Zwischenzustands ***Ï(+)*** gesehen werden, der spÃ¤ter in Gleichung 136 verwendet wird.

### 11.1. Zustand (State)
Der Zustand des Berichterstattungs- und VerfÃ¼gbarkeitsteils des Protokolls ist grÃ¶ÃŸtenteils in ***Ï*** enthalten, das die Arbeitsberichte verfolgt, die gemeldet, aber noch nicht akkumuliert wurden, sowie die IdentitÃ¤ten der BÃ¼rgen, die sie gemeldet haben, und die Zeit, zu der sie gemeldet wurden. Wie bereits erwÃ¤hnt, darf zu einem bestimmten Zeitpunkt nur ein Bericht einem Kern zugewiesen werden. Formal:

<div align="center">
<img src="img/equation-109.PNG" width="700"/>
</div>

Wie Ã¼blich werden Zwischen- und nachfolgende Werte ***(Ï(+)***, ***Ï(++)***, ***Ïâ€²***) unter den gleichen EinschrÃ¤nkungen wie der vorherige Wert gehalten.

#### 11.1.1 Arbeitsbericht (Work Report)
Ein Arbeitsbericht, aus der Menge ***W***, wird als ein Tupel aus Autorisierungshash ***a*** und Ausgabe ***o***, dem Verfeinerungskontext ***x***, der Paketspezifikation ***s*** und den Ergebnissen der Auswertung jedes Elements im Paket ***r*** definiert, das immer mindestens ein Element und hÃ¶chstens ***I*** Elemente umfassen darf. Formal:

<div align="center">
<img src="img/equation-110.PNG" width="700"/>
</div>

Die GesamtgrÃ¶ÃŸe eines Arbeitsberichts darf ***WR*** Bytes nicht Ã¼berschreiten:

<div align="center">
<img src="img/equation-111.PNG" width="700"/>
</div>

#### 11.1.2 Verfeinerungskontext (Refinement Context)
Ein Verfeinerungskontext, bezeichnet durch die Menge ***X***, beschreibt den Kontext der Kette zu dem Zeitpunkt, an dem das entsprechende Arbeitspaket des Berichts ausgewertet wurde. Er identifiziert zwei historische BlÃ¶cke, den Anker, den Header-Hash ***a*** zusammen mit seinem zugehÃ¶rigen nachfolgenden Zustand-Root ***s*** und dem nachfolgenden Beefy-Root ***b***; und den Lookup-Anker, den Header-Hash ***l*** und den Zeitschlitz ***t***. SchlieÃŸlich identifiziert er den Hash eines optionalen vorausgesetzten Arbeitspakets ***p***. Formal:

<div align="center">
<img src="img/equation-112.PNG" width="700"/>
</div>

#### 11.1.3 VerfÃ¼gbarkeit (Availability.)
Wir definieren die Menge der VerfÃ¼gbarkeitsspezifikationen, S, als das Tupel aus dem hash h und der LÃ¤nge l des Ã¼berprÃ¼fbaren Arbeitspakets zusammen mit einem Erasure-Root u und einem Segment-Root e. Arbeitsergebnisse umfassen die VerfÃ¼gbarkeitsspezifikation fÃ¼r die Kodierung des entsprechenden Arbeitspakets. Formal:

<div align="center">
<img src="img/equation-113.PNG" width="700"/>
</div>

Das Erasure-Root (***u***) ist der Root eines binÃ¤ren Merkle-Baums, der als Verpflichtung zu allen im Audit ***DA*** und im Imports ***DA*** gespeicherten DatenblÃ¶cken in Bezug auf diesen Arbeitsbericht (und die Auswirkungen seines entsprechenden Arbeitspakets) dient. Es wird von Sicherstellern verwendet, um die Korrektheit der verteilten Daten zu Ã¼berprÃ¼fen, die von PrÃ¼fern sichergestellt wurden. Es wird in Abschnitt 13 ausfÃ¼hrlich besprochen.
Das Segment-Root (***e***) ist der Root eines konstant tiefen, linksgerichteten und null-hash-gefÃ¼llten binÃ¤ren Merkle-Baums, der sich zu den Hashes jedes exportierten Segments jedes Arbeitselements verpflichtet. Diese werden von BÃ¼rgen verwendet, um die Korrektheit aller rekonstruierten Segmente zu Ã¼berprÃ¼fen, die sie zur Bewertung eines spÃ¤teren Arbeitspakets importieren sollen. Es wird ebenfalls in Abschnitt 13 besprochen.

#### 11.1.4 Arbeitsergebnis (Work Result)
Wir kommen schlieÃŸlich dazu, ein Arbeitsergebnis, ***L***, zu definieren, welches das Datenleitungswerkzeug ist, durch das der Zustand der Dienste durch die innerhalb eines Arbeitspakets durchgefÃ¼hrte Berechnung geÃ¤ndert werden kann.

<div align="center">
<img src="img/equation-114.PNG" width="700"/>
</div>

Arbeitsergebnisse sind ein Tupel, das mehrere Elemente umfasst. Erstens ***s***, der Index des Dienstes, dessen Zustand geÃ¤ndert werden soll und dessen Refinement-Code bereits ausgefÃ¼hrt wurde. Wir fÃ¼gen den Hash des Codes des Dienstes zum Zeitpunkt der Berichterstattung hinzu, ***c***, der gemÃ¤ÃŸ Gleichung ***146*** genau vorhergesagt werden muss.
Als nÃ¤chstes folgt der Hash der Nutzlast (***l***) innerhalb des Arbeitselements, das in der Refinement-Phase ausgefÃ¼hrt wurde, um dieses Ergebnis zu erzielen. Dies hat keine unmittelbare Relevanz, wird aber der Akkumulationslogik des Dienstes zur VerfÃ¼gung gestellt. AnschlieÃŸend folgt das Gas-PriorisierungsverhÃ¤ltnis ***g***, das bei der Bestimmung verwendet wird, wie viel Gas fÃ¼r die AusfÃ¼hrung dieses Elements akkumuliert werden soll.
SchlieÃŸlich gibt es die Ausgabe oder den Fehler der CodeausfÃ¼hrung ***o***, der entweder eine Oktettfolge ist, falls erfolgreich, oder ein Mitglied der Menge J, falls nicht. Letztere Menge ist als die Menge mÃ¶glicher Fehler definiert, formal:

<div align="center">
<img src="img/equation-115.PNG" width="700"/>
</div>

Die ersten beiden sind spezielle Werte bezÃ¼glich der AusfÃ¼hrung der virtuellen Maschine, ***âˆ*** bedeutet einen Out-of-Gas-Fehler und ***â˜‡*** bedeutet einen unerwarteten Programmabbruch. Die verbleibenden zwei zeigen an, dass der Code des Dienstes im nachfolgenden Zustand des Lookup-Anker-Blocks entweder nicht verfÃ¼gbar war oder die maximale erlaubte GrÃ¶ÃŸe ***S*** Ã¼berschritt.

### 11.2. PaketverfÃ¼gbarkeitssicherungen (Package Availability Assurances)
Wir definieren zuerst ***Ï(++)***, den Zwischenzustand, der als nÃ¤chstes in Abschnitt 11.4 verwendet wird, sowie ***R***, die Menge der verfÃ¼gbaren Arbeitsberichte, die spÃ¤ter in Abschnitt 12 verwendet werden. Beide erfordern die Integration von Informationen aus den Sicherungsextrinsik ***EA***.

#### 11.2.1 Die Sicherungsextrinsik (The Assurances Extrinsic.)
Die Sicherungsextrinsik ist eine Folge von Sicherungswerten, hÃ¶chstens einer pro Validator. Jede Sicherung ist eine Folge von BinÃ¤rwerten (d.h. einer Bitfolge), jeweils eine pro Kern, zusammen mit einer Signatur und dem Index des Validators, der sichert. Ein Wert von 1 (oder ***âŠº***, wenn als Boolean interpretiert) an einem beliebigen Index impliziert, dass der Validator versichert, dass er zur VerfÃ¼gbarkeit beitrÃ¤gt.**^11** Formal:

<div align="center">
<img src="img/equation-116.PNG" width="700"/>
</div>

> **Footnotes:**
>
>**^11** Dies ist eine â€weicheâ€œ Implikation, da es keine Konsequenzen in der Blockchain gibt, wenn unehrlich berichtet wird. FÃ¼r weitere Informationen zu dieser Implikation siehe Abschnitt 15.

Die Sicherungen mÃ¼ssen alle am Ã¼bergeordneten Block verankert und nach Validatorindex geordnet sein:

<div align="center">
<img src="img/equation-117-118.PNG" width="700"/>
</div>

Die Signatur muss von einem Ã¶ffentlichen SchlÃ¼ssel des Validators stammen, der sichert, und dessen Nachricht die Serialisierung des Ã¼bergeordneten Hashes ***Hp*** und der oben genannten Bitfolge ist:

<div align="center">
<img src="img/equation-119-120.PNG" width="700"/>
</div>

Ein Bit darf nur gesetzt werden, wenn der entsprechende Kern einen Bericht anhÃ¤ngig hat, dessen VerfÃ¼gbarkeit sichergestellt wird:

<div align="center">
<img src="img/equation-121.PNG" width="700"/>
</div>

#### 11.2.2 VerfÃ¼gbare Berichte (Available Reports)
Ein Arbeitsbericht wird als verfÃ¼gbar angesehen, wenn und nur wenn eine klare 2/3-Mehrheit der Validatoren das Setzen seines Kerns innerhalb der Sicherungsextrinsik des Blocks markiert haben. Formal definieren wir die Reihe der verfÃ¼gbaren Arbeitsberichte ***R*** wie folgt:

<div align="center">
<img src="img/equation-122.PNG" width="700"/>
</div>

Dieser Wert wird in der Definition von sowohl ***Î´â€²*** als auch ***Ï(++)*** verwendet, die wir als gleichwertig zu ***Ï(+)*** definieren, auÃŸer dass Elemente entfernt werden, die jetzt verfÃ¼gbar sind:

<div align="center">
<img src="img/equation-123.PNG" width="700"/>
</div>

### 11.3. BÃ¼rgschaftszuteilungen (Guarantor Assignments.) 
Jeder Block hat einen bestimmten Kern, dem eine bestimmte Anzahl von Validatoren zugewiesen ist, die Arbeitsberichte dafÃ¼r garantieren. Bei ***V = 1.023*** Validatoren und ***C = 341*** Kernen ergibt dies genau ***V/C = 3*** Validatoren pro Kern. Die Ed25519-SchlÃ¼ssel dieser Validatoren werden durch ***G*** bezeichnet:

<div align="center">
<img src="img/equation-124.PNG" width="700"/>
</div>

Wir bestimmen den Kern, dem ein bestimmter Validator zugewiesen wird, durch eine Zufallsmischung mit epochaler Entropie und einer periodischen Rotation, um die Sicherheit und Lebendigkeit des Netzwerks zu gewÃ¤hrleisten. Wir verwenden ***Î·2*** fÃ¼r die epochale Entropie anstelle von ***Î·1***, um die MÃ¶glichkeit einer GabelvergrÃ¶ÃŸerung zu vermeiden, bei der Unsicherheit Ã¼ber den Kettenzustand am Ende einer Epoche zwei etablierte Gabeln entstehen lassen kÃ¶nnte, bevor sie sich natÃ¼rlich auflÃ¶st. Wir definieren die Permutationsfunktion ***P***, die Rotationsfunktion ***R*** und schlieÃŸlich die BÃ¼rgschaftszuteilungen ***G*** wie folgt:

<div align="center">
<img src="img/equation-125-127.PNG" width="700"/>
</div>

Wir definieren auch ***Gâˆ—***, was dem Wert ***G*** entspricht, wie er unter der vorherigen Rotation gewesen wÃ¤re:

<div align="center">
<img src="img/equation-128-129.PNG" width="700"/>
</div>

### 11.4. Arbeitsberichtsgarantien (Work Report Guarantees.)
Wir beginnen mit der Definition der Garantieextrinsik, ***EG***, einer Reihe von Garantien, hÃ¶chstens eine fÃ¼r jeden Kern, jede davon ein Tupel aus einem Kernindex, einem Arbeitsbericht, einer Berechtigung a und dem entsprechenden Zeitschlitz ***t***. Formal:

<div align="center">
<img src="img/equation-130-131.PNG" width="700"/>
</div>

Die Berechtigung ist selbst eine Folge von drei Tupeln aus einer Signatur und einem Validator-Index ***E***. Nur das letzte Element darf legitimerweise ***âˆ…*** sein.
Der Kernindex jeder Garantie muss in aufsteigender Reihenfolge sein:

<div align="center">
<img src="img/equation-132-133.PNG" width="700"/>
</div>

Die Signatur muss von einem Ã¶ffentlichen SchlÃ¼ssel des Validators stammen, der in der Berechtigung identifiziert ist, und dessen Nachricht die Serialisierung des Kernindex und des Arbeitsberichts ist. Die signierenden Validatoren mÃ¼ssen dem betreffenden Kern entweder in diesem Block ***G*** zugewiesen sein, wenn der Zeitschlitz fÃ¼r die Garantie in derselben Rotation wie der Zeitschlitz dieses Blocks liegt, oder im jÃ¼ngsten vorherigen Satz von Zuweisungen, ***Gâˆ—***:

<div align="center">
<img src="img/equation-134-135.PNG" width="700"/>
</div>

Es dÃ¼rfen keine Berichte auf Kernen platziert werden, die einen Bericht anhÃ¤ngig haben, dessen VerfÃ¼gbarkeit noch nicht sichergestellt ist, es sei denn, er ist abgelaufen. Im letzteren Fall mÃ¼ssen ***U = 5*** Zeitschlitze nach dem Erstellen des Berichts vergangen sein. Ein Bericht ist ungÃ¼ltig, wenn der Autorisierungshash nicht im Autorisierungspool des Kerns vorhanden ist, auf dem die Arbeit gemeldet wird. Formal:

<div align="center">
<img src="img/equation-136.PNG" width="700"/>
</div>

Wir bezeichnen w als die Menge der Arbeitsberichte im aktuellen Extrinsik ***E***:

<div align="center">
<img src="img/equation-137.PNG" width="700"/>
</div>

Wir geben den maximalen Gesamterfordernis an Akkumulationsgas an, den ein Arbeitsbericht implizieren darf, als ***GA*** an, und verlangen, dass die Summe aller Mindestgasanforderungen der Dienste nicht grÃ¶ÃŸer als dieser Wert ist:

<div align="center">
<img src="img/equation-138.PNG" width="700"/>
</div>

#### 11.4.1 Kontextuelle GÃ¼ltigkeit der Berichte (Contextual Validity of Reports)
Der Einfachheit halber definieren wir zwei Ã„quivalenzen ***x*** und ***p***, die jeweils die Menge aller Kontexte und Arbeitspakethashes innerhalb des Extrinsiks darstellen:

<div align="center">
<img src="img/equation-139.PNG" width="700"/>
</div>

Es dÃ¼rfen keine doppelten Arbeitspakethashes vorhanden sein (d.h. zwei Arbeitsberichte desselben Pakets). Daher verlangen wir, dass die KardinalitÃ¤t von ***p*** der LÃ¤nge der Arbeitsberichtsequenz ***w*** entspricht:

<div align="center">
<img src="img/equation-140.PNG" width="700"/>
</div>

Wir verlangen, dass der Ankerblock innerhalb der letzten ***H*** BlÃ¶cke liegt und dass seine Details korrekt sind, indem wir sicherstellen, dass er in unseren neuesten BlÃ¶cken ***Î²*** erscheint:

<div align="center">
<img src="img/equation-141.PNG" width="700"/>
</div>

Wir verlangen, dass jeder Lookup-Ankerblock innerhalb der letzten ***L*** Zeitschlitze liegt:

<div align="center">
<img src="img/equation-142.PNG" width="700"/>
</div>

Wir verlangen auch, dass wir einen Datensatz darÃ¼ber haben; dies ist eine der wenigen Bedingungen, die nicht rein durch den On-Chain-Zustand Ã¼berprÃ¼ft werden kÃ¶nnen und durch das Beibehalten der letzten ***L*** Header als Ahnenmenge ***A*** Ã¼berprÃ¼ft werden mÃ¼ssen. Da es durch die Header-Kette bestimmt wird, ist es immer noch deterministisch und berechenbar. Formal:

<div align="center">
<img src="img/equation-143.PNG" width="700"/>
</div>

Wir verlangen, dass das Arbeitspaket des Berichts nicht das Arbeitspaket eines anderen Berichts ist, der in der Vergangenheit erstellt wurde. Da das Arbeitspaket den Ankerblock impliziert und der Ankerblock auf die neuesten BlÃ¶cke beschrÃ¤nkt ist, mÃ¼ssen wir nur sicherstellen, dass das Arbeitspaket nicht in unserer jÃ¼ngsten Geschichte erscheint:

<div align="center">
<img src="img/equation-144.PNG" width="700"/>
</div>

Wir verlangen, dass das vorausgesetzte Arbeitspaket, falls vorhanden, entweder im Extrinsik oder in unserer jÃ¼ngsten Geschichte vorhanden ist:

<div align="center">
<img src="img/equation-145.PNG" width="700"/>
</div>

Wir verlangen, dass alle Arbeitsergebnisse im Extrinsik den korrekten Codehash fÃ¼r ihren entsprechenden Dienst vorhergesagt haben:

<div align="center">
<img src="img/equation-146.PNG" width="700"/>
</div>

### 11.5. Ãœbergang fÃ¼r Berichte (Transitioning for Reports.)
Wir definieren ***Ïâ€²*** als Ã¤quivalent zu ***Ï(++)***, auÃŸer in FÃ¤llen, in denen der Extrinsik einen Eintrag ersetzt hat. Falls ein Eintrag ersetzt wird, enthÃ¤lt der neue Wert die aktuelle Zeit ***Ï„â€²***, sodass der Wert unabhÃ¤ngig von seiner VerfÃ¼gbarkeit ersetzt werden kann, sobald genÃ¼gend Zeit verstrichen ist (siehe Gleichung 136).

<div align="center">
<img src="img/equation-147.PNG" width="700"/>
</div>

Dies schlieÃŸt den Abschnitt Ã¼ber Berichterstattung und Sicherung ab. Wir haben nun eine vollstÃ¤ndige Definition von ***Ïâ€²*** zusammen mit ***R***, die in Abschnitt 12 verwendet werden, welcher den Zustandsteil beschreibt, der eintritt, sobald ein Arbeitsbericht garantiert und verfÃ¼gbar gemacht wird.

## 12. Akkumulation (Accumulation)
Die Akkumulation kann als eine Funktion definiert werden, deren Argumente ***R*** und ***Î´*** zusammen mit ausgewÃ¤hlten Teilen des (manchmal teilweise Ã¼bergangenen) Zustands sind und die den nachfolgenden Dienstzustand ***Î´â€²*** zusammen mit zusÃ¤tzlichen Zustandselementen ***Î¹â€²***, ***Ï†â€²*** und ***Ï‡â€²*** ergibt.
Das Prinzip der Akkumulation ist tatsÃ¤chlich ganz einfach: Wir mÃ¶chten lediglich die Akkumulationslogik des Dienstcodes jedes Dienstes ausfÃ¼hren, der mindestens eine Arbeitsausgabe hat, und ihm die Arbeitsausgaben und nÃ¼tzliche Kontextinformationen Ã¼bergeben. Es gibt jedoch drei Hauptkomplikationen. Erstens mÃ¼ssen wir die AusfÃ¼hrungsumgebung dieser Logik definieren, insbesondere die fÃ¼r sie verfÃ¼gbaren Hostfunktionen. Zweitens mÃ¼ssen wir die Menge des Gases festlegen, die fÃ¼r die AusfÃ¼hrung jedes Dienstes zulÃ¤ssig ist. SchlieÃŸlich mÃ¼ssen wir die Natur der Ãœbertragungen innerhalb der Akkumulation bestimmen, was, wie wir sehen werden, zur Notwendigkeit eines zweiten Einstiegspunkts, "on-transfer", fÃ¼hrt.

### 12.1. Preimage-Integration
Vor der Akkumulation mÃ¼ssen wir zuerst alle im Lookup-Extrinsik bereitgestellten Preimages integrieren. Das Lookup-Extrinsik ist eine Folge von Paaren aus Dienstindizes und Daten. Diese Paare mÃ¼ssen geordnet und ohne Duplikate sein (Gleichung 149 erfordert dies). Die Daten mÃ¼ssen von einem Dienst angefordert worden sein, aber noch nicht bereitgestellt worden sein. Formal:

<div align="center">
<img src="img/equation-148-151.PNG" width="700"/>
</div>

### 12.2. Gasabrechnung (Gas Accounting)
Wir definieren ***S***, die Menge aller Dienste, die in diesem Block akkumuliert werden; das sind alle Dienste, die mindestens eine Arbeitsausgabe innerhalb von ***R*** haben, zusammen mit allen privilegierten Diensten, ***Ï‡***. Formal:

<div align="center">
<img src="img/equation-152.PNG" width="700"/>
</div>

Wir berechnen das Gas, das jedem Dienst zugewiesen wird, als die Summe des Anteils jeder Arbeitsausgabe des Dienstes am wahlfreien Akkumulationsgas seines Berichts zusammen mit der Zwischensumme der Mindestgasanforderungen:

<div align="center">
<img src="img/equation-153.PNG" width="700"/>
</div>

### 12.3. Vorbereitung (Wrangling)
Wir definieren schlieÃŸlich die Ergebnisse, die als Operand in die Akkumulationsfunktion fÃ¼r jeden Dienst in ***S*** eingegeben werden. Dies ist eine Folge von Operandentupeln ***O***, eine Folge fÃ¼r jeden Dienst in ***S***. Jede Folge enthÃ¤lt ein Element pro Arbeitsausgabe (oder Fehler), die fÃ¼r diesen Dienst akkumuliert werden soll, zusammen mit dem Nutzlast-Hash, dem Paket-Hash und der Autorisierungsausgabe der Arbeitsausgabe. Die Tupel sind in der gleichen Reihenfolge angeordnet, in der sie in ***R*** erscheinen. Formal:

<div align="center">
<img src="img/equation-154.PNG" width="700"/>
</div>

<div align="center">
<img src="img/equation-155.PNG" width="700"/>
</div>

### 12.4. Aufruf (Invocation)
In diesem Abschnitt definieren wir ***A***, die Funktion, die die Akkumulation eines einzelnen Dienstes durchfÃ¼hrt. Formal gesprochen nimmt ***A*** die OmniprÃ¤senz des Zeitschlitzes ***Ht*** und einiger vorheriger Zustandskomponenten ***Î´(+)***, ***Î½***, ***Rd*** an und nimmt als spezifische Argumente den Dienstindex ***s âˆˆ S*** (aus dem es die aufbereiteten Ergebnisse ***M(s)*** und das Gaslimit ***G(s)*** ableiten kann) und liefert Werte fÃ¼r ***Î´(+)[s]*** und Staging-Zuweisungen in ***Ï†***, ***Î¹*** zusammen mit einer Reihe von Lookup-Anfragen/Vergessen, einer Reihe von verzÃ¶gerten Ãœbertragungen und ***C***, das eine Abbildung vom Dienstindex zu den Beefy-Verpflichtungshashes darstellt.
Wir bezeichnen zuerst die Menge der verzÃ¶gerten Ãœbertragungen als ***T***, wobei eine Ãœbertragung eine Memo-Komponente m von 64 Oktetten sowie den Dienstindex des Absenders ***s***, den Dienstindex des EmpfÃ¤ngers ***d***, die zu Ã¼bertragende Token-Menge ***a*** und das Gaslimit ***g*** fÃ¼r die Ãœbertragung umfasst. Formal:

<div align="center">
<img src="img/equation-156.PNG" width="700"/>
</div>

Wir kÃ¶nnen dann A definieren, die Abbildung vom Index der akkumulierten Dienste zu den verschiedenen Komponenten, in denen wir unseren nachfolgenden Zustand definieren werden:

<div align="center">
<img src="img/equation-157.PNG" width="700"/>
</div>

Wie klar zu sehen ist, kombiniert unsere Akkumulationsabbildung A Teile des vorherigen Zustands zu Argumenten fÃ¼r einen Aufruf der virtuellen Maschine. Insbesondere die Dienstkonten ***Î´(+)*** zusammen mit dem Index des betreffenden Dienstes s und seinen aufbereiteten Refinement-Ergebnissen ***M(s)*** und Gaslimit ***G(s)*** werden arrangiert, um die Argumente fÃ¼r ***Î¨A*** zu erstellen, das selbst einen Aufruf der virtuellen Maschine gemÃ¤ÃŸ Anhang B.4 verwendet.
Die Beefy-Verpflichtungsabbildung ist eine Funktion, die alle akkumulierten Dienste auf ihr Akkumulationsergebnis (den ***r***-Komponente des Ergebnisses von ***A***) abbildet. Dies wird zur Bestimmung der Akkumulations-Ergebnis-Baumwurzel fÃ¼r den aktuellen Block verwendet, nÃ¼tzlich fÃ¼r das Beefy-Protokoll:

<div align="center">
<img src="img/equation-158.PNG" width="700"/>
</div>

Angesichts unserer Abbildung ***A***, die vollstÃ¤ndig aus den VM-Aufrufen jedes akkumulierten Dienstes ***S*** berechnet werden kann, kÃ¶nnen wir den nachfolgenden Zustand ***Î´â€²***, ***Ï‡â€²***, ***Ï†â€²*** und ***Î¹â€²*** als das Ergebnis der Integration von ***A*** in unseren Zustand definieren.

#### 12.4.1. Privilegierte ÃœbergÃ¤nge (Privileged Transitions)
Die Staging-Kernzuweisungen und die Validator-SchlÃ¼ssel sowie das privilegierte Dienstset werden jeweils basierend auf den Auswirkungen der Akkumulation der drei privilegierten Dienste geÃ¤ndert:

<div align="center">
<img src="img/equation-159.PNG" width="700"/>
</div>

#### 12.4.2. DienstkontoÃ¼bergÃ¤nge (Service Account Transitions)
SchlieÃŸlich integrieren wir alle Ã„nderungen an den Dienstkonten in den Zustand.
Wir stellen fest, dass alle neu hinzugefÃ¼gten Dienstindizes, definiert als ***K(A(s)n)*** fÃ¼r jeden akkumulierten Dienst ***s***, nicht mit den Indizes vorhandener oder neu hinzugefÃ¼gter Dienste kollidieren dÃ¼rfen. Dies sollte nie passieren, da neue Indizes explizit ausgewÃ¤hlt werden, um solche Konflikte zu vermeiden. Sollte es jedoch in seltenen FÃ¤llen passieren, wÃ¤re der Block ungÃ¼ltig. Formal:

<div align="center">
<img src="img/equation-160.PNG" width="700"/>
</div>

Wir definieren zuerst ***Î´(++)***, einen Zwischenzustand nach der Hauptakkumulation, aber bevor die Ãœbertragungen gutgeschrieben und verarbeitet wurden:

<div align="center">
<img src="img/equation-161.PNG" width="700"/>
</div>

Wir bezeichnen ***R(s)*** als die Sequenz der Ãœbertragungen, die von einem bestimmten Dienst mit dem Index s empfangen wurden, in der Reihenfolge, in der sie von Diensten mit aufsteigendem Index gesendet wurden. (Wenn ein Dienst s keine Ãœbertragungen erhalten hat oder einfach nicht existiert, wÃ¤re ***R(s)*** gÃ¼ltig als leere Sequenz definiert.) Formal:

<div align="center">
<img src="img/equation-162.PNG" width="700"/>
</div>

Der nachfolgende Zustand ***Î´â€²*** kann dann als der Zwischenzustand mit allen angewendeten verzÃ¶gerten Ãœbertragungen definiert werden:

<div align="center">
<img src="img/equation-163.PNG" width="700"/>
</div>

Beachten Sie, dass ***Î¨T*** in Anhang B.5 definiert ist, sodass es zu ***Î´(++)[d]*** fÃ¼hrt, d.h. keine Ã„nderung des Zwischenzustands des Kontos, wenn ***R(d) = []***, d.h. wenn das Konto keine Ãœbertragungen erhalten hat.

## 13. Arbeitspakete und Arbeitsberichte (Work Packages and Work Reports)
### 13.1. Ehrliches Verhalten (Honest Behavior)
Bisher haben wir spezifiziert, wie BlÃ¶cke fÃ¼r eine korrekt Ã¼bergehende JAM-Blockchain erkannt werden. Durch die Definition der Zustandstransitionsfunktion und einer Merklization-Funktion fÃ¼r den Zustand haben wir auch definiert, wie ein gÃ¼ltiger Header erkannt wird. Obwohl es nicht besonders schwierig ist zu verstehen, wie ein neuer Block erstellt werden kann, wenn ein Knoten einen SchlÃ¼ssel kontrolliert, der die Erstellung der beiden Signaturen im Header ermÃ¶glicht, und um die anderen Headerfelder auszufÃ¼llen, bleibt der Inhalt der Extrinsik unklar.

Wir definieren nicht nur korrektes Verhalten durch die Erstellung korrekter BlÃ¶cke, sondern auch ehrliches Verhalten, das die Teilnahme des Knotens an mehreren Off-Chain-AktivitÃ¤ten umfasst. Dies hat analoge Aspekte innerhalb von YP Ethereum, obwohl es in diesem Dokument nicht so explizit erwÃ¤hnt wird: Die Erstellung von BlÃ¶cken sowie das Weitergeben und EinfÃ¼gen von Transaktionen in diese BlÃ¶cke wÃ¼rden alle als Off-Chain-AktivitÃ¤ten gelten, fÃ¼r die ehrliches Verhalten hilfreich ist. Im Fall von JAM ist ehrliches Verhalten gut definiert und wird von mindestens **2/3** der Validatoren erwartet.

Ãœber die Produktion von BlÃ¶cken hinaus umfasst das incentivierte ehrliche Verhalten:

- Das Garantieren und Melden von Arbeitspaketen sowie das Chunking und die Verteilung sowohl der Chunks als auch des Arbeitspakets selbst, wie in Abschnitt 14 besprochen.
- Die Sicherstellung der VerfÃ¼gbarkeit von Arbeitspaketen nach Erhalt ihrer Daten.
- Die Bestimmung, welche Arbeitsberichte geprÃ¼ft werden sollen, deren Abruf und PrÃ¼fung sowie die Erstellung und Verteilung von Urteilen basierend auf dem Ergebnis der PrÃ¼fung.
- Das Einreichen der korrekten Menge an Arbeit, die von anderen Validatoren gesehen wurde, wie in Abschnitt 19 besprochen.

### 13.2. Segmente und das Manifest 
Unsere grundlegende Erasure-Coding-SegmentgrÃ¶ÃŸe betrÃ¤gt **WC = 684 Oktette**, abgeleitet aus dem Wunsch, auch dann rekonstruieren zu kÃ¶nnen, wenn fast zwei Drittel unserer **1023** Teilnehmer bÃ¶swillig oder handlungsunfÃ¤hig sind, dem 16-Bit-Galois-Feld, auf dem der Erasure-Code basiert, und dem Wunsch, Daten von nahe an, aber nicht weniger als, **4 KB** effizient zu unterstÃ¼tzen.

Arbeitspakete sind im Allgemeinen klein, um sicherzustellen, dass BÃ¼rgen nicht viel Bandbreite investieren mÃ¼ssen, um herauszufinden, ob sie fÃ¼r ihre Bewertung in einen Arbeitsbericht bezahlt werden kÃ¶nnen. Anstatt viele Daten inline zu haben, verweisen sie stattdessen auf Daten durch Commitments. Die einfachsten Commitments sind extrinsische Daten.

Extrinsische Daten sind Blobs, die zusammen mit dem Arbeitspaket selbst allgemein vom Arbeitspaket-Ersteller in das System eingefÃ¼hrt werden. Sie werden der Refine-Logik als Argument zugÃ¤nglich gemacht. Wir verpflichten uns zu ihnen, indem wir jeden ihrer Hashes im Arbeitspaket einschlieÃŸen.

Arbeitspakete haben zwei andere Arten externer Daten, die mit ihnen verbunden sind: Ein kryptografisches Commitment zu jedem importierten Segment und schlieÃŸlich die Anzahl der exportierten Segmente.

#### 13.2.1. Segmente, Importe und Exporte
Die FÃ¤higkeit, groÃŸe Mengen an Daten von einem Arbeitspaket zu einem nachfolgenden Arbeitspaket zu kommunizieren, ist ein SchlÃ¼sselmerkmal des JAM-VerfÃ¼gbarkeitssystems. Ein exportiertes Segment, definiert als die Menge ***G***, ist eine Oktettsequenz fester LÃ¤nge **WSWC = 4104**. Es ist das kleinste Datum, das einzeln aus dem oder in das langfristige Imports DA wÃ¤hrend der Refine-Funktion eines Arbeitspakets importiert oder exportiert werden kann. Da es ein genaues Vielfaches der Erasure-Coding-StÃ¼ckgrÃ¶ÃŸe ist, wird sichergestellt, dass die Datensegmente des Arbeitspakets effizient im DA-System platziert werden kÃ¶nnen.

<div align="center">
<img src="img/equation-164.PNG" width="700"/>
</div>

Exportierte Segmente sind Daten, die durch die AusfÃ¼hrung der Refine-Logik generiert werden und somit ein Nebeneffekt der Umwandlung des Arbeitspakets in einen Arbeitsbericht sind. Da ihre Daten deterministisch basierend auf der AusfÃ¼hrung der Refine-Logik sind, benÃ¶tigen wir kein besonderes Commitment zu ihnen im Arbeitspaket, auÃŸer zu wissen, wie viele mit jedem Refine-Aufruf verbunden sind, damit wir einen genauen Index bereitstellen kÃ¶nnen.

Importierte Segmente hingegen sind Segmente, die von vorherigen Arbeitspaketen exportiert wurden. Um sie leicht abrufen und Ã¼berprÃ¼fen zu kÃ¶nnen, werden sie nicht durch Hash, sondern durch den Root eines Merkle-Baums referenziert, der alle anderen zum Zeitpunkt eingefÃ¼hrten Segmente einschlieÃŸt, zusammen mit einem Index in diese Sequenz. Dies ermÃ¶glicht die Erstellung von KorrektheitsbegrÃ¼ndungen, die gespeichert, zusammen mit den abgerufenen Daten eingefÃ¼gt und Ã¼berprÃ¼ft werden kÃ¶nnen. Dies wird im nÃ¤chsten Abschnitt ausfÃ¼hrlich beschrieben.

#### 13.2.2. Datenerfassung und BegrÃ¼ndung (Data Collection and Justification.)
Es ist die Aufgabe eines BÃ¼rgen, alle importierten Segmente durch das Abrufen der erasure-codierten Chunks dieser Segmente von genÃ¼gend einzigartigen Validatoren wiederherzustellen. Allein die Wiederherstellung reicht nicht aus, da eine Datenkorruption auftreten wÃ¼rde, wenn ein oder mehrere Validatoren einen falschen Chunk bereitstellen. Aus diesem Grund stellen wir sicher, dass die Spezifikation des Importsegments (ein Merkle-Root und ein Index in den Baum) eine Art kryptografisches Commitment ist, das durch eine BegrÃ¼ndung nachweisen kann, dass ein bestimmtes Segment tatsÃ¤chlich korrekt ist.

BegrÃ¼ndungsdaten mÃ¼ssen jedem Knoten wÃ¤hrend der potenziellen Anforderung seines Segments zur VerfÃ¼gung stehen. Bei etwa 350 Byte zur BegrÃ¼ndung eines einzelnen Segments sind die BegrÃ¼ndungsdaten zu umfangreich, als dass alle Validatoren alle Daten speichern kÃ¶nnten. Daher verwenden wir das gleiche allgemeine VerfÃ¼gbarkeitsframework fÃ¼r die Bereitstellung von BegrÃ¼ndungsmetadaten wie fÃ¼r die Daten selbst.

Der BÃ¼rge kann diesen Beweis nutzen, um sich selbst zu bestÃ¤tigen, dass er seine Zeit nicht mit falschem Verhalten verschwendet. Wir zwingen PrÃ¼fer nicht dazu, denselben Prozess durchzugehen. Stattdessen erstellen BÃ¼rgen ein Ã¼berprÃ¼fbares Arbeitspaket und platzieren dies im Audit-DA-System. Dies ist das ursprÃ¼ngliche Arbeitspaket, seine extrinsischen Daten, seine importierten Daten und ein prÃ¤gnanter Korrektheitsnachweis dieser importierten Daten. Diese Taktik dupliziert routinemÃ¤ÃŸig Daten zwischen dem Imports-DA und dem Audits-DA, ist jedoch akzeptabel, um die Bandbreitenkosten fÃ¼r PrÃ¼fer zu reduzieren, die die Korrektheit so kostengÃ¼nstig wie mÃ¶glich nachweisen mÃ¼ssen, da das PrÃ¼fen im Durchschnitt 30 Mal fÃ¼r jedes Arbeitspaket erfolgt, wÃ¤hrend die Garantie nur zwei- oder dreimal erfolgt.

### 13.3. Pakete und Elemente (Packages and Items)
Wir beginnen mit der Definition eines Arbeitspakets, der Menge ***P***, und seiner konstituierenden Arbeitselemente, der Menge ***I***. Ein Arbeitspaket umfasst einen einfachen Blob, der als Autorisierungstoken ***j*** fungiert, den Index des Dienstes, der den Autorisierungscode hostet, ***h***, einen Autorisierungscode-Hash ***c*** und einen Parametrisierungs-Blob ***p***, einen Kontext ***x*** und eine Sequenz von Arbeitselementen ***i***:

<div align="center">
<img src="img/equation-165.PNG" width="700"/>
</div>

Ein Arbeitselement umfasst: ***s***, den Bezeichner des Dienstes, auf den es sich bezieht, den Code-Hash des Dienstes zum Zeitpunkt der Berichterstattung ***c*** (dessen Preimage aus der Perspektive des Lookup-Ankerblocks verfÃ¼gbar sein muss), einen Nutzlast-Blob ***y***, ein Gaslimit ***g*** und die drei Elemente seines Manifests, eine Sequenz importierter Datensegmente ***i***, identifiziert durch den Root des Segmentbaums und einen Index darin, ***x***, eine Sequenz von Hashes der Datensegmente, die in diesem Block eingefÃ¼hrt werden sollen (und die wir annehmen, dass der Validator sie kennt) und ***e***, die Anzahl der von diesem Arbeitselement exportierten Datensegmente:

<div align="center">
<img src="img/equation-166.PNG" width="700"/>
</div>

Wir begrenzen die Gesamtanzahl der exportierten Elemente auf **WM = 211**. Wir setzen auch das gleiche Limit fÃ¼r die Gesamtanzahl der importierten Elemente:

<div align="center">
<img src="img/equation-167.PNG" width="700"/>
</div>

Wir gehen davon aus, dass das Preimage zu jedem extrinsischen Hash in jedem Arbeitselement dem BÃ¼rgen bekannt ist. Im Allgemeinen werden diese Daten dem BÃ¼rgen zusammen mit dem Arbeitspaket Ã¼bermittelt.

Wir begrenzen die kodierte GrÃ¶ÃŸe eines Arbeitspakets plus die GesamtgrÃ¶ÃŸe der implizierten Import- und Extrinsikelemente auf **12 MB**, um einen Datendurchsatz von etwa **2 MB/s/Kern** zu ermÃ¶glichen:

<div align="center">
<img src="img/equation-168-170.PNG" width="700"/>
</div>

Wir definieren den implizierten Autorisierer des Arbeitspakets als ***pa***, den Hash der Verkettung des Autorisierungscodes und der Parametrisierung. Wir definieren den Autorisierungscode als ***pc*** und verlangen, dass er zum Zeitpunkt des Lookup-Ankerblocks im historischen Lookup des Dienstes ***h*** verfÃ¼gbar ist. Formal:

<div align="center">
<img src="img/equation-171.PNG" width="700"/>
</div>

(Î› ist die historische Lookup-Funktion, die in Gleichung 91 definiert ist.)

#### 13.3.1. Exportieren
Jedes Arbeitselement eines Arbeitspakets kann Segmente exportieren, und ein Segment-Root wird im Arbeitsbericht platziert, der diese commitet, in der Reihenfolge entsprechend dem Arbeitselement, das exportiert. Es wird als der Root eines binÃ¤ren Merkle-Baums konstanter Tiefe gebildet, wie in Gleichung 292 definiert:
BÃ¼rgen mÃ¼ssen zwei DatensÃ¤tze erasure-codieren und verteilen: einen Blob, das Ã¼berprÃ¼fbare Arbeitspaket, das das kodierte Arbeitspaket, extrinsische Daten und selbstbegrÃ¼ndende importierte Segmente enthÃ¤lt, welches im kurzlebigen Audit-DA-Store platziert wird, und einen zweiten Satz exportierter Segmentdaten zusammen mit den Metadaten der Paged-Proofs. Elemente im ersten Store sind kurzlebig; Assurer sollen sie nur bis zur Finalisierung des Blocks aufbewahren, der das Arbeitsergebnis enthÃ¤lt. Elemente im zweiten Store hingegen sind langlebig und sollen mindestens **28** Tage (**672** vollstÃ¤ndige Epochen) nach der Berichterstattung des Arbeitsberichts aufbewahrt werden.

Wir definieren die Paged-Proofs-Funktion ***P***, die eine Reihe exportierter Segmente ***s*** akzeptiert und eine Reihe zusÃ¤tzlicher Segmente definiert, die Ã¼ber Erasure-Coding und Verteilung in das Imports-DA-System eingebracht werden. Die Funktion bewertet Seiten von Hashes zusammen mit Subtree-Proofs, sodass KorrektheitsbegrÃ¼ndungen basierend auf einem Segment-Root daraus erstellt werden kÃ¶nnen:

<div align="center">
<img src="img/equation-172.PNG" width="700"/>
</div>

Hinweis: Falls ***âˆ£sâˆ£*** kein Vielfaches von 64 ist, wird der Term ***siâ‹…â‹…â‹…+64*** korrekt auf weniger als **64** Elemente verweisen, wenn es sich um die letzte Seite handelt.

### 13.4. Berechnung der Arbeitsergebnisse (Computation of Work Results)
Wir kommen nun zur Funktion ***Î***, die die Arbeitsergebnisse berechnet. Diese bildet die Grundlage fÃ¼r die Nutzung der Kerne in JAM. Sie akzeptiert ein Arbeitspaket ***p*** fÃ¼r einen benannten Kern ***c*** und resultiert entweder in einem Fehler ***âˆ‡*** oder im Arbeitsergebnis und einer Reihe exportierter Segmente. Diese Funktion ist deterministisch und erfordert nur, dass sie innerhalb von acht Epochen nach einem kÃ¼rzlich finalisierten Block ausgewertet wird, dank der historischen Lookup-FunktionalitÃ¤t. Sie kann somit problemlos von jedem Knoten innerhalb der PrÃ¼fungsperiode ausgewertet werden, auch unter BerÃ¼cksichtigung der PraktikabilitÃ¤t einer unvollkommenen Synchronisierung.

<div align="center">
<img src="img/equation-173.PNG" width="700"/>
</div>

Die hier gegebene Definition ist in mehrere Funktionen unterteilt, um die Lesbarkeit zu erleichtern. Der erste eingefÃ¼hrte Begriff, ***o***, ist die Autorisierungsausgabe, das Ergebnis der Is-Authorized-Funktion. Der zweite Begriff, (***r***, ***e***), ist die Sequenz der Ergebnisse fÃ¼r jedes der Arbeitselemente im Arbeitspaket zusammen mit allen von jedem Arbeitselement exportierten Segmenten.

Die dritte und vierte Definition sind Hilfsbegriffe dafÃ¼r, wobei die dritte eine geordnete Akkumulation (d.h. ZÃ¤hler) durchfÃ¼hrt, um sicherzustellen, dass die Refine-Funktion Zugang zur Gesamtzahl der Exporte aus dem Arbeitspaket bis zum aktuellen Arbeitselement hat. Der vierte Begriff, ***R***, ist im Wesentlichen ein Aufruf der Refine-Funktion, der die relevanten Daten aus dem Arbeitspaket und dem Arbeitselement zusammenfÃ¼hrt.

Die obigen Definitionen basieren auf zwei Funktionen, ***M*** und ***X***, die jeweils die Importsegmentdaten und die extrinsischen Daten fÃ¼r ein Arbeitselementargument ***i*** definieren:

<div align="center">
<img src="img/equation-173a.PNG" width="700"/>
</div>

In der Zwischenzeit ist ***s*** als die Datenspezifikation des Pakets definiert, wobei die "segments-root"-Funktion ***A*** und ***M***, die Imports-Lookup-Funktion, sowie ***X***, die extrinsische Daten-Lookup-Funktion, verwendet werden:

<div align="center">
<img src="img/equation-173b.PNG" width="700"/>
</div>

Obwohl ***M*** und ***j*** beide unter Verwendung des Begriffs ***s*** (die vollstÃ¤ndige Menge der Segmente, die zusammen mit jedem zu importierenden Segment bereitgestellt werden) formuliert werden, wird dieser Wert im Allgemeinen nicht benÃ¶tigt, da die BegrÃ¼ndung durch einen einzigen paged-proof abgeleitet werden kann. Dies reduziert das schlimmste Fall-Datenabrufen fÃ¼r einen BÃ¼rgen auf zwei Segmente fÃ¼r jedes zu importierende Segment. Falls zusammenhÃ¤ngend exportierte Segmente importiert werden (was wir als eine ziemlich hÃ¤ufige Situation annehmen kÃ¶nnen), sollte eine einzige Proof-Seite ausreichen, um viele importierte Segmente zu begrÃ¼nden.

Die Is-Authorized-Logik wird zuerst ausgefÃ¼hrt, um sicherzustellen, dass das Arbeitspaket die benÃ¶tigte Kernzeit rechtfertigt. Danach sollte der BÃ¼rge sicherstellen, dass alle Segmentbaum-Wurzeln, die Importsegment-Commitments bilden, bekannt sind und nicht abgelaufen sind. SchlieÃŸlich sollte der BÃ¼rge sicherstellen, dass er alle Preimage-Daten abrufen kann, die als Commitments extrinsischer Segmente referenziert werden.

Sobald dies erledigt ist, mÃ¼ssen importierte Segmente rekonstruiert werden. Dieser Prozess kann tatsÃ¤chlich lazy erfolgen, da die Refine-Funktion die Daten erst benÃ¶tigt, wenn der Import-Host-Call erfolgt. Das Abrufen impliziert im Allgemeinen, dass fÃ¼r jedes importierte Segment erasure-codierte Chunks von genÃ¼gend einzigartigen Validatoren (**342**, einschlieÃŸlich des BÃ¼rgen) abgerufen werden, wie im Anhang ***H*** ausfÃ¼hrlicher beschrieben wird. (Da wir systematisches Erasure-Coding spezifizieren, ist seine Rekonstruktion trivial, falls die korrekten **342** Validatoren ansprechbar sind.) Chunks mÃ¼ssen sowohl fÃ¼r die Daten selbst als auch fÃ¼r die BegrÃ¼ndungsmetadaten abgerufen werden, die es uns ermÃ¶glichen, sicherzustellen, dass die Daten korrekt sind.

Validatoren, in ihrer Rolle als VerfÃ¼gbarkeitsprÃ¼fer, sollten solche Chunks entsprechend dem Index des Segmentbaums indexieren, dessen Rekonstruktion sie erleichtern. Da die Daten fÃ¼r Segment-Chunks so klein sind (12 Byte), sollten feste Kommunikationskosten auf ein Minimum reduziert werden. Ein gutes Netzwerkprotokoll (derzeit nicht im Umfang enthalten) ermÃ¶glicht es den BÃ¼rgen, nur die Segmentbaum-Wurzel und den Index zusammen mit einem Booleschen Wert anzugeben, um anzugeben, ob der Proof-Chunk bereitgestellt werden muss. Da wir annehmen, dass mindestens **341** andere Validatoren online und wohlwollend sind, kÃ¶nnen wir davon ausgehen, dass der BÃ¼rge ***i*** und ***j*** oben mit Zuversicht berechnen kann, basierend auf der allgemeinen VerfÃ¼gbarkeit von Daten, die mit eâ™£ commitet wurden, was unten spezifiziert ist.

Wir definieren die Segment-Root-Funktion, die zum Committen der exportierten Segmente verwendet wird. Die Sequenz ist einfach die Untersequenz von jedem Arbeitselement, die in der Reihenfolge der genannten Arbeitselemente miteinander verkettet ist.
Wir definieren die VerfÃ¼gbarkeits-Spezifizierungsfunktion ***A***, die eine VerfÃ¼gbarkeits-Spezifizierung aus einer Oktettsequenz des audit-freundlichen Arbeitspaket-Bundles erstellt (bestehend aus dem Arbeitspaket selbst, den extrinsischen Daten und den verketteten Importsegmenten zusammen mit ihren Korrektheitsnachweisen) und einer Sequenz von Segmenten fÃ¼r jedes im Manifest erwÃ¤hnte exportierte Segment:

<div align="center">
<img src="img/equation-174.PNG" width="700"/>
</div>

Die Paged-Proofs-Funktion ***P,*** die zuvor in Gleichung 172 definiert wurde, akzeptiert eine Sequenz von Segmenten und gibt eine Sequenz von Paged-Proofs zurÃ¼ck, die ausreicht, um die Korrektheit jedes Segments zu begrÃ¼nden. Es gibt genau **âŒˆ1/64âŒ‰** Paged-Proof-Segmente, die als Anzahl der gelieferten Segmente, jede bestehend aus einer Seite von 64 Hashes von Segmenten, zusammen mit einem Merkle-Proof von der Wurzel zum Teilbaum-Root, der diese 64 Segmente enthÃ¤lt.
Die Funktionen ***M*** und ***MS*** sind die Fixed-Depth- und Simple-Binary-Merkle-Root-Funktionen, die in den Gleichungen 292 und 291 definiert sind. Die Funktion ***C*** ist die Erasure-Coding-Funktion, die im Anhang H definiert ist.
Und ***P*** ist die Null-Padding-Funktion, um ein Oktett-Array auf ein Vielfaches von ***n*** in der LÃ¤nge zu bringen:

<div align="center">
<img src="img/equation-175.PNG" width="700"/>
</div>

Validatoren werden dazu angehalten, jeden neu erasure-codierten Daten-Chunk an den entsprechenden Validator zu verteilen, da sie nicht fÃ¼r das Garantieren bezahlt werden, es sei denn, ein Arbeitsbericht wird von einer Supermehrheit der Validatoren als verfÃ¼gbar betrachtet. Angesichts unseres Arbeitspakets ***p*** sollten wir daher den entsprechenden Arbeitspaket-Bundle-Chunk und exportierte Segment-Chunks an jeden Validator senden, dessen SchlÃ¼ssel zusammen mit Ã¤hnlich entsprechenden Chunks fÃ¼r importierte, extrinsische und exportierte Segmente vorliegen, sodass jeder Validator die VollstÃ¤ndigkeit gemÃ¤ÃŸ dem Erasure-Root des Arbeitsberichts rechtfertigen kann. Im Falle eines bevorstehenden Epochenwechsels kÃ¶nnen sie auch die erwartete Belohnung maximieren, indem sie an den neuen Validatorensatz verteilen.
Wir werden diese Funktion in den nÃ¤chsten Abschnitten fÃ¼r das Garantieren, PrÃ¼fen und Beurteilen nutzen.

## 14. Garantieren (Guaranteeing)
Das Garantieren von Arbeitspaketen umfasst die Erstellung und Verteilung eines entsprechenden Arbeitsberichts, der bestimmte Bedingungen erfÃ¼llen muss. Zusammen mit dem Bericht wird eine Signatur benÃ¶tigt, die das Engagement des Validators fÃ¼r dessen Korrektheit demonstriert. Mit zwei BÃ¼rgschaftssignaturen kann der Arbeitsbericht an den nÃ¤chsten JAM-Chain-Blockautor verteilt werden, um im ***EG*** verwendet zu werden, was zu einer Belohnung fÃ¼r die BÃ¼rgen fÃ¼hrt.

Wir gehen davon aus, dass in einem Ã¶ffentlichen System Validatoren schwer bestraft werden, wenn sie Fehlfunktionen aufweisen und sich zu einem Bericht verpflichten, der das Ergebnis von ***Î***, angewendet auf ein Arbeitspaket, nicht getreu darstellt. Der gesamte Prozess umfasst:

- (1) Bewertung der Autorisierung des Arbeitspakets und Abgleich mit dem Autorisierungspool im neuesten JAM-Chain-Zustand.
- (2) Erstellung und VerÃ¶ffentlichung eines Arbeitspaketberichts.
- (3) Aufteilung des Arbeitspakets und seiner extrinsischen und exportierten Daten gemÃ¤ÃŸ dem Erasure-Code.
- (4) Verteilung der vorgenannten Chunks Ã¼ber den Validatorensatz.
- (5) Bereitstellung des Arbeitspakets, der extrinsischen und exportierten Daten auf Anfrage fÃ¼r andere Validatoren, um eine optimale Netzwerkleistung zu gewÃ¤hrleisten.

FÃ¼r jedes Arbeitspaket ***p***, das wir erhalten, kÃ¶nnen wir den entsprechenden Arbeitsbericht fÃ¼r den Kern ***c*** bestimmen, dem wir zugewiesen sind. Wenn der JAM-Chain-Zustand benÃ¶tigt wird, verwenden wir immer den Zustand des neuesten Blocks.

FÃ¼r jeden BÃ¼rgen mit dem Index ***v***, der dem Kern ***c*** und einem Arbeitspaket ***p*** zugewiesen ist, definieren wir den Arbeitsbericht ***r*** einfach als:

<div align="center">
<img src="img/equation-176.PNG" width="700"/>
</div>

Solche BÃ¼rgen kÃ¶nnen das Payload (***s***, ***v***) sicher erstellen und verteilen. Die Komponente ***s*** kann gemÃ¤ÃŸ Gleichung 134 erstellt werden; speziell ist es eine Signatur mit dem registrierten Ed25519-SchlÃ¼ssel des Validators auf einem Payload l:

<div align="center">
<img src="img/equation-177.PNG" width="700"/>
</div>

Um den Gewinn zu maximieren, sollte der BÃ¼rge sicherstellen, dass das Arbeitsergebnis alle Erwartungen erfÃ¼llt, die wÃ¤hrend der Garantiextrinsik gemÃ¤ÃŸ Abschnitt 11.4 festgelegt sind. Dies umfasst die kontextuelle GÃ¼ltigkeit, die Aufnahme der Autorisierung in den Autorisierungspool und die Sicherstellung, dass das Gesamtgas hÃ¶chstens ***GA*** betrÃ¤gt. Das Nicht-ErfÃ¼llen dieser Bedingungen fÃ¼hrt nicht zu einer Bestrafung, verhindert jedoch, dass der Blockautor das Paket einbezieht, und verringert somit die Belohnungen.

Fortgeschrittene Knoten kÃ¶nnen die Wahrscheinlichkeit maximieren, dass ihre Berichte in die Blockchain aufgenommen werden, indem sie versuchen, den Zustand der Kette zu dem Zeitpunkt vorherzusagen, zu dem der Bericht den Blockautor erreicht. Einfache Knoten kÃ¶nnen einfach den aktuellen Kettenkopf verwenden, wenn sie den Arbeitsbericht Ã¼berprÃ¼fen. Um die Arbeit zu minimieren, sollten Knoten alle diese Bewertungen vor der Auswertung der ***Î¨R***-Funktion durchfÃ¼hren, um die Arbeitsergebnisse des Berichts zu berechnen.

Sobald ein Arbeitspaket als vernÃ¼nftig zu garantieren bewertet wurde, sollten die BÃ¼rgen die Chance maximieren, dass ihre Arbeit nicht verschwendet wird, indem sie versuchen, einen Konsens Ã¼ber den Kern zu bilden. Dazu sollten sie das Arbeitspaket an alle anderen BÃ¼rgen im gleichen Kern senden, von denen sie glauben, dass sie es noch nicht kennen.

Um die Arbeit fÃ¼r die Blockautoren zu minimieren und somit die erwarteten Gewinne zu maximieren, sollten die BÃ¼rgen versuchen, die nÃ¤chste Garantiextrinsik ihres Kerns aus dem Arbeitsbericht, dem Kernindex und einer Reihe von Attestationen, einschlieÃŸlich ihrer eigenen und so vieler anderer wie mÃ¶glich, zu erstellen.

Um die Wahrscheinlichkeit zu minimieren, dass Blockautoren den BÃ¼rgen wegen Anti-Spam-MaÃŸnahmen ignorieren, sollten die BÃ¼rgen durchschnittlich nicht mehr als zwei Arbeitsberichte pro Zeitschlitz signieren.

## 15. VerfÃ¼gbarkeitsgarantie (Availability Assurance)

Validatoren sollten eine unterschriebene ErklÃ¤rung, eine sogenannte Garantie, abgeben, wenn sie im Besitz aller zugehÃ¶rigen erasure-codierten Chunks fÃ¼r einen bestimmten Arbeitsbericht sind, der derzeit auf VerfÃ¼gbarkeit wartet. Um eine Garantie fÃ¼r einen Arbeitsbericht zu erhalten, muss ein Validator vier Datenklassen besitzen:
Erstens, ihren erasure-codierten Chunk fÃ¼r diesen Bericht. Die GÃ¼ltigkeit dieses Chunks kann durch die Erasure-Root des Arbeitspakets des Arbeitsberichts und einen Merkle-Beweis der Einbeziehung an der richtigen Stelle leicht nachgewiesen werden. Der Beweis sollte vom BÃ¼rgen bereitgestellt werden. Der Chunk sollte **28** Tage lang aufbewahrt und auf Anfrage jedem Validator zur VerfÃ¼gung gestellt werden.

Zweitens, die beiden Manifeste fÃ¼r die beiden Klassen von Datenelementen: erforderlich und bereitgestellt. Diese haben Commitments als binÃ¤re Merkle-Wurzeln im Arbeitsbericht. Sie mÃ¼ssen zusammen mit den folgenden Daten bereitgestellt werden, sind jedoch nur zur ÃœberprÃ¼fung ihrer GÃ¼ltigkeit und VollstÃ¤ndigkeit erforderlich und mÃ¼ssen nicht aufbewahrt werden, nachdem der Arbeitsbericht als geprÃ¼ft betrachtet wird. Bis dahin sollten sie auf Anfrage den Validatoren zur VerfÃ¼gung gestellt werden.

Drittens sollte der Validator bereits ihren entsprechenden erasure-codierten Chunk fÃ¼r jedes der im erforderlichen Manifest aufgefÃ¼hrten Elemente besitzen. Diese Chunks kÃ¶nnen auf Ã¤hnliche Weise wie fÃ¼r das Arbeitspaket nachgewiesen werden, mit einem Merkle-Beweis auf der Wurzel, die im Manifest enthalten ist.**^12** Alle solchen Elemente dÃ¼rfen nicht vor weiteren **4.800** Zeitschlitzen zur LÃ¶schung vorgesehen sein. (Wenn sie es sind, sollte der Arbeitsbericht nicht als verfÃ¼gbar betrachtet werden.)

> **Footnotes:**
>
>**^12** Falls es scheint, dass das eigene VerfÃ¼gbarkeitssystem fÃ¼r die letzten 28 Tage von BlÃ¶cken unvollstÃ¤ndig ist, werden hilfreiche Validatoren sich bemÃ¼hen, ihren Chunk zu rekonstruieren, indem sie Anfragen an andere Validatoren stellen.

SchlieÃŸlich sollte der Validator den entsprechenden erasure-codierten Chunk fÃ¼r jedes der im bereitgestellten Manifest aufgefÃ¼hrten Elemente besitzen. Ã„hnlich wie der Chunk des Arbeitspakets sollten diese **28** Tage lang aufbewahrt und auf Anfrage jedem Validator zur VerfÃ¼gung gestellt werden.

## 16. (Auditing and Judging)
Das ÃœberprÃ¼fungs- und Beurteilungssystem ist theoretisch Ã¤quivalent zu dem in Elves, eingefÃ¼hrt von Stewart (2018). FÃ¼r eine vollstÃ¤ndige Sicherheitsanalyse des Mechanismus siehe diese Arbeit. Es gibt einen Unterschied in der Terminologie, wobei die Begriffe "Backing" und "Approval" dort unseren Begriffen "Garantieren" und "ÃœberprÃ¼fen" entsprechen.

### 16.1. Ãœbersicht

Der ÃœberprÃ¼fungsprozess erfordert, dass jeder Knoten zufÃ¤llig, aber deterministisch eine Menge von Arbeitsberichten aus jedem JAM-Chain-Block, in dem der Arbeitsbericht verfÃ¼gbar wird (d.h. aus ***R***), abruft, bewertet und ein Urteil darÃ¼ber abgibt. Vor jeder Bewertung erklÃ¤rt und beweist ein Knoten seine Anforderung. Zu bestimmten gemeinsamen Zeitpunkten danach kann die Menge der Arbeitsberichte, die ein Knoten aus jedem Block's ***R*** bewerten muss, vergrÃ¶ÃŸert werden, wenn eine deklarierte Absicht nicht innerhalb einer angemessenen Zeit durch ein positives Urteil bestÃ¤tigt wird oder im Falle eines negativen Urteils. Diese VergrÃ¶ÃŸerungsereignisse werden "Tranches" genannt.

Wenn alle deklarierten Absichten fÃ¼r einen Arbeitsbericht zu einem bestimmten Zeitpunkt durch ein positives Urteil bestÃ¤tigt werden, gilt der Arbeitsbericht als Ã¼berprÃ¼ft. Sobald alle neu verfÃ¼gbaren Arbeitsberichte eines Blocks Ã¼berprÃ¼ft sind, betrachten wir den Block als Ã¼berprÃ¼ft. Eine Voraussetzung fÃ¼r die Finalisierung eines Blocks durch einen Knoten ist, dass er den Block als Ã¼berprÃ¼ft ansieht. Beachten Sie, dass es letztendlich einen Konsens darÃ¼ber geben wird, ob ein Block Ã¼berprÃ¼ft ist, dieser Konsens jedoch mÃ¶glicherweise nicht zum Zeitpunkt der Finalisierung des Blocks besteht. Dies beeintrÃ¤chtigt nicht die krypto-Ã¶konomischen Garantien dieses Systems.

Im regulÃ¤ren Betrieb wird letztendlich kein negatives Urteil fÃ¼r einen Arbeitsbericht gefunden, und es gibt keine direkten Konsequenzen der ÃœberprÃ¼fungsstufe. Im unwahrscheinlichen Fall, dass ein negatives Urteil gefunden wird, passiert eines von mehreren Dingen; wenn es immer noch mehr als **2/3V** positive Urteile gibt, kÃ¶nnen Validatoren, die negative Urteile ausstellen, fÃ¼r Zeitverschwendung bestraft werden. Wenn es mehr als **1/3V** negative Urteile gibt, wird der Block, der den Arbeitsbericht enthÃ¤lt, auf die Bannliste gesetzt. Er und alle seine Nachkommen werden ignoriert und dÃ¼rfen nicht weiter aufgebaut werden. In allen FÃ¤llen, sobald genÃ¼gend Stimmen vorliegen, kann ein Urteilsextrinsik von einem Blockautor erstellt und on-chain platziert werden, um das Ergebnis zu kennzeichnen. Details hierzu finden Sie in Abschnitt 10.

Alle AnkÃ¼ndigungen und Urteile werden allen Validatoren zusammen mit Metadaten, die das signierte Material beschreiben, verÃ¶ffentlicht. Beim Erhalt dieser Daten wird von den Validatoren erwartet, dass sie ihre Perspektive entsprechend aktualisieren (spÃ¤ter definiert als ***J*** und ***A***).

### 16.2. Datenerfassung (Data Fetching)

FÃ¼r jeden zu Ã¼berprÃ¼fenden Arbeitsbericht verwenden wir seinen Erasure-Root, um erasure-codierte Chunks von genÃ¼gend Assurern anzufordern. Von jedem Assurer holen wir drei Elemente (die mit einem guten Netzwerkprotokoll unter einer einzigen Anfrage erfolgen sollten), die den Super-Chunks des Arbeitspakets, den selbstbegrÃ¼ndenden Import-Super-Chunks und den extrinsischen Segment-Super-Chunks entsprechen.

Wir kÃ¶nnen die Rekonstruktion des Arbeitspakets validieren, indem wir sicherstellen, dass sein Hash dem Hash entspricht, der als Teil der Arbeitspaket-Spezifikation im Arbeitsbericht enthalten ist. Wir kÃ¶nnen die extrinsischen Segmente validieren, indem wir sicherstellen, dass ihre Hashes jeweils denjenigen entsprechen, die im entsprechenden Arbeitselement zu finden sind.

SchlieÃŸlich kÃ¶nnen wir jedes importierte Segment validieren, da eine BegrÃ¼ndung den verketteten Segmenten folgen muss, was es ermÃ¶glicht, zu Ã¼berprÃ¼fen, dass der Hash jedes Segments im referenzierenden Merkle-Root und Index des entsprechenden Arbeitselements enthalten ist.

Exportierte Segmente mÃ¼ssen nicht auf die gleiche Weise rekonstruiert werden, sondern sollten auf die gleiche Weise wie beim Garantieren bestimmt werden, d.h. durch die AusfÃ¼hrung der Refine-Logik.

Alle Elemente im Arbeitspaket-Spezifikationsfeld des Arbeitsberichts sollten aus diesen nun als korrekt bekannten Daten neu berechnet und verifiziert werden, indem im Wesentlichen die Schritte der BÃ¼rgen nachgezeichnet und deren Korrektheit sichergestellt wird.

### 16.3. Auswahl von Berichten (Selection of Reports)
Jeder Validator soll ÃœberprÃ¼fungsaufgaben fÃ¼r jeden gÃ¼ltigen Block Ã¼bernehmen, den er erhÃ¤lt. Da wir uns nun in der Off-Chain-Logik befinden und keinen Konsens voraussetzen kÃ¶nnen, betrachten wir uns fortan als einen spezifischen Validator mit dem Index ***v*** und nehmen an, dass wir uns auf einen Block ***B*** konzentrieren, wobei andere Begriffe entsprechend Ã¼bereinstimmen. Somit ist ***Ïƒâ€²*** der nachfolgende Zustand dieses Blocks, ***H*** ist sein Header usw. Praktisch mÃ¼ssen alle Ãœberlegungen fÃ¼r alle BlÃ¶cke repliziert werden und Ãœberlegungen zu mehreren BlÃ¶cken kÃ¶nnen gleichzeitig im Gange sein.

Wir definieren die Sequenz von Arbeitsberichten, die wir mÃ¶glicherweise Ã¼berprÃ¼fen mÃ¼ssen, als ***Q***, eine Sequenz mit einer LÃ¤nge, die der Anzahl der Kerne entspricht und als Abbildung vom Kernindex auf einen anstehenden Arbeitsbericht dient, der gerade verfÃ¼gbar geworden ist, oder ***âˆ…***, wenn kein Bericht im Kern verfÃ¼gbar wurde. Formal:

<div align="center">
<img src="img/equation-178-179.PNG" width="700"/>
</div>

Wir definieren unsere initiale ÃœberprÃ¼fungstranche in Bezug auf eine Ã¼berprÃ¼fbare ZufallsgrÃ¶ÃŸe ***s0***, die speziell dafÃ¼r erstellt wurde:

<div align="center">
<img src="img/equation-180-181.PNG" width="700"/>
</div>

Wir kÃ¶nnen dann ***a0*** als die nicht-leeren Elemente definieren, die durch eine Ã¼berprÃ¼fbare zufÃ¤llige Auswahl von zehn Kernen Ã¼berprÃ¼ft werden sollen:

<div align="center">
<img src="img/equation-182-184.PNG" width="700"/>
</div>

Alle ***A = 8*** Sekunden nach einem neuen Zeitschlitz beginnt eine neue Tranche, und wir kÃ¶nnen feststellen, dass zusÃ¤tzliche Kerne eine ÃœberprÃ¼fung von uns benÃ¶tigen. Solche Elemente werden als ***an*** definiert, wobei ***n*** die aktuelle Tranche ist. Formal:

<div align="center">
<img src="img/equation-185.PNG" width="700"/>
</div>

Neue Tranchen kÃ¶nnen Elemente aus ***Q***v enthalten, die aus einem von zwei GrÃ¼nden stammen: entweder wurde ein negatives Urteil empfangen oder die Anzahl der Urteile aus der vorherigen Tranche ist geringer als die Anzahl der AnkÃ¼ndigungen aus dieser Tranche. Im ersten Fall ist der Validator immer verpflichtet, ein Urteil Ã¼ber den Arbeitsbericht abzugeben.

In allen FÃ¤llen verÃ¶ffentlichen wir eine signierte ErklÃ¤rung darÃ¼ber, welche der Kerne wir unserer Meinung nach Ã¼berprÃ¼fen mÃ¼ssen (eine AnkÃ¼ndigung) zusammen mit einem Beweis der VRF-Signatur, um sie auszuwÃ¤hlen, und die AnkÃ¼ndigungen der anderen Validatoren aus der vorherigen Tranche, die nicht mit einem Urteil Ã¼bereinstimmen, damit alle anderen Validatoren die AnkÃ¼ndigung Ã¼berprÃ¼fen kÃ¶nnen. Die VerÃ¶ffentlichung einer AnkÃ¼ndigung sollte als Vertrag zur DurchfÃ¼hrung der ÃœberprÃ¼fung angesehen werden, unabhÃ¤ngig von zukÃ¼nftigen Informationen.

Formal stellen wir sicher, dass die AnkÃ¼ndigungserklÃ¤rung fÃ¼r jede Tranche ***n*** verÃ¶ffentlicht und an alle anderen Validatoren zusammen mit unserem Validator-Index ***v***, dem Beweis sn und allen signierten Daten verteilt wird. Die AnkÃ¼ndigungserklÃ¤rungen der Validatoren mÃ¼ssen in der Menge sein:

<div align="center">
<img src="img/equation-186-187.PNG" width="700"/>
</div>

Wir definieren ***An*** als unsere Wahrnehmung, welcher Validator jeden der Arbeitsberichte (identifiziert durch ihren zugehÃ¶rigen Kern) in Tranche ***n*** Ã¼berprÃ¼fen muss. Dies ergibt sich aus den AnkÃ¼ndigungen der anderen Validatoren (oben definiert). Es kann nicht korrekt bewertet werden, bis ***n*** aktuell ist. Wir haben absolute Kenntnis Ã¼ber unsere eigenen ÃœberprÃ¼fungsanforderungen.

<div align="center">
<img src="img/equation-188-189.PNG" width="700"/>
</div>

Wir definieren weiter ***JâŠº*** und ***J(+)*** als die Validator-Indizes, von denen wir wissen, dass sie jeweils positive bzw. negative Urteile abgegeben haben, die von jedem Arbeitsberichtskern abgebildet wurden. Uns ist es egal, aus welcher Tranche ein Urteil stammt.

<div align="center">
<img src="img/equation-190.PNG" width="700"/>
</div>

Wir kÃ¶nnen an fÃ¼r Tranchen jenseits der ersten auf der Grundlage der Anzahl der Validatoren definieren, von denen wir wissen, dass sie eine ÃœberprÃ¼fung durchfÃ¼hren mÃ¼ssen, von denen wir jedoch noch kein Urteil gesehen haben. Es ist mÃ¶glich, dass das spÃ¤te Eintreffen von Informationen an Ã¤ndert und Knoten sollten dies neu bewerten und entsprechend handeln, falls dies passiert.

Wir kÃ¶nnen an daher jenseits der initialen Tranche durch eine neue **VRF** definieren, die auf die Menge der Nicht-Erscheinungs-Validatoren wirkt.

<div align="center">
<img src="img/equation-191-192.PNG" width="700"/>
</div>

Wir definieren unseren Bias-Faktor ***F = 2***, was die erwartete Anzahl von Validatoren ist, die ein Urteil fÃ¼r einen Arbeitsbericht abgeben mÃ¼ssen, wenn ein einzelner Nicht-Erscheinen in der vorherigen Tranche auftritt. Modellierungen von Stewart (2018) zeigen, dass dies optimal ist.

SpÃ¤tere ÃœberprÃ¼fungen mÃ¼ssen Ã¤hnlich wie die erste angekÃ¼ndigt werden. Wenn die ÃœberprÃ¼fungsanforderungen beim Erhalt neuer Informationen (d.h. die RÃ¼ckkehr eines positiven Urteils fÃ¼r einen vorherigen Nicht-Erscheinen) sinken, werden alle bereits angekÃ¼ndigten ÃœberprÃ¼fungen abgeschlossen und Urteile verÃ¶ffentlicht. Wenn die ÃœberprÃ¼fungsanforderungen beim Erhalt neuer Informationen (d.h. eine zusÃ¤tzliche AnkÃ¼ndigung ohne begleitendes Urteil) steigen, kÃ¼ndigen wir die zusÃ¤tzlichen ÃœberprÃ¼fungen an, die wir durchfÃ¼hren werden.

Mit zunehmender Zeit und an wird unsere PrÃ¼fungsverantwortung bekannt und definiert. Wir mÃ¼ssen versuchen, alle Arbeitspakete und ihre erforderlichen Daten zu rekonstruieren, die jedem Arbeitsbericht entsprechen, den wir Ã¼berprÃ¼fen mÃ¼ssen. Dies kann durch Anfordern erasure-codierter Chunks von einem Drittel der Validatoren erfolgen. Es kann auch durch Anfragen an eine kooperative Drittpartei (z.B. einen ursprÃ¼nglichen BÃ¼rgen) fÃ¼r die Preimages abgekÃ¼rzt werden.

FÃ¼r jeden solchen Arbeitsbericht ***w*** kÃ¶nnen wir sicher sein, dass wir ein Kandidaten-Arbeitspaket-Encoding ***F(w)*** abrufen kÃ¶nnen, das entweder durch die Rekonstruktion erasure-codierter Chunks, die durch die Merkle-Root des Erasure-Codings verifiziert wurden, oder alternativ durch das Preimage des Arbeitspaket-Hashes stammt. Wir dekodieren diesen Kandidaten-Blob in ein Arbeitspaket.

ZusÃ¤tzlich zum Arbeitspaket gehen wir davon aus, dass wir alle zugehÃ¶rigen Manifestdaten durch Anfordern und Rekonstruieren erasure-codierter Chunks von einem Drittel der Validatoren auf die gleiche Weise wie oben beschrieben abrufen kÃ¶nnen.

Wir versuchen dann, den Bericht auf dem Kern zu reproduzieren, um en zu geben, eine Abbildung von Kernen zu Bewertungen:

<div align="center">
<img src="img/equation-193.PNG" width="700"/>
</div>

Beachten Sie, dass ein Dekodierungsfehler einen ungÃ¼ltigen Arbeitsbericht impliziert.

Aus dieser Abbildung gibt der Validator eine Reihe von Urteilen ab:

<div align="center">
<img src="img/equation-194.PNG" width="700"/>
</div>

Alle Urteile ***jâˆ—*** sollten anderen Validatoren verÃ¶ffentlicht werden, damit sie ihre Sichtweise von ***J*** aufbauen kÃ¶nnen und im Falle eines negativen Urteils einen Extrinsik fÃ¼r ***EJ*** bilden kÃ¶nnen.

Wir betrachten einen Arbeitsbericht unter zwei UmstÃ¤nden als Ã¼berprÃ¼ft. Entweder, wenn er keine negativen Urteile hat und es eine Tranche gibt, in der wir ein positives Urteil von allen Validatoren sehen, von denen wir glauben, dass sie ihn Ã¼berprÃ¼fen mÃ¼ssen; oder wenn wir positive Urteile von mehr als zwei Dritteln des Validatorensatzes sehen.

<div align="center">
<img src="img/equation-195.PNG" width="700"/>
</div>

Unser Block ***B*** kann als Ã¼berprÃ¼ft betrachtet werden, ein Zustand, der als ***U*** bezeichnet wird, wenn alle verfÃ¼gbaren Arbeitsberichte als Ã¼berprÃ¼ft gelten. Formal:

<div align="center">
<img src="img/equation-196.PNG" width="700"/>
</div>

FÃ¼r jeden Block mÃ¼ssen wir ihn als Ã¼berprÃ¼ft beurteilen (d.h. ***U = âŠº***), bevor wir fÃ¼r den Block stimmen, um in Grandpa finalisiert zu werden. Weitere Informationen hierzu finden Sie in Abschnitt 18.

DarÃ¼ber hinaus ignorieren wir gezielt Ketten, die die Akkumulation eines Berichts enthalten, den wir wissen, dass mindestens ein Drittel der Validatoren als ungÃ¼ltig beurteilen. Alle Ketten, die einen solchen Block enthalten, sind nicht fÃ¼r die Erstellung geeignet. Der beste Block, d.h. der, auf dem wir neue BlÃ¶cke aufbauen, ist die Kette mit den meisten regulÃ¤ren Safrole-BlÃ¶cken, die keinen solchen ignorierten Block enthÃ¤lt. Implementierungstechnisch kann dies eine RÃ¼ckkehr zu einem frÃ¼heren Kopf oder einer alternativen Gabel erfordern.

Als Blockautor schlieÃŸen wir einen Urteilsextrinsik ein, der Urteilssignaturen sammelt und sie on-chain meldet. Im Falle eines ungÃ¼ltigen Urteils (d.h. eines Urteils, das nicht zwei Drittel plus eins der Urteile zur BestÃ¤tigung der GÃ¼ltigkeit umfasst), wird dieser Extrinsik in einen Block eingefÃ¼hrt, in dem die Akkumulation des ungÃ¼ltigen Arbeitsberichts kurz bevorsteht. Der ungÃ¼ltige Urteilsextrinsik entfernt ihn aus den anstehenden Arbeitsberichten, ***Ï***. Weitere Details hierzu finden Sie in Abschnitt 10.

## 17. Beefy-Verteilung (Beefy Distribution)
FÃ¼r jeden finalisierten Block ***B***, den ein Validator importiert, soll dieser Validator eine BLS-Signatur auf der Kurve BLS12-381 erstellen, wie von BLS12-381 definiert, und den Keccak-Hash des jÃ¼ngsten Beefy-MMR des Blocks bestÃ¤tigen. Diese Signatur sollte verÃ¶ffentlicht und frei verteilt werden, zusammen mit dem signierten Material. Diese Signaturen kÃ¶nnen aggregiert werden, um prÃ¤gnante FinalitÃ¤tsnachweise fÃ¼r Drittsysteme bereitzustellen. Der Signier- und Aggregationsmechanismus wird vollstÃ¤ndig von cryptoeprint:2022/1611 definiert.

Formal, sei ***Fv*** das signierte Commitment des Validators mit dem Index ***v***, das verÃ¶ffentlicht wird:

<div align="center">
<img src="img/equation-197-198.PNG" width="700"/>
</div>

## 18. Grandpa und die beste Kette (Grandpa and the Best Chain)
Knoten nehmen am Grandpa-Protokoll teil, wie von Stewart 2020 definiert.
Wir definieren den neuesten finalisierten Block als ***Bâ™®***. Alle damit verbundenen Begriffe bezÃ¼glich Block und Zustand sind entsprechend hochgestellt. Wir betrachten den besten Block, ***Bâ™­***, als denjenigen, der aus der Menge akzeptabler BlÃ¶cke nach den folgenden Kriterien ausgewÃ¤hlt wird:

Hat den finalisierten Block als Vorfahren.
EnthÃ¤lt keine unfinalisierten BlÃ¶cke, bei denen wir eine Equivokation (zwei gÃ¼ltige BlÃ¶cke zum selben Zeitpunkt) sehen.
Wird als Ã¼berprÃ¼ft betrachtet.
Formal:

<div align="center">
<img src="img/equation-199-201.PNG" width="700"/>
</div>

Von diesen akzeptablen BlÃ¶cken sollte derjenige ausgewÃ¤hlt werden, der die meisten VorfahrenblÃ¶cke enthÃ¤lt, deren Autor ein Siegel-SchlÃ¼sselticket anstelle eines Fallback-SchlÃ¼ssels verwendet hat, und somit die Kette, auf der der Teilnehmer Grandpa-Stimmen abgeben sollte.

Formal, wir streben an, ***Bâ™­*** auszuwÃ¤hlen, um den Wert ***m*** zu maximieren, wobei:

<div align="center">
<img src="img/equation-202.PNG" width="700"/>
</div>

## 19. Bewertungen und Belohnungen

Die JAM-Kette vergibt nicht explizit Belohnungen â€“ dies Ã¼berlassen wir dem Staking-Subsystem (eine System-Parachain â€“ gebÃ¼hrenfrei gehostet â€“ in der aktuellen Vorstellung eines Ã¶ffentlichen JAM-Netzwerks). Es ist jedoch wichtig, dass die JAM-Kette, Ã¤hnlich wie bei der Bestrafungsinformation fÃ¼r Validatoren, die Bereitstellung von Leistungsinformationen an das Staking-Subsystem erleichtert, damit darauf reagiert werden kann.

Solche Leistungsinformationen kÃ¶nnen nicht alle Aspekte der Validator-AktivitÃ¤ten direkt abdecken; wÃ¤hrend Blockproduktion, BÃ¼rgermeldungen und VerfÃ¼gbarkeitsgarantien leicht on-chain verfolgt werden kÃ¶nnen, kÃ¶nnen Grandpa-, Beefy- und PrÃ¼fungsaktivitÃ¤ten dies nicht. In letzterem Fall wird dies stattdessen durch die AbstimmungsaktivitÃ¤t der Validatoren verfolgt: Validatoren stimmen Ã¼ber ihre EinschÃ¤tzung der BemÃ¼hungen der anderen ab und ein Median kann als die Wahrheit fÃ¼r jeden einzelnen Validator akzeptiert werden. Mit der Annahme von 50% ehrlichen Validatoren bietet dies ein angemessenes Mittel, um diese Informationen zu orakeln.

## 20. Diskussion
### 20.1 Technische Merkmale

Insgesamt, mit unserem angegebenen Ziel von **1.023** Validatoren und drei Validatoren pro Kern, sowie der Anforderung, dass jeder Validator im Durchschnitt zehn Audits pro Zeitschlitz durchfÃ¼hrt, und somit **30** Audits pro Arbeitsbericht, ist JAM in der Lage, **341** Arbeitspakete pro Zeitschlitz vertrauenslos zu verarbeiten und zu integrieren.

Wir gehen davon aus, dass die Hardware der Knoten ein moderner **16-Kern-CPU** mit **64 GB RAM**, **1 TB** SekundÃ¤rspeicher und **0,5 Gbit/s** NetzwerkkapazitÃ¤t ist. Unsere Leistungsmodelle gehen von einer ungefÃ¤hren Aufteilung der CPU-Zeit wie folgt aus:

<div align="center">
<img src="img/tabel-1.PNG" width="700"/>
</div>

SchÃ¤tzungen fÃ¼r den Netzwerkbandbreitenbedarf sind wie folgt:

<div align="center">
<img src="img/tabel-2.PNG" width="700"/>
</div>

Eine Verbindung, die **500 Mbit/s** aufrechterhalten kann, sollte genÃ¼gend Fehlertoleranz und Spielraum bieten, um andere Validatoren sowie einige Ã¶ffentliche Verbindungen zu bedienen, obwohl die Spitzenlast bei der BlockverÃ¶ffentlichung impliziert, dass Validatoren sicherstellen sollten, dass die Spitzenbandbreite hÃ¶her ist.

Unter diesen Bedingungen erwarten wir eine gesamte netzwerkbereitgestellte DatenverfÃ¼gbarkeit von **2 PB**, wobei jeder Knoten maximal **6 TB** fÃ¼r VerfÃ¼gbarkeitsspeicher bereitstellt. SchÃ¤tzungen fÃ¼r den Speicherbedarf sind wie folgt:

<div align="center">
<img src="img/tabel-3.PNG" width="700"/>
</div>

Als grobe Richtlinie hat jede Parachain einen durchschnittlichen Speicherbedarf von etwa **2 MB** in der Polkadot-Relay-Chain; ein **40-GB-Zustand** wÃ¼rde es ermÃ¶glichen, die Informationen von **20.000 Parachains** im Zustand zu behalten.

Die â€virtuelle Hardwareâ€œ eines JAM-Kerns ist im Wesentlichen ein regulÃ¤rer CPU-Kern, der mit etwa **25%** bis **50%** der regulÃ¤ren Geschwindigkeit fÃ¼r den gesamten sechs Sekunden dauernden Abschnitt ausgefÃ¼hrt wird und durchschnittlich **2,5 MB/s** fÃ¼r allgemeine Ein-/Ausgabe ziehen und bereitstellen kann und bis zu **2 GB RAM** nutzen kann. Die Ein-/Ausgabe umfasst alle vertrauenslosen LesevorgÃ¤nge aus dem JAM-Chain-Zustand, wenn auch in der jÃ¼ngeren Vergangenheit. Diese virtuelle Hardware bietet auch unbegrenzte LesevorgÃ¤nge aus einer semi-statischen Preimage-Lookup-Datenbank.

Jedes Arbeitspaket kann diese Hardware belegen und beliebigen Code darauf in sechs Sekunden langen Segmenten ausfÃ¼hren, um ein Ergebnis von maximal **90 KB** zu erzeugen. Dieses Arbeitsergebnis hat dann Anspruch auf **10 ms** auf derselben Maschine, diesmal ohne â€externeâ€œ Ein-/Ausgabe auÃŸer dem genannten Ergebnis, aber mit vollem und unmittelbarem Zugriff auf den JAM-Chain-Zustand und kann die Dienste, zu denen die Ergebnisse gehÃ¶ren, Ã¤ndern.

### 20.2. Leistungsdarstellung
In Bezug auf die reine Rechenleistung kann die JAM-Maschinenarchitektur extrem hohe Ebenen homogener vertrauensloser Berechnungen liefern. Das Kernmodell von JAM ist jedoch eine klassische parallelisierte Rechenarchitektur, und damit LÃ¶sungen die Architektur gut nutzen kÃ¶nnen, mÃ¼ssen sie bis zu einem gewissen Grad damit gestaltet werden. Daher ist es sehr schwierig, direkte Vergleiche mit bestehenden Systemen anzustellen, bis solche AnwendungsfÃ¤lle mit Ã¤hnlicher Semantik auf JAM erscheinen. Dennoch kÃ¶nnen wir mit einigen Annahmen grobe Vergleiche anstellen.

#### 20.2.1. Vergleich mit Polkadot
Vor der asynchronen UnterstÃ¼tzung validiert Polkadot etwa **50** Parachains, wobei jede etwa **250 ms** nativer Berechnung (d.h. eine halbe Sekunde Wasm-AusfÃ¼hrungszeit bei etwa 50% Overhead) und **5 MB** Ein-/Ausgabe fÃ¼r alle zwÃ¶lf Sekunden Echtzeit benÃ¶tigt. Dies entspricht einer aggregierten Rechenleistung von etwa ParitÃ¤t mit einem nativen CPU-Kern und einer gesamten verteilten VerfÃ¼gbarkeit von etwa **20 MB/s**. Die Akkumulation liegt auÃŸerhalb der FÃ¤higkeiten von Polkadot und ist daher nicht vergleichbar.

Nach der asynchronen UnterstÃ¼tzung und der SchÃ¤tzung, dass Polkadot derzeit in der Lage ist, maximal **80** Parachains zu validieren, die jeweils eine Sekunde nativer Berechnung in sechs Sekunden durchfÃ¼hren, erhÃ¶ht sich die aggregierte Leistung auf etwa 13x nativer CPU und die verteilte VerfÃ¼gbarkeit auf etwa **67 MB/s**.

Zum Vergleich: In unseren Basis-Modellen sollte JAM in der Lage sein, etwa **85x** die Rechenlast eines einzelnen nativen CPU-Kerns und eine verteilte VerfÃ¼gbarkeit von **852 MB/s** zu erreichen.

#### 20.2.2. Einfache Ãœberweisungen (Simple Transfers)
Wir kÃ¶nnten auch versuchen, eine einfache Transaktionen-pro-Sekunde-Anzahl zu modellieren, wobei jede Transaktion eine SignaturÃ¼berprÃ¼fung und die Ã„nderung von zwei KontostÃ¤nden erfordert. Da es jedoch bis zur klaren Gestaltung noch einige Annahmen gibt, mÃ¼ssen wir einige Annahmen machen. Unser naivstes Modell wÃ¤re, die JAM-Kerne (d.h. die Verfeinerung) einfach zur TransaktionsÃ¼berprÃ¼fung und Kontosuche zu verwenden. Die JAM-Kette wÃ¼rde dann die Salden in ihrem Zustand halten und Ã¤ndern. Dies wÃ¼rde wahrscheinlich keine groÃŸartige Leistung erbringen, da fast alle erforderlichen Ein-/Ausgaben synchron wÃ¤ren, aber es kann als Grundlage dienen.

Ein **15-MB**-Arbeitspaket kann etwa **125k** Transaktionen mit **128 Byte** pro Transaktion halten. Ein **90-KB**-Arbeitsergebnis kÃ¶nnte jedoch nur etwa **11k** Kontoupdates kodieren, wenn jedes Update als Paar aus einem **4-Byte-Kontoindex** und einem **4-Byte-Saldo** angegeben wird, was zu einem Limit von **5,5k** Transaktionen pro Paket fÃ¼hrt, oder insgesamt **312k TPS**. Es ist mÃ¶glich, dass die acht Bytes typischerweise um ein oder zwei Bytes komprimiert werden kÃ¶nnten, was den maximalen Durchsatz etwas erhÃ¶hen wÃ¼rde. Unsere Erwartungen sind, dass Zustandsaktualisierungen mit hoch parallelisierter Merklisierung mit etwa **500k** bis **1 Million** Lese-/SchreibvorgÃ¤ngen pro Sekunde durchgefÃ¼hrt werden kÃ¶nnen, was etwa **250k-350k TPS** impliziert, je nachdem, was sich als Engpass herausstellt.

Ein raffinierteres Modell wÃ¤re, die JAM-Kerne sowohl fÃ¼r Saldenaktualisierungen als auch fÃ¼r die TransaktionsÃ¼berprÃ¼fung zu verwenden. Wir mÃ¼ssten annehmen, dass der Zustand und die Transaktionen, die auf sie wirken, zwischen Arbeitspaketen mit einer gewissen Effizienz partitioniert werden kÃ¶nnen und dass die **15 MB** des Arbeitspakets zwischen Transaktionsdaten und Zustandsnachweisdaten aufgeteilt wÃ¼rden. Unsere Basis-Modelle sagen voraus, dass ein **4-Milliarden-32-Bit-Kontosystem**, das in **210** Konten/Seite und **128 Byte** pro Transaktion unterteilt ist, bei Annahme, dass nur etwa 1% der orakelten Konten nÃ¼tzlich sind, durchschnittlich Ã¼ber **1,7 MTPS** erreichen kÃ¶nnte, abhÃ¤ngig von der Partitionierung und den Nutzungseigenschaften. Die Partitionierung kÃ¶nnte mit einer festen Fragmentierung (im Wesentlichen Sharding des Zustands), einem rotierenden Partitionierungsmuster oder einer dynamischen Partitionierung (die eine spezialisierte Sequenzierung erfordern wÃ¼rde) durchgefÃ¼hrt werden.

Interessanterweise erwarten wir, dass keines der Modelle bei der Berechnung einen Engpass darstellt, was bedeutet, dass Transaktionen wesentlich ausgefeilter sein kÃ¶nnten, mÃ¶glicherweise mit flexiblerer Kryptografie oder Smart-Contract-FunktionalitÃ¤t, ohne dass dies einen signifikanten Einfluss auf die Leistung hat.

#### 20.2.3. Rechendurchsatz (Computation Throughput)
Die TPS-Metrik eignet sich nicht gut zur Messung der Rechenleistung verteilter Systeme, daher wenden wir uns nun einem etwas stÃ¤rker auf die Berechnung fokussierten Benchmark zu: dem **EVM**. Das grundlegende YP-Ethereum-Netzwerk, das sich dem Jahrzehnt nÃ¤hert, ist wahrscheinlich das bekannteste Beispiel fÃ¼r dezentrale Berechnungen allgemeiner Art und dient als vernÃ¼nftiger MaÃŸstab. Es kann eine Berechnungs- und E/A-Rate von **1,25 Millionen Gas/Sekunde** aufrechterhalten, mit einer Spitzenleistung von doppelt so viel. Die **EVM**-Gas-Metrik wurde entwickelt, um eine zeitproportionale Metrik zur Vorhersage und Begrenzung der ProgrammausfÃ¼hrung zu sein.

Der Versuch, einen konkreten Vergleich zur **PVM**-Leistung zu ziehen, ist nicht trivial und notwendigerweise subjektiv, aufgrund der Unterschiede zwischen den beiden Plattformen einschlieÃŸlich WortgrÃ¶ÃŸe, Endianness, Stack/Register-Architektur und Speichermodell. Wir werden jedoch versuchen, einen vernÃ¼nftigen Wertebereich zu bestimmen.

**EVM**-Gas Ã¼bersetzt sich nicht direkt in native AusfÃ¼hrung, da es auch Zustandslesungen und -schreibungen sowie Transaktionseingabedaten kombiniert, was impliziert, dass es eine Kombination von bis zu 595 Speicherlesungen, **57** Speicherschreibungen und **1,25 Millionen Gas** sowie **78 KB** Eingabedaten pro Sekunde verarbeiten kann, indem eines gegen das andere ausgetauscht wird.**^13** Wir kÃ¶nnen keine Analyse der typischen Aufteilung zwischen Speicher-E/A und reiner Berechnung finden, daher machen wir eine sehr konservative SchÃ¤tzung und nehmen an, dass es alle vier durchfÃ¼hrt. In Wirklichkeit wÃ¼rden wir erwarten, dass es im Durchschnitt **1/4** von jedem ausfÃ¼hrt.

Unsere Experimente **^14** zeigen, dass wir auf moderner, hochleistungsfÃ¤higer Verbrauchshardware mit einer modernen **EVM**-Implementierung irgendwo zwischen **100** und **500** **Gas/Âµs** Durchsatz bei reinen Rechenlasten erwarten kÃ¶nnen (wir haben speziell Odd-Product, Triangle-Number und mehrere Implementierungen der Fibonacci-Berechnung verwendet). Um einen konservativen Vergleich zur **PVM** zu ziehen, schlagen wir vor, den **EVM**-Code in **PVM**-Code zu transkompilieren und ihn dann unter dem Polkavm-Prototyp erneut auszufÃ¼hren.**^15**

Um eine vernÃ¼nftige Untergrenze fÃ¼r ****EVM**-Gas/Âµs** zu schÃ¤tzen, beispielsweise fÃ¼r Workloads, die mehr Speicher- und E/A-Lasten haben, schauen wir uns reale, erlaubnisfreie EinsÃ¤tze der **EVM** an und sehen, dass das Moonbeam-Netzwerk nach Korrektur der Verlangsamung durch die AusfÃ¼hrung innerhalb der neu kompilierten WebAssembly-Plattform auf der etwas konservativen Polkadot-Hardwareplattform einen Durchsatz von etwa 100 Gas/Âµs impliziert. Daher behaupten wir, dass in Bezug auf die Berechnung **1 Âµs **EVM**-Gas** etwa **100-500** Gas auf moderner hochleistungsfÃ¤higer Verbrauchshardware entspricht.**^16**

Benchmarking- und Regressionstests zeigen, dass der Prototyp-**PVM**-Engine einen festen Vorverarbeitungsaufwand von etwa **5 ns/Byte** Programmcode hat und fÃ¼r rechenintensive Aufgaben zumindest einen marginalen Faktor von **1,6-2%** im Vergleich zur **EVM**-AusfÃ¼hrung aufweist, was eine asymptotische Beschleunigung von etwa **50-60x** impliziert. Bei Maschinencode von **1 MB GrÃ¶ÃŸe**, der voraussichtlich etwa eine Sekunde zur Berechnung benÃ¶tigt, werden die Kompilierungskosten nur 0,5% der Gesamtzeit betragen.**^17**

FÃ¼r Code, der nicht von Natur aus fÃ¼r die 256-Bit-**EVM**-ISA geeignet ist, wÃ¼rden wir erheblich verbesserte relative AusfÃ¼hrungszeiten auf der **PVM** erwarten, obwohl mehr Arbeit erforderlich ist, um sicherzustellen, dass diese Beschleunigungen allgemein anwendbar sind.

> **Footnotes:**
>
>**^13** Die neuesten "Proto-Danksharding"-Ã„nderungen ermÃ¶glichen es, 87,3 kb/s an festgelegten Daten zu akzeptieren, obwohl diese nicht direkt im Zustand verfÃ¼gbar sind. Daher schlieÃŸen wir es aus dieser Darstellung aus, obwohl die Einbeziehung in die Eingabedaten die Ergebnisse nur geringfÃ¼gig Ã¤ndern wÃ¼rde.
>
>**^14** Dies ist ausfÃ¼hrlich beschrieben unter https://hackmd.io/@XXX9CM1uSSCWVNFRYaSB5g/HJarTUhJA und soll aktualisiert werden, sobald wir mehr Informationen erhalten.
>
>**^15** Es ist konservativ, da wir nicht berÃ¼cksichtigen, dass der Quellcode ursprÃ¼nglich in **EVM**-Code kompiliert wurde und somit der **PVM**-Maschinencode architektonische Artefakte replizieren wird und daher sehr wahrscheinlich pessimistisch ist. Ein Beispiel: Alle arithmetischen Operationen in **EVM** sind 256-Bit und 32-Bit native **PVM** wird gezwungen, dies zu honorieren, auch wenn der Quellcode tatsÃ¤chlich nur 32-Bit-Werte benÃ¶tigt.
>
>**^16** Wir spekulieren, dass die erhebliche Spanne mÃ¶glicherweise teilweise durch die groÃŸen architektonischen Unterschiede zwischen der **EVM**-ISA und typischer moderner Hardware verursacht wird.
>
>**^17** Ein Beispiel: Unser Odd-Product-Benchmark, eine sehr reine Rechenaufgabe, benÃ¶tigt 58 Sekunden auf **EVM** und 1,04 Sekunden innerhalb unseres **PVM**-Prototyps, einschlieÃŸlich aller Vorverarbeitung.

Wenn wir erlauben, dass die Vorverarbeitung denselben Anteil an der AusfÃ¼hrung einnimmt wie die marginalen Kosten (aufgrund eines beispielsweise extrem groÃŸen, aber kurz laufenden Programms) und dass die **PVM**-Messung eine SicherheitsÃ¼berlastung von **2x** zur AusfÃ¼hrungsgeschwindigkeit impliziert, kÃ¶nnen wir erwarten, dass ein JAM-Kern in der Lage ist, das Ã„quivalent von etwa **1.500 **EVM**-Gas/Âµs** zu verarbeiten. Aufgrund der Grobheit unserer Analyse kÃ¶nnten wir vernÃ¼nftigerweise vorhersagen, dass es irgendwo innerhalb eines Faktors von drei in beide Richtungen liegt â€“ also **500-5.000 **EVM**-Gas/Âµs**.

JAM-Kerne sind jeweils in der Lage, **2,5 MB/s** Bandbreite zu erreichen, was jegliche Zustands-E/A und Daten, die neu eingefÃ¼hrt werden mÃ¼ssen (z.B. Transaktionen), umfassen muss. WÃ¤hrend SchreibvorgÃ¤nge vergleichsweise wenig Kosten fÃ¼r den Kern verursachen, da nur das Hashing erforderlich ist, um eine endgÃ¼ltige aktualisierte Merkle-Root zu bestimmen, mÃ¼ssen LesevorgÃ¤nge nachgewiesen werden, wobei jeder etwa **640 Byte** Beweisdaten kostet, wenn man konservativ von einem BinÃ¤r-Merkle-Trie mit einer Million EintrÃ¤gen ausgeht. Dies wÃ¼rde zu einem Maximum von knapp **4.000** LesevorgÃ¤ngen/Sekunde/Kern fÃ¼hren, wobei die genaue Menge davon abhÃ¤ngt, wie viel der Bandbreite fÃ¼r neu eingefÃ¼hrte Eingabedaten verwendet wird.

Alles in allem kÃ¶nnen die Zahlen von JAM, mit Ausnahme der Akkumulation, die zusÃ¤tzlichen Durchsatz hinzufÃ¼gen kÃ¶nnte, mit **341** multipliziert werden (mit dem Vorbehalt, dass die Berechnungen der einzelnen Knoten nicht die der anderen stÃ¶ren kÃ¶nnen, auÃŸer durch Zustandsorakalisierung und Akkumulation). Im Gegensatz zu Roll-up-Chain-Designs wie Polkadot und Ethereum muss kein persistent fragmentierter Zustand vorhanden sein. Der Zustand von Smart Contracts kann in einem kohÃ¤renten Format auf der JAM-Kette gehalten werden, solange alle Updates Ã¼ber die **15 KB/Kern/Sek**-Arbeitsergebnisse vorgenommen werden, die nur die Hashes der geÃ¤nderten Zustandswurzeln der VertrÃ¤ge enthalten mÃ¼ssen.

<div align="center">
<img src="img/tabel-4.PNG" width="700"/>
</div>

Was wir sehen kÃ¶nnen, ist, dass das insgesamt vorhergesagte Leistungsprofil von JAM impliziert, dass es vergleichbar mit vielen Tausenden der grundlegenden Ethereum-L1-Kette sein kÃ¶nnte. Der groÃŸe Faktor hier ist im Wesentlichen auf drei Dinge zurÃ¼ckzufÃ¼hren: rÃ¤umlicher Parallelismus, da JAM mehrere hundert Kerne unter seinem Sicherheitsapparat hosten kann; zeitlicher Parallelismus, da JAM eine kontinuierliche AusfÃ¼hrung fÃ¼r seine Kerne anstrebt und einen GroÃŸteil der Berechnungen zwischen BlÃ¶cken pipelinet, um eine konstante, optimale Arbeitslast zu gewÃ¤hrleisten; und Plattformoptimierung durch die Verwendung eines VM- und Gas-Modells, das eng zu modernen Hardwarearchitekturen passt.

Es muss jedoch verstanden werden, dass dies nur eine vorlÃ¤ufige und grobe SchÃ¤tzung ist. Sie dient nur dem Zweck, die Leistung von JAM in greifbaren Begriffen auszudrÃ¼cken und ist nicht als Mittel zum Vergleich mit einer â€voll entwickeltenâ€œ Ethereum/L2-Ã–kosystem-Kombination gedacht. Insbesondere berÃ¼cksichtigt es nicht:

- dass diese Zahlen auf der realen Leistung von Ethereum und der Leistungsmodellierung von JAM basieren (obwohl unsere Modelle auf der realen Leistung der Komponenten basieren);
- jegliche L2-Skalierung, die mit JAM oder Ethereum mÃ¶glich sein kÃ¶nnte;
- die Zustandspartitionierung, die die Verwendung von JAM implizieren wÃ¼rde;
- das noch nicht festgelegte Gas-Modell fÃ¼r die **PVM**;
- dass **PVM**/**EVM**-Vergleiche notwendigerweise ungenau sind;
- (+) alle Zahlen fÃ¼r Ethereum L1 stammen aus derselben Quelle: im Durchschnitt wird jede Zahl nur **1/4** dieses Maximums sein.
- (++) die Zustandslesungen und Eingabedatenzahlen fÃ¼r JAM stammen aus derselben Quelle: im Durchschnitt wird jede Zahl nur **1/2** dieses Maximums sein.
Wir Ã¼berlassen es zukÃ¼nftigen Arbeiten, eine empirische Leistungsanalyse und einen Vergleich zwischen JAM und dem Aggregat eines hypothetischen Ethereum-Ã–kosystems durchzufÃ¼hren, das eine maximale Menge an L2-Bereitstellungen zusammen mit vollstÃ¤ndigem Dank-Sharding und allen anderen zusÃ¤tzlichen Konsenselementen, die sie benÃ¶tigen wÃ¼rden, einschlieÃŸt. Dies liegt jedoch auÃŸerhalb des Umfangs der vorliegenden Arbeit.

## 21. Schlussfolgerung

Wir haben ein neuartiges Berechnungsmodell eingefÃ¼hrt, das bestehende kryptographisch-Ã¶konomische Mechanismen nutzen kann, um erhebliche Verbesserungen in der Skalierbarkeit zu erzielen, ohne eine dauerhafte Fragmentierung des Zustands zu verursachen und somit die GesamtkohÃ¤sion zu opfern. Wir nennen dieses Gesamtmuster "collect-refine-join-accumulate". DarÃ¼ber hinaus haben wir den On-Chain-Teil dieser Logik formell definiert, im Wesentlichen den join-accumulate-Teil. Wir nennen dieses Protokoll die JAM-Kette.

Wir argumentieren, dass das Modell von JAM einen neuartigen "sweet spot" bietet, der es ermÃ¶glicht, enorme Mengen an Berechnungen in einem sicheren, widerstandsfÃ¤higen Konsens im Vergleich zu vollstÃ¤ndig synchronen Modellen durchzufÃ¼hren, und dennoch strikte Garantien Ã¼ber sowohl das Timing als auch die Integration der Berechnung in eine singulÃ¤re Zustandsmaschine bietet, im Gegensatz zu dauerhaft fragmentierten Modellen.

### 21.1. WeiterfÃ¼hrende Arbeiten

WÃ¤hrend wir in der Lage sind, die theoretische Berechnung unter bestimmten Grundannahmen zu schÃ¤tzen und sogar grobe Vergleiche mit bestehenden Systemen anzustellen, sind praktische Zahlen von unschÃ¤tzbarem Wert. Wir glauben, dass das Modell weitere empirische Forschung verdient, um besser zu verstehen, wie sich diese theoretischen Grenzen in der realen Welt auswirken. Wir halten eine ordnungsgemÃ¤ÃŸe Kostenanalyse und den Vergleich mit bestehenden Protokollen ebenfalls fÃ¼r ein ausgezeichnetes Thema fÃ¼r weiterfÃ¼hrende Arbeiten.

Wir kÃ¶nnen mit einiger Sicherheit sagen, dass das Design von JAM es ermÃ¶glicht, einen Dienst zu hosten, unter dem Polkadot-Parachains validiert werden kÃ¶nnten, jedoch sind weitere Prototyping-Arbeiten erforderlich, um zu verstehen, welchen mÃ¶glichen Durchsatz ein **PVM**-gestÃ¼tztes Abrechnungssystem unterstÃ¼tzen kÃ¶nnte. Wir lassen einen solchen Bericht als weiterfÃ¼hrende Arbeit. Ebenso haben wir bewusst Details von Protokollelementen hÃ¶herer Ebene wie KryptowÃ¤hrung, Coretime-VerkÃ¤ufe, Staking und regulÃ¤re Smart-Contract-FunktionalitÃ¤t ausgelassen.

Eine Reihe potenzieller Ã„nderungen am hier beschriebenen Protokoll werden in Betracht gezogen, um die praktische Nutzung des Protokolls zu erleichtern. Diese umfassen:

- Synchrone Aufrufe zwischen Diensten im accumulate-Prozess.
- EinschrÃ¤nkungen der Transferfunktion, um eine erhebliche ParallelitÃ¤t Ã¼ber die Akkumulation hinweg zu ermÃ¶glichen.
- Die MÃ¶glichkeit, unter bestimmten Bedingungen wÃ¤hrend der Akkumulation betrÃ¤chtliche zusÃ¤tzliche RechenkapazitÃ¤t zu reservieren.
- Die EinfÃ¼hrung der Merklisierung in das Work-Package-Format, um die Notwendigkeit zu beseitigen, das gesamte Paket herunterzuladen, um seine Autorisierung zu bewerten.

Das Netzwerkprotokoll ist zu diesem Zeitpunkt ebenfalls absichtlich undefiniert gelassen und seine Beschreibung muss in einem Folgeantrag erfolgen. Die Leistung der Validatoren wird derzeit nicht On-Chain verfolgt. Wir erwarten, dass dies in der endgÃ¼ltigen Version des JAM-Protokolls On-Chain verfolgt wird, aber das spezifische Format ist noch ungewiss und daher derzeit ausgelassen.

## 22. Anerkennung
Die Informationen sind Kapitel 22 des Originalpapiers zu entnehmen.

## APPENDIX
Die Informationen sind Anhang des Originalpapiers zu entnehmen.